{"meta":{"title":"崔八由","subtitle":"","description":"七只鸟离开了夏天，飞向了秋天","author":"崔八由","url":"https://acchw.top","root":"/"},"pages":[{"title":"关于","date":"2025-01-21T05:49:52.462Z","updated":"2025-01-21T05:49:52.462Z","comments":false,"path":"about/index.html","permalink":"https://acchw.top/about/index.html","excerpt":"","text":"我的名字：崔八由 希望十年后， 我的这个小破站还在吧。 博客大事记久远的一些变更已经记不清具体时间了，这儿只记录一些还能找到的时间点 2021 2022 2023 2024 2024"},{"title":"留言板","date":"2023-04-08T18:23:25.000Z","updated":"2025-01-21T05:49:52.462Z","comments":true,"path":"board/index.html","permalink":"https://acchw.top/board/index.html","excerpt":"","text":"有什么想说的或者建议，都可以在这儿说。 当然，不要涉及敏感话题喔 。"},{"title":"分类","date":"2025-01-21T05:49:52.462Z","updated":"2025-01-21T05:49:52.462Z","comments":false,"path":"categories/index.html","permalink":"https://acchw.top/categories/index.html","excerpt":"","text":""},{"title":"","date":"2025-01-21T05:49:52.462Z","updated":"2025-01-21T05:49:52.462Z","comments":true,"path":"css/custom.css","permalink":"https://acchw.top/css/custom.css","excerpt":"","text":"body { background-color: rgba(76, 76, 76, 0) !important; background-image: url(\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='260' height='260' viewBox='0 0 260 260'%3E%3Cg fill-rule='evenodd'%3E%3Cg fill='%23000000' fill-opacity='0.06'%3E%3Cpath d='M24.37 16c.2.65.39 1.32.54 2H21.17l1.17 2.34.45.9-.24.11V28a5 5 0 0 1-2.23 8.94l-.02.06a8 8 0 0 1-7.75 6h-20a8 8 0 0 1-7.74-6l-.02-.06A5 5 0 0 1-17.45 28v-6.76l-.79-1.58-.44-.9.9-.44.63-.32H-20a23.01 23.01 0 0 1 44.37-2zm-36.82 2a1 1 0 0 0-.44.1l-3.1 1.56.89 1.79 1.31-.66a3 3 0 0 1 2.69 0l2.2 1.1a1 1 0 0 0 .9 0l2.21-1.1a3 3 0 0 1 2.69 0l2.2 1.1a1 1 0 0 0 .9 0l2.21-1.1a3 3 0 0 1 2.69 0l2.2 1.1a1 1 0 0 0 .86.02l2.88-1.27a3 3 0 0 1 2.43 0l2.88 1.27a1 1 0 0 0 .85-.02l3.1-1.55-.89-1.79-1.42.71a3 3 0 0 1-2.56.06l-2.77-1.23a1 1 0 0 0-.4-.09h-.01a1 1 0 0 0-.4.09l-2.78 1.23a3 3 0 0 1-2.56-.06l-2.3-1.15a1 1 0 0 0-.45-.11h-.01a1 1 0 0 0-.44.1L.9 19.22a3 3 0 0 1-2.69 0l-2.2-1.1a1 1 0 0 0-.45-.11h-.01a1 1 0 0 0-.44.1l-2.21 1.11a3 3 0 0 1-2.69 0l-2.2-1.1a1 1 0 0 0-.45-.11h-.01zm0-2h-4.9a21.01 21.01 0 0 1 39.61 0h-2.09l-.06-.13-.26.13h-32.31zm30.35 7.68l1.36-.68h1.3v2h-36v-1.15l.34-.17 1.36-.68h2.59l1.36.68a3 3 0 0 0 2.69 0l1.36-.68h2.59l1.36.68a3 3 0 0 0 2.69 0L2.26 23h2.59l1.36.68a3 3 0 0 0 2.56.06l1.67-.74h3.23l1.67.74a3 3 0 0 0 2.56-.06zM-13.82 27l16.37 4.91L18.93 27h-32.75zm-.63 2h.34l16.66 5 16.67-5h.33a3 3 0 1 1 0 6h-34a3 3 0 1 1 0-6zm1.35 8a6 6 0 0 0 5.65 4h20a6 6 0 0 0 5.66-4H-13.1z'/%3E%3Cpath id='path6_fill-copy' d='M284.37 16c.2.65.39 1.32.54 2H281.17l1.17 2.34.45.9-.24.11V28a5 5 0 0 1-2.23 8.94l-.02.06a8 8 0 0 1-7.75 6h-20a8 8 0 0 1-7.74-6l-.02-.06a5 5 0 0 1-2.24-8.94v-6.76l-.79-1.58-.44-.9.9-.44.63-.32H240a23.01 23.01 0 0 1 44.37-2zm-36.82 2a1 1 0 0 0-.44.1l-3.1 1.56.89 1.79 1.31-.66a3 3 0 0 1 2.69 0l2.2 1.1a1 1 0 0 0 .9 0l2.21-1.1a3 3 0 0 1 2.69 0l2.2 1.1a1 1 0 0 0 .9 0l2.21-1.1a3 3 0 0 1 2.69 0l2.2 1.1a1 1 0 0 0 .86.02l2.88-1.27a3 3 0 0 1 2.43 0l2.88 1.27a1 1 0 0 0 .85-.02l3.1-1.55-.89-1.79-1.42.71a3 3 0 0 1-2.56.06l-2.77-1.23a1 1 0 0 0-.4-.09h-.01a1 1 0 0 0-.4.09l-2.78 1.23a3 3 0 0 1-2.56-.06l-2.3-1.15a1 1 0 0 0-.45-.11h-.01a1 1 0 0 0-.44.1l-2.21 1.11a3 3 0 0 1-2.69 0l-2.2-1.1a1 1 0 0 0-.45-.11h-.01a1 1 0 0 0-.44.1l-2.21 1.11a3 3 0 0 1-2.69 0l-2.2-1.1a1 1 0 0 0-.45-.11h-.01zm0-2h-4.9a21.01 21.01 0 0 1 39.61 0h-2.09l-.06-.13-.26.13h-32.31zm30.35 7.68l1.36-.68h1.3v2h-36v-1.15l.34-.17 1.36-.68h2.59l1.36.68a3 3 0 0 0 2.69 0l1.36-.68h2.59l1.36.68a3 3 0 0 0 2.69 0l1.36-.68h2.59l1.36.68a3 3 0 0 0 2.56.06l1.67-.74h3.23l1.67.74a3 3 0 0 0 2.56-.06zM246.18 27l16.37 4.91L278.93 27h-32.75zm-.63 2h.34l16.66 5 16.67-5h.33a3 3 0 1 1 0 6h-34a3 3 0 1 1 0-6zm1.35 8a6 6 0 0 0 5.65 4h20a6 6 0 0 0 5.66-4H246.9z'/%3E%3Cpath d='M159.5 21.02A9 9 0 0 0 151 15h-42a9 9 0 0 0-8.5 6.02 6 6 0 0 0 .02 11.96A8.99 8.99 0 0 0 109 45h42a9 9 0 0 0 8.48-12.02 6 6 0 0 0 .02-11.96zM151 17h-42a7 7 0 0 0-6.33 4h54.66a7 7 0 0 0-6.33-4zm-9.34 26a8.98 8.98 0 0 0 3.34-7h-2a7 7 0 0 1-7 7h-4.34a8.98 8.98 0 0 0 3.34-7h-2a7 7 0 0 1-7 7h-4.34a8.98 8.98 0 0 0 3.34-7h-2a7 7 0 0 1-7 7h-7a7 7 0 1 1 0-14h42a7 7 0 1 1 0 14h-9.34zM109 27a9 9 0 0 0-7.48 4H101a4 4 0 1 1 0-8h58a4 4 0 0 1 0 8h-.52a9 9 0 0 0-7.48-4h-42z'/%3E%3Cpath d='M39 115a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm6-8a6 6 0 1 1-12 0 6 6 0 0 1 12 0zm-3-29v-2h8v-6H40a4 4 0 0 0-4 4v10H22l-1.33 4-.67 2h2.19L26 130h26l3.81-40H58l-.67-2L56 84H42v-6zm-4-4v10h2V74h8v-2h-8a2 2 0 0 0-2 2zm2 12h14.56l.67 2H22.77l.67-2H40zm13.8 4H24.2l3.62 38h22.36l3.62-38z'/%3E%3Cpath d='M129 92h-6v4h-6v4h-6v14h-3l.24 2 3.76 32h36l3.76-32 .24-2h-3v-14h-6v-4h-6v-4h-8zm18 22v-12h-4v4h3v8h1zm-3 0v-6h-4v6h4zm-6 6v-16h-4v19.17c1.6-.7 2.97-1.8 4-3.17zm-6 3.8V100h-4v23.8a10.04 10.04 0 0 0 4 0zm-6-.63V104h-4v16a10.04 10.04 0 0 0 4 3.17zm-6-9.17v-6h-4v6h4zm-6 0v-8h3v-4h-4v12h1zm27-12v-4h-4v4h3v4h1v-4zm-6 0v-8h-4v4h3v4h1zm-6-4v-4h-4v8h1v-4h3zm-6 4v-4h-4v8h1v-4h3zm7 24a12 12 0 0 0 11.83-10h7.92l-3.53 30h-32.44l-3.53-30h7.92A12 12 0 0 0 130 126z'/%3E%3Cpath d='M212 86v2h-4v-2h4zm4 0h-2v2h2v-2zm-20 0v.1a5 5 0 0 0-.56 9.65l.06.25 1.12 4.48a2 2 0 0 0 1.94 1.52h.01l7.02 24.55a2 2 0 0 0 1.92 1.45h4.98a2 2 0 0 0 1.92-1.45l7.02-24.55a2 2 0 0 0 1.95-1.52L224.5 96l.06-.25a5 5 0 0 0-.56-9.65V86a14 14 0 0 0-28 0zm4 0h6v2h-9a3 3 0 1 0 0 6H223a3 3 0 1 0 0-6H220v-2h2a12 12 0 1 0-24 0h2zm-1.44 14l-1-4h24.88l-1 4h-22.88zm8.95 26l-6.86-24h18.7l-6.86 24h-4.98zM150 242a22 22 0 1 0 0-44 22 22 0 0 0 0 44zm24-22a24 24 0 1 1-48 0 24 24 0 0 1 48 0zm-28.38 17.73l2.04-.87a6 6 0 0 1 4.68 0l2.04.87a2 2 0 0 0 2.5-.82l1.14-1.9a6 6 0 0 1 3.79-2.75l2.15-.5a2 2 0 0 0 1.54-2.12l-.19-2.2a6 6 0 0 1 1.45-4.46l1.45-1.67a2 2 0 0 0 0-2.62l-1.45-1.67a6 6 0 0 1-1.45-4.46l.2-2.2a2 2 0 0 0-1.55-2.13l-2.15-.5a6 6 0 0 1-3.8-2.75l-1.13-1.9a2 2 0 0 0-2.5-.8l-2.04.86a6 6 0 0 1-4.68 0l-2.04-.87a2 2 0 0 0-2.5.82l-1.14 1.9a6 6 0 0 1-3.79 2.75l-2.15.5a2 2 0 0 0-1.54 2.12l.19 2.2a6 6 0 0 1-1.45 4.46l-1.45 1.67a2 2 0 0 0 0 2.62l1.45 1.67a6 6 0 0 1 1.45 4.46l-.2 2.2a2 2 0 0 0 1.55 2.13l2.15.5a6 6 0 0 1 3.8 2.75l1.13 1.9a2 2 0 0 0 2.5.8zm2.82.97a4 4 0 0 1 3.12 0l2.04.87a4 4 0 0 0 4.99-1.62l1.14-1.9a4 4 0 0 1 2.53-1.84l2.15-.5a4 4 0 0 0 3.09-4.24l-.2-2.2a4 4 0 0 1 .97-2.98l1.45-1.67a4 4 0 0 0 0-5.24l-1.45-1.67a4 4 0 0 1-.97-2.97l.2-2.2a4 4 0 0 0-3.09-4.25l-2.15-.5a4 4 0 0 1-2.53-1.84l-1.14-1.9a4 4 0 0 0-5-1.62l-2.03.87a4 4 0 0 1-3.12 0l-2.04-.87a4 4 0 0 0-4.99 1.62l-1.14 1.9a4 4 0 0 1-2.53 1.84l-2.15.5a4 4 0 0 0-3.09 4.24l.2 2.2a4 4 0 0 1-.97 2.98l-1.45 1.67a4 4 0 0 0 0 5.24l1.45 1.67a4 4 0 0 1 .97 2.97l-.2 2.2a4 4 0 0 0 3.09 4.25l2.15.5a4 4 0 0 1 2.53 1.84l1.14 1.9a4 4 0 0 0 5 1.62l2.03-.87zM152 207a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm6 2a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm-11 1a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm-6 0a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm3-5a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm-8 8a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm3 6a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm0 6a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm4 7a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm5-2a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm5 4a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm4-6a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm6-4a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm-4-3a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm4-3a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm-5-4a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm-24 6a1 1 0 1 1 2 0 1 1 0 0 1-2 0zm16 5a5 5 0 1 0 0-10 5 5 0 0 0 0 10zm7-5a7 7 0 1 1-14 0 7 7 0 0 1 14 0zm86-29a1 1 0 0 0 0 2h2a1 1 0 0 0 0-2h-2zm19 9a1 1 0 0 1 1-1h2a1 1 0 0 1 0 2h-2a1 1 0 0 1-1-1zm-14 5a1 1 0 0 0 0 2h2a1 1 0 0 0 0-2h-2zm-25 1a1 1 0 0 0 0 2h2a1 1 0 0 0 0-2h-2zm5 4a1 1 0 0 0 0 2h2a1 1 0 0 0 0-2h-2zm9 0a1 1 0 0 1 1-1h2a1 1 0 0 1 0 2h-2a1 1 0 0 1-1-1zm15 1a1 1 0 0 1 1-1h2a1 1 0 0 1 0 2h-2a1 1 0 0 1-1-1zm12-2a1 1 0 0 0 0 2h2a1 1 0 0 0 0-2h-2zm-11-14a1 1 0 0 1 1-1h2a1 1 0 0 1 0 2h-2a1 1 0 0 1-1-1zm-19 0a1 1 0 0 0 0 2h2a1 1 0 0 0 0-2h-2zm6 5a1 1 0 0 1 1-1h2a1 1 0 0 1 0 2h-2a1 1 0 0 1-1-1zm-25 15c0-.47.01-.94.03-1.4a5 5 0 0 1-1.7-8 3.99 3.99 0 0 1 1.88-5.18 5 5 0 0 1 3.4-6.22 3 3 0 0 1 1.46-1.05 5 5 0 0 1 7.76-3.27A30.86 30.86 0 0 1 246 184c6.79 0 13.06 2.18 18.17 5.88a5 5 0 0 1 7.76 3.27 3 3 0 0 1 1.47 1.05 5 5 0 0 1 3.4 6.22 4 4 0 0 1 1.87 5.18 4.98 4.98 0 0 1-1.7 8c.02.46.03.93.03 1.4v1h-62v-1zm.83-7.17a30.9 30.9 0 0 0-.62 3.57 3 3 0 0 1-.61-4.2c.37.28.78.49 1.23.63zm1.49-4.61c-.36.87-.68 1.76-.96 2.68a2 2 0 0 1-.21-3.71c.33.4.73.75 1.17 1.03zm2.32-4.54c-.54.86-1.03 1.76-1.49 2.68a3 3 0 0 1-.07-4.67 3 3 0 0 0 1.56 1.99zm1.14-1.7c.35-.5.72-.98 1.1-1.46a1 1 0 1 0-1.1 1.45zm5.34-5.77c-1.03.86-2 1.79-2.9 2.77a3 3 0 0 0-1.11-.77 3 3 0 0 1 4-2zm42.66 2.77c-.9-.98-1.87-1.9-2.9-2.77a3 3 0 0 1 4.01 2 3 3 0 0 0-1.1.77zm1.34 1.54c.38.48.75.96 1.1 1.45a1 1 0 1 0-1.1-1.45zm3.73 5.84c-.46-.92-.95-1.82-1.5-2.68a3 3 0 0 0 1.57-1.99 3 3 0 0 1-.07 4.67zm1.8 4.53c-.29-.9-.6-1.8-.97-2.67.44-.28.84-.63 1.17-1.03a2 2 0 0 1-.2 3.7zm1.14 5.51c-.14-1.21-.35-2.4-.62-3.57.45-.14.86-.35 1.23-.63a2.99 2.99 0 0 1-.6 4.2zM275 214a29 29 0 0 0-57.97 0h57.96zM72.33 198.12c-.21-.32-.34-.7-.34-1.12v-12h-2v12a4.01 4.01 0 0 0 7.09 2.54c.57-.69.91-1.57.91-2.54v-12h-2v12a1.99 1.99 0 0 1-2 2 2 2 0 0 1-1.66-.88zM75 176c.38 0 .74-.04 1.1-.12a4 4 0 0 0 6.19 2.4A13.94 13.94 0 0 1 84 185v24a6 6 0 0 1-6 6h-3v9a5 5 0 1 1-10 0v-9h-3a6 6 0 0 1-6-6v-24a14 14 0 0 1 14-14 5 5 0 0 0 5 5zm-17 15v12a1.99 1.99 0 0 0 1.22 1.84 2 2 0 0 0 2.44-.72c.21-.32.34-.7.34-1.12v-12h2v12a3.98 3.98 0 0 1-5.35 3.77 3.98 3.98 0 0 1-.65-.3V209a4 4 0 0 0 4 4h16a4 4 0 0 0 4-4v-24c.01-1.53-.23-2.88-.72-4.17-.43.1-.87.16-1.28.17a6 6 0 0 1-5.2-3 7 7 0 0 1-6.47-4.88A12 12 0 0 0 58 185v6zm9 24v9a3 3 0 1 0 6 0v-9h-6z'/%3E%3Cpath d='M-17 191a1 1 0 0 0 0 2h2a1 1 0 0 0 0-2h-2zm19 9a1 1 0 0 1 1-1h2a1 1 0 0 1 0 2H3a1 1 0 0 1-1-1zm-14 5a1 1 0 0 0 0 2h2a1 1 0 0 0 0-2h-2zm-25 1a1 1 0 0 0 0 2h2a1 1 0 0 0 0-2h-2zm5 4a1 1 0 0 0 0 2h2a1 1 0 0 0 0-2h-2zm9 0a1 1 0 0 1 1-1h2a1 1 0 0 1 0 2h-2a1 1 0 0 1-1-1zm15 1a1 1 0 0 1 1-1h2a1 1 0 0 1 0 2h-2a1 1 0 0 1-1-1zm12-2a1 1 0 0 0 0 2h2a1 1 0 0 0 0-2H4zm-11-14a1 1 0 0 1 1-1h2a1 1 0 0 1 0 2h-2a1 1 0 0 1-1-1zm-19 0a1 1 0 0 0 0 2h2a1 1 0 0 0 0-2h-2zm6 5a1 1 0 0 1 1-1h2a1 1 0 0 1 0 2h-2a1 1 0 0 1-1-1zm-25 15c0-.47.01-.94.03-1.4a5 5 0 0 1-1.7-8 3.99 3.99 0 0 1 1.88-5.18 5 5 0 0 1 3.4-6.22 3 3 0 0 1 1.46-1.05 5 5 0 0 1 7.76-3.27A30.86 30.86 0 0 1-14 184c6.79 0 13.06 2.18 18.17 5.88a5 5 0 0 1 7.76 3.27 3 3 0 0 1 1.47 1.05 5 5 0 0 1 3.4 6.22 4 4 0 0 1 1.87 5.18 4.98 4.98 0 0 1-1.7 8c.02.46.03.93.03 1.4v1h-62v-1zm.83-7.17a30.9 30.9 0 0 0-.62 3.57 3 3 0 0 1-.61-4.2c.37.28.78.49 1.23.63zm1.49-4.61c-.36.87-.68 1.76-.96 2.68a2 2 0 0 1-.21-3.71c.33.4.73.75 1.17 1.03zm2.32-4.54c-.54.86-1.03 1.76-1.49 2.68a3 3 0 0 1-.07-4.67 3 3 0 0 0 1.56 1.99zm1.14-1.7c.35-.5.72-.98 1.1-1.46a1 1 0 1 0-1.1 1.45zm5.34-5.77c-1.03.86-2 1.79-2.9 2.77a3 3 0 0 0-1.11-.77 3 3 0 0 1 4-2zm42.66 2.77c-.9-.98-1.87-1.9-2.9-2.77a3 3 0 0 1 4.01 2 3 3 0 0 0-1.1.77zm1.34 1.54c.38.48.75.96 1.1 1.45a1 1 0 1 0-1.1-1.45zm3.73 5.84c-.46-.92-.95-1.82-1.5-2.68a3 3 0 0 0 1.57-1.99 3 3 0 0 1-.07 4.67zm1.8 4.53c-.29-.9-.6-1.8-.97-2.67.44-.28.84-.63 1.17-1.03a2 2 0 0 1-.2 3.7zm1.14 5.51c-.14-1.21-.35-2.4-.62-3.57.45-.14.86-.35 1.23-.63a2.99 2.99 0 0 1-.6 4.2zM15 214a29 29 0 0 0-57.97 0h57.96z'/%3E%3C/g%3E%3C/g%3E%3C/svg%3E\") !important; } .meta-secondline { display:none; }"},{"title":"友情链接","date":"2022-06-07T22:17:49.000Z","updated":"2025-01-21T05:49:52.465Z","comments":true,"path":"link/index.html","permalink":"https://acchw.top/link/index.html","excerpt":"","text":""},{"title":"标签","date":"2025-01-21T05:49:52.465Z","updated":"2025-01-21T05:49:52.465Z","comments":false,"path":"tags/index.html","permalink":"https://acchw.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Android应用在上架Google Play时封闭式测试的一些建议","slug":"编程/other/Android应用在上架Google Play时封闭式测试的一些建议","date":"2025-01-09T00:00:00.000Z","updated":"2025-01-09T00:00:00.000Z","comments":true,"path":"posts/40888/","link":"","permalink":"https://acchw.top/posts/40888/","excerpt":"","text":"最近上架了一个自己写的App到Google Play上，其中的封闭式测试这一环节卡了很久，现在将其中的一些注意事项记录一下，方便后来人看到。当然，这个只适用于那些没有自己的测试渠道，和我一样，单纯只有自己一个人的情况下，怎样通过封闭式测试。 因为我是第一次弄这个，前后经过了二次被拒，第三次才成功通过。 这是我第一次申请失败的截图。 Google Play对新注册的账号，如果需要发布应用，必须要有封闭式测试，且要求连续14天有20个人参与测试。 对于我这种没有自己测试渠道和测试人员的开发者，目前来看，成功率最高的是通过在reddit上发布帖子或者在别人发布的此类帖子下回帖，如此找到20个人参与测试，其中https://www.reddit.com/r/AndroidClosedTesting 这个板块热度较高，相对而言更容易。 首先是找人，可以在刚开始的前2天自己发帖或者回帖，凑齐20个人（可以多一点，因为中途可能会有人卸载），然后在之后的每天内都可以继续找人，还是为了防止中间有人卸载，不过之后的话就不用那么多了，每天找到几个就OK了。 还有一条是在这期间，可以发布几个版本，让Google认为你确实通过测试发现了一些问题并进行了修复，这在最后的调查问卷中可以填上去。 最后一条，对于别人发表的评价，要积极回复，也能够增加通过概率。 如果大家还有其他什么渠道或方法，也可以留言讨论。","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"other","slug":"编程/other","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/other/"}],"tags":[{"name":"海外","slug":"海外","permalink":"https://acchw.top/tags/%E6%B5%B7%E5%A4%96/"},{"name":"Google Play","slug":"Google-Play","permalink":"https://acchw.top/tags/Google-Play/"},{"name":"Android","slug":"Android","permalink":"https://acchw.top/tags/Android/"},{"name":"封闭式测试","slug":"封闭式测试","permalink":"https://acchw.top/tags/%E5%B0%81%E9%97%AD%E5%BC%8F%E6%B5%8B%E8%AF%95/"}]},{"title":"JVM中的Shallow Size 和 Retained Size解释","slug":"编程/java/JVM中的Shallow Size 和 Retained Size解释","date":"2024-09-27T00:00:00.000Z","updated":"2024-09-27T00:00:00.000Z","comments":true,"path":"posts/25621/","link":"","permalink":"https://acchw.top/posts/25621/","excerpt":"","text":"在使用相关的JVM内存工具查看堆栈情况时， 有两个指标Shallow Size和Shallow Size不是很清楚其真正含义，现在通过一个例子来了解其含义。 先说一下概念描述： shallow size: 对象自身占用的内存, 不包括它引用的其他实例。例如，对于一个简单的对象，如果它有几个基本数据类型的字段和对其他对象的引用，那么该值只计算这些字段所占的空间，而不计算被引用对象的空间 retained size: 当实例A被回收时, 可以同时被回收的实例的Shallow Size之和 示例代码很简答， 构造一个List，然后插入100万个元素， 在程序运行的过程中使用IDEA自带的Profiler来获取堆栈快照，后面的一个无限循环是为了防止程序运行完终止。 12345678910public static void main(String[] args) throws Exception &#123; List&lt;Integer&gt; l = new ArrayList&lt;&gt;(); for (int i=0; i &lt; 1000000; i++)&#123; l.add(i); &#125; while (true)&#123; TimeUnit.SECONDS.sleep(3); System.out.println(&quot;sdsdsds&quot;); &#125; &#125; 结果如下图所示： 可以看到，List实例的shallow size很小，因为其代表本身这个List对象占用的内存，不包含其引用的100万的Integer对象， 而retained size很大，接近29M。 在此处， 想验证一下long类型和int类型各自占用的空间占用区别有多大。 将Integer改成了Long, 其他不变，观察retained size，接近33M，和int的差距不是很大。","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"java","slug":"编程/java","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://acchw.top/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"https://acchw.top/tags/jvm/"}]},{"title":"acme.sh自动生成泛域名证书的几个坑","slug":"编程/other/acme.sh使用namesilo生成域名证书的几个坑","date":"2024-05-20T00:00:00.000Z","updated":"2024-05-20T00:00:00.000Z","comments":true,"path":"posts/16115/","link":"","permalink":"https://acchw.top/posts/16115/","excerpt":"","text":"先说一下我的环境与配置： 域名：在namesilo上购买的 证书使用方式：nginx nginx部署方式：docker 说一下在使用过程中可能会遇到的一些坑， 方便后来人正确处理。 安装脚本过程安装acme.sh前要将系统用户切换到和nginx服务使用的用户， 否则之后的relaod命令将没有权限执行。 比如我使用root用户安装的docker启动nginx, 就切换到root，并在此用户下安装acme.sh 生成证书过程此处使用的是dns的api方式来验证，有几个点需要注意。 生成api key的时候，Generate key for read-only access 一定不要勾选 如果第一次没有注意勾选，并且使用脚本生成证书（不管是否生成失败），在新生成key之后， 需要先将.acme.sh account.conf Namesilo_Key 删除掉","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"other","slug":"编程/other","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/other/"}],"tags":[{"name":"acme.sh","slug":"acme-sh","permalink":"https://acchw.top/tags/acme-sh/"},{"name":"证书","slug":"证书","permalink":"https://acchw.top/tags/%E8%AF%81%E4%B9%A6/"},{"name":"namesilo","slug":"namesilo","permalink":"https://acchw.top/tags/namesilo/"}]},{"title":"老了","slug":"生活/老了","date":"2024-03-31T00:00:00.000Z","updated":"2024-03-31T00:00:00.000Z","comments":true,"path":"posts/16268/","link":"","permalink":"https://acchw.top/posts/16268/","excerpt":"","text":"今天在公交上，一个应该是初中或高中的学生，让我帮忙弄一下行李箱，叫我 “叔叔”， 这好像是我印象中第一次有陌生人叫我这个称呼，看来是真老了。 但我的人生还有许多事没做，必须加紧步伐，把有限的时间花费在更有意义的事情上。 同时， 更重要的一点是身体，要加强锻炼，才能更好的应付之后可能发生的事。 希望今年心想事成，最重要的结婚和工作的事都能如意。","categories":[{"name":"生活","slug":"生活","permalink":"https://acchw.top/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://acchw.top/tags/%E7%94%9F%E6%B4%BB/"}]},{"title":"go学习笔记之指针","slug":"编程/go/go学习笔记之指针","date":"2024-03-07T22:00:00.000Z","updated":"2024-03-07T22:00:00.000Z","comments":true,"path":"posts/13710/","link":"","permalink":"https://acchw.top/posts/13710/","excerpt":"","text":"什么是指针 一个变量，指向了另外一个变量的内存地址。 指针变量通常用于引用其他变量的内存地址，以便能够直接访问或修改该变量的值。 指针用法 * 声明变量类型为指针；或者使用指针访问变量的值 &amp; 指针指向的内存地址， 也是将一个普通变量赋值给一个指针变量的方式 1234567891011121314151617181920212223package mainimport &quot;fmt&quot;func main() &#123; var a int= 20 /* 声明实际变量 */ var ip *int /* 声明指针变量 */ ip = &amp;a /* 指针变量的存储地址 */ fmt.Printf(&quot;a 变量的地址是: %x\\n&quot;, &amp;a ) /* 指针变量的存储地址 */ fmt.Printf(&quot;ip 变量储存的指针地址: %x\\n&quot;, ip ) /* 使用指针访问值 */ fmt.Printf(&quot;*ip 变量的值: %d\\n&quot;, *ip )&#125;// 输出结果a 变量的地址是: 20818a220ip 变量储存的指针地址: 20818a220*ip 变量的值: 20 什么时候适合用指针 如果需要修改外部变量的值，我们需要使用指针 不需要对map，slice等引用类型使用指针，因为他们本身就是一个指针 如果有超级大的结构体需要作为函数的参数，使用指针可以节省内存开销 因为指针可以修改其指向数据的值，所以最好不要随意在并发场景下使用 最好不要嵌套使用指针，比如b :&#x3D; &amp;a, c :&#x3D; &amp;b，这样代码会比较复杂难懂 对于一些特殊场景，比如接口传参，假如参数类型是布尔类型，因为go中变量必定会存在一个默认值，对于布尔类型是false， 如果不想有默认值，可以将这个参数设置为布尔类型的指针 总结 指针也是变量，只不过存储的是地址 通过指针可以去修改其指向数据的值 指针可以帮助我们在任何地方修改其所指向数据的值 传递指针参数可以节省拷贝大结构体的内存开销","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"go","slug":"编程/go","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/go/"}],"tags":[{"name":"go","slug":"go","permalink":"https://acchw.top/tags/go/"}]},{"title":"pve主机使用smart_ctl监控磁盘信息","slug":"折腾/监控/pve主机使用smart_ctl监控磁盘信息","date":"2024-01-30T10:10:00.000Z","updated":"2024-01-30T10:10:00.000Z","comments":true,"path":"posts/3239/","link":"","permalink":"https://acchw.top/posts/3239/","excerpt":"","text":"pve中一块nvme磁盘最近偶尔会报温度过高， 所以需要加个监控， 之前已经装过node_expoter, 但是其磁盘硬件监控这一块的信息不够全面，其更多强调的是磁盘的性能，比如IO等。 温度监控这一块也有， 但是不够直观明显，而且缺少其他的一些磁盘硬件本身的信息， 下图是node_exporter监控硬件温度，在Hardware Misc里的Hardware temperature monitor中的显示信息： 基于此， 需要一个专门用来收集磁盘硬件本身信息的exporter, prometheus提供了一个基于smart ctl的exporter, 地址是https://github.com/prometheus-community/smartctl_exporter 因为这是直接监控硬件的， 所以我是直接安装在宿主机上的（包括之前的node_exporter)， 没有安装在虚拟机上。 smartctl _exporter安装 进入 https://github.com/prometheus-community/smartctl_exporter/releases下载自己机器需要的版本, 此处以0.11.0版本为例， 登录宿主机执行命令： 1wget https://github.com/prometheus-community/smartctl_exporter/releases/download/v0.11.0/smartctl_exporter-0.11.0.linux-amd64.tar.gz 解压 tar -xzf smartctl_exporter-0.11.0.linux-amd64.tar.gz 移动 cp smartctl_exporter /usr/bin 此时执行 smartctl_exporter命令， 如果有正确输出，则表示安装成功 设置开启自启 在 /etc/systemd/system 下新建一个配置文件 smartctl_exporter.service，内容如下： 1234567891011[Unit]Description=AutoStart smartctl_exporterAfter=network.target[Service]ExecStart=/usr/bin/smartctl_exporterRemainAfterExit=yesRestart=on-failure[Install]WantedBy=multi-user.target 执行命令： 12systemctl enable smartctl_exporter.servicesystemctl start smartctl_exporter.service prometheus与grafana设置 prometheus的配置文件加上smart_ctl的监控（默认的端口是9633）， 配置如下： 123- job_name: &#x27;pve-smart-ctl-exporter&#x27; static_configs: - targets: [&#x27;主机IP:9633&#x27;] grafana导入模板， 模板ID为20204, 效果如下 至此， 大功告成。","categories":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"监控","slug":"折腾/监控","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/tags/%E6%8A%98%E8%85%BE/"},{"name":"linux","slug":"linux","permalink":"https://acchw.top/tags/linux/"},{"name":"监控","slug":"监控","permalink":"https://acchw.top/tags/%E7%9B%91%E6%8E%A7/"},{"name":"prometheus","slug":"prometheus","permalink":"https://acchw.top/tags/prometheus/"}]},{"title":"tailscale的设置与安装","slug":"折腾/其他/tailscale的设置与安装","date":"2024-01-18T00:00:00.000Z","updated":"2024-01-21T00:00:00.000Z","comments":true,"path":"posts/3940/","link":"","permalink":"https://acchw.top/posts/3940/","excerpt":"","text":"先说一下整体的环境和安装方式 pve虚拟机专门开了一个lxc容器，用于安装tailscale，并利用此容器转发流量到局域网内的其他机器上，实现外部访问内网所有机器 由于tailscale本身的中转服务器derp没有中国的节点，最近的节点是位于东京的，所以此处选择自己搭建一个中继节点 PVE LXC安装tailscale此处的lxc模板使用的是Debian 11(bullseye)。 创建一个非特权的CT容器， 模板选择Debian 11(bullseye)，其他配置都使用默认配置（网络那儿最好选择DHCP，让路由器自动分配一个IP） 安装完成后， 先不要启动，需要修改一些配置 在pve宿主机中，获取信息， 执行命令和返回结果如下, 记录 10, 200 这两个数字, 后面需要用到 12root@pve:~# ls -al /dev/net/tuncrw-rw-rw- 1 root root 10, 200 Jun 30 23:08 /dev/net/tun 在pve宿主机中，修改 /etc/pve/lxc/CTID.conf文件， 新增如下两行：其中10和200是上一步中获取到的值 12lxc.cgroup2.devices.allow: c 10:200 rwmlxc.mount.entry: /dev/net/tun dev/net/tun none bind,create=file 上述配置完成后， 启动容器，在容器内安装tailscale, 安装文档：https://tailscale.com/kb/1038/install-debian-bullseye， 安装完成后先不要启动tailscale 开启lxc的转发功能，进入lxc容器， 修改/etc/sysctl.conf配置文件（一般是有的，将注释去掉就行），修改为如下两行： 12net.ipv4.ip_forward=1net.ipv6.conf.all.forwarding=1 修改完成后， 使其生效， 执行命令：sysctl -p /etc/sysctl.conf 启动tailscale， 因为此处是要使用此容器作为转发， 所以需要加上advertise-routes参数， 假设tailscale容器的IP为10.0.0.23， 要转发的网络段为 10.0.0.0&#x2F;24， 则使用如下命令启动: 12# 此处使用的authKey来启动， 也可以不使用这个，具体方法参见tailscale文档tailscale up --authkey=xxxxx --accept-routes --advertise-routes=10.0.0.0/24 上一步使用的authKey是在tailscale的web管理端生成的，具体位置见下图： 当tailsale成功连接之后， 登录web端，在对应设备上点击 Edit route setting， 在弹出框中将subnet routes勾选上，并保存， 至此， 当其他设备连接上tailscale之后，就可以直接通过10.0.0.X的IP直接访问和lxc容器属于同一网段的其他设备。 lxc设置tailscale开启自启 以下操作都是在lxc容器内部进行的。 此处使用systemd设置开机自启。在/etc/systemd/system下新建一个配置文件: tailscale.service, 文件内容如下： 123456789101112 [Unit]Description=AutoStart tailscale After=tailscale.serviceRequires=tailscale.service [Service] Type=oneshot ExecStart=/usr/bin/tailscale up --authkey=你的authKey --accept-routes --advertise-routes=你的转发范围 ExecStop=/usr/bin/tailscale down RemainAfterExit=yes Restart=on-failure [Install] WantedBy=multi-user.target 然后执行如下命令： 12systemctl enable tailscale.servicesystemctl start tailscale.service 使用自定义中继服务器Derp前提条件： 公网VPS：配置不用太高，阿里云的最低配置就行 VPS开通端口8082和3478：我此处指定了derp的端口为8082， 你也可以指定其他端口 域名 域名对应的https证书： 我此处使用的是阿里云的免费证书 此处为了方便，使用docker部署derp。 在和docker-compose.yml文件的相同目录下，创建certs目录， 并将证书文件放入此目录中。 docker-compose.yml文件如下： 123456789101112131415version: &quot;3.9&quot;services: derper: image: fredliang/derper container_name: derper volumes: - ./config/certs:/app/certs ports: - 8082:8082 - 3478:3478/udp environment: - DERP_DOMAIN=你的域名 - DERP_CERT_MODE=manual - DERP_ADDR=:8082 # 自定义的端口，也可以换成其他 - DERP_HTTP_PORT=-1 然后启动，docker-compose up -d tailscale配置 登录tailscale的web控制台， 在Access Controls选项卡下，编辑配置文件， 在配置文件加上如下一段： 123456789101112131415161718// 自定义的中继derp&quot;derpMap&quot;: &#123; &quot;Regions&quot;: &#123; &quot;900&quot;: &#123; &quot;RegionID&quot;: 900, &quot;RegionCode&quot;: &quot;随便填一个有标识性的即可&quot;, &quot;RegionName&quot;: &quot;随便填一个有标识性的即可&quot;, &quot;Nodes&quot;: [ &#123; &quot;Name&quot;: &quot;随便填一个有标识性的即可&quot;, &quot;RegionID&quot;: 900, &quot;HostName&quot;: &quot;你的域名&quot;, &quot;StunPort&quot;: 3478, &quot;DerpPort&quot;: 8082, //之前配的端口 &#125;, ], &#125;, &#125;, 具体加的位置如图所示： 验证是否生效：随便在一个已经连接上tailscale的机器上， 执行 tailscale netcheck，看到的中继列表里如果有你刚加的， 那就说明成功了。","categories":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"其他","slug":"折腾/其他","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"tailscale","slug":"tailscale","permalink":"https://acchw.top/tags/tailscale/"},{"name":"pve","slug":"pve","permalink":"https://acchw.top/tags/pve/"}]},{"title":"go中获取某个包下定义的所有变量","slug":"编程/go/go中获取某个包下定义的所有变量","date":"2024-01-11T23:10:00.000Z","updated":"2024-01-11T23:10:00.000Z","comments":true,"path":"posts/50851/","link":"","permalink":"https://acchw.top/posts/50851/","excerpt":"","text":"有这样一个场景， 我们在e这个包下， 有一个err_code.go文件，在其中自定义了一个错误码结构体和一些错误码，内容如下: 1234567891011package etype ErrCode struct &#123; Code int Msg string&#125;var ( Success = ErrCode&#123;Code: 10000, Msg: &quot;&quot;&#125; UnknownErr = ErrCode&#123;Code: 10001, Msg: &quot;未知错误&quot;&#125; InvalidParams = ErrCode&#123;Code: 10002, Msg: &quot;参数不合法&quot;&#125;) 现在我们想获取到所有这些预先定义的错误码的code，应该如何做呢？ 可以借助go标准库中AST语法树的能力遍历所有变量，然后过滤得到我们想要的变量类型， 具体代码如下： 12345678910111213141516171819202122232425262728293031323334func Test_IntlDictMatchErrCodeEnum(t *testing.T) &#123; fset := token.NewFileSet() // 此处填写错误码所处包的相对路径 pkgs, err := parser.ParseDir(fset, &quot;../pkg/e&quot;, nil, parser.ParseComments) if err != nil &#123; log.Fatal(err) &#125; // 此处填写实际包的名字 pkg := pkgs[&quot;e&quot;] // 遍历文件 for _, file := range pkg.Files &#123; // 遍历文件的声明 for _, decl := range file.Decls &#123; // 检查声明是否是变量声明 if genDecl, ok := decl.(*ast.GenDecl); ok &amp;&amp; genDecl.Tok == token.VAR &#123; // 遍历变量声明的规范 for _, spec := range genDecl.Specs &#123; if valueSpec, ok := spec.(*ast.ValueSpec); ok &#123; codeElt := valueSpec.Values[0] if y, ok := codeElt.(*ast.CompositeLit); ok &#123; if j, ok := y.Elts[0].(*ast.KeyValueExpr); ok &#123; if l, ok := j.Value.(*ast.BasicLit); ok &#123; // 此处能获取到错误码对应的Code fmt.Printf(&quot;code:%s\\n&quot;, l.Value) &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"go","slug":"编程/go","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/go/"}],"tags":[{"name":"go","slug":"go","permalink":"https://acchw.top/tags/go/"}]},{"title":"mysql是如何解决不可重复读和幻读的","slug":"编程/mysql/mysql是如何解决不可重复读和幻读的","date":"2023-09-11T00:00:00.000Z","updated":"2023-09-11T00:00:00.000Z","comments":true,"path":"posts/21511/","link":"","permalink":"https://acchw.top/posts/21511/","excerpt":"","text":"Mysql的默认隔离级别是可重复读。并且在该级别下， 也不会出现幻读（一般意义上的可重复读是存在幻读的）， 那么Mysql是如何实现的呢？ 不可重复读的解决方案 不可重复读定义：在同一个事务中， 前后两次相同的查询， 返回的结果不一样， 针对的是 update 的操作 结论：通过使用MVCC实现不可重复读。 每个事务在开始的时候， 都会创建一个递增的当前事务版本号。 mysql中每条记录都有两个隐藏字段：创建版本号create_version和删除版本号delete_version。 当记录被insert的时候， 创建版本号就是当前事务的版本号， 删除版本号为null 当记录被delete的时候， 将删除版本号设置为当前事务的版本号 当记录被update的时候， 先进行delete，然后再进行add 对于update的操作， 举例说明一下， 假设刚开始的表数据如下： id name create_version delete_version 1 小明 1 NULL 2 小红 3 NULL 现在要执行如下sql， 假设执行此sql的事务版本号为10: update person set name=&#39;李梅&#39; where id =1 执行完毕之后表中数据如下： id name create_version delete_version 1 小明 1 10 2 小红 3 NULL 1 李梅 10 NULL 查询的时候需要满足以下两个条件： 当前事务的版本号需要 大于或等于创建版本号create_version 当前事务的版本号需要小于删除的版本号delete_version，或者当前删除版本号delete_version为NULL 这样， 就能阻止在同一个事务中读取到其他事务提交的数据， 从而实现了可重复读。 根据上述结论， 如果执行 select * from person where id=1的查询， 假设开启此查询的事务版本号是11， 此时得到的结果如下： id name create_version delete_version 1 李梅 10 NULL 幻读的解决方案 幻读定义： 在同一个事务中，前后两次相同的查询， 返回的结果不一样， 针对的是 insert 和 delete 的操作。 结论： 对于快照读， MVCC就能实现 对于当前读， 是利用锁来实现的 首先说一下两种读的区别： 快照读： 事务开始的时候，生成一个快照， 之后的数据都是从这个快照中读取。 普通的select语句就是快照读。 当前读：读取数据的最新版本。insert、update、delete、select..for update 都是当前读。 由于快照读取的永远是事务刚开始的快照数据， 所以即使有其他事务进行了删除或新增操作，该事务也读取不到，所以天然的解决了幻读。 对于当前读， 首先要明白一个概念， 锁。 mysql 什么时候会加锁？ 在进行insert、update、delete、select…for update操作。 需要注意的是，此处的锁指的是行锁， 都是针对索引进行加锁的， 如果没有索引，那么加的就是表锁， 锁住的是整个表。 mysql的行锁分为如下三种： 记录锁 record lock: 只针对唯一索引或主键索引， 锁住的是单条记录 间隙锁 gap lock: 只针对非唯一索引，锁住的是一个区间， 但并不包含该记录本身 临键锁 next key lock: 只针对唯一索引，可以理解为是行锁+间隙锁， 锁住一个区间和记录本身， 整体区间范围 左开右闭 当事务进行当前读的时候， 使用间隙锁或临键锁，锁住一个区间，这样当其他事务在这个区间内进行删除或新增操作的时候，就只能阻塞，需要等待当前事务释放这个锁。 从而保证前后两次读取到的数据一致。","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"mysql","slug":"编程/mysql","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://acchw.top/tags/mysql/"}]},{"title":"一致性哈希算法解读","slug":"编程/分布式/一致性哈希算法解读","date":"2023-06-11T00:00:00.000Z","updated":"2023-09-11T00:00:00.000Z","comments":true,"path":"posts/35513/","link":"","permalink":"https://acchw.top/posts/35513/","excerpt":"","text":"首先理解一下哈希函数的意思。 哈希函数 将任意长度的数据映射到有限长度的域上。 本质是对一段数据m进行杂糅，然后输出另一段固定长度的数据h，并将这个h作为这段数据的特征值。 基本原理就是将数据块m分成多段，每一段长度固定（如128位），若某段长度不足，则进行补位（如0或者1），然后对每一块都进行hash运算，再将这些数据进行迭代（比如相邻两段进行异或），最终得到一个数据。 普通哈希取模先来看一下普通哈希取模是什么样的？ 1c = hash(key) % n 其中n为节点数目，计算得到的c为对应的节点编号。 假设现在总共有A，B，C三台服务器节点， 现在对某个key值哈希之后得到的值为5， 则c &#x3D; 5 % 4 &#x3D; 1, 表示该值存储在B节点上。 现在若需要增加一台服务器节点D，则此时c&#x3D;5 % 5 &#x3D; 0，表明该值存储在A服务器上，前后就会出现不一致。 这样当出现服务器新增、删除、宕机的时候，这样就会请求后端数据库，造成缓存穿透。因此普通的哈希取模定位key所在的服务器的方法会有问题。 综上， 普通哈希最大的缺点就是在扩容或缩容的时候， 会造成key定位的失效。 一致性哈希一致性哈希算法不是对服务器数目取模，而是对2^32进行取模。 将2^32个数组织成一个圆环，从0到2^32-1， 整个空间按照顺时针方向组织，圆环的正上方的数是0， 0 点右侧的第一个数是1， 左侧的第一个数是2^32-1, 这样就组成一个hash环。 现在假设有四台服务器1，2，3，4，利用哈希算法计算出这四台服务器的哈希值（具体可以是服务器的IP等），其在圆环上的分布如图所示，同时假设有三个key，其代号分别是A、B、 C，计算其哈希之后得到的值在圆环的分布如图所示。 根据哈希环的规定，确定一个值在哪个服务器上存储，只需要从该key在哈希环的位置开始，按照顺时针方向找到的第一个服务器节点，就是该key存储的服务器。如下图所示，A存储在节点1上，B存储在节点2上，C存储在节点3上。 综上， 一致性哈希需要计算2次哈希值： 计算存储节点的哈希值，确定存储节点在环上的位置 计算key的哈希值， 确定key在环上的位置 可以看到当节点3宕机的时候，对A、B无影响，只有C定位到节点4上，也就是说，当某个节点出现故障或者新增节点时，受影响的数据仅仅是此节点到其环空间中上一个节点的数据，其他的不会受到影响。故数据影响范围较小。 虚拟节点这里有一个问题需要注意，当节点数量较少时，可能会导致环上节点分布不均匀，导致大部分数据会落在某一个或者某几个节点上。 为了保证数据能够均匀分布，一致性哈希算法引入了虚拟节点的概念，即对某一个实体节点计算多个哈希，每个计算结果都占据环上一个位置。 具体做法可以在服务器IP上增加编号来实现。在实际环境中，通常将每个实体节点设置32个虚拟节点甚至更大，保证数据均匀分布。","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"分布式","slug":"编程/分布式","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://acchw.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"分布式","slug":"分布式","permalink":"https://acchw.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"mysql事务详解","slug":"编程/mysql/mysql事务详解","date":"2023-05-29T00:00:00.000Z","updated":"2023-05-29T00:00:00.000Z","comments":true,"path":"posts/42346/","link":"","permalink":"https://acchw.top/posts/42346/","excerpt":"","text":"以下都是针对InnoDb引擎， 描述的都是单机事务，说明一下个人对事务的一些理解。 事务的四大特性这四个特性并不是平级的关系。准确的说， 一致性是最基本的属性，其他的属性都是为了保证一致性而存在的。 Atomicity 原子性 整个事务是一个整体，是程序运行时不可分割的最小工作单位。 一个事务中的所有操作要么全部执行成功，要么全部都不执行。任何一条语句执行失败，都会导致事务回滚。 实现方式：undo log，当执行失败的时候，使用undo log进行回滚。 Isolation 隔离性 一个事务所做的修改在该事务未提交之前，对其他事务不可见。 为什么会出现隔离性的需求？ 本质是因为并发， 试想一下， 如果没有并发，所有事务都是串行执行的，那么也就不会存在隔离性的问题了。所以mysql提出了隔离级别的概念， 针对不同的隔离级别，进行不同的处理， 这在下文的隔离级别会有详细描述。 那么， 如何解决并发造成的数据一致性问题？ 第一个想法自然是加锁，给数据加锁，相当于让各个事务串行执行，自然就不存在数据一致性的问题了。同时为了提高加锁的效率和粒度，mysql针对锁提出了不同的类别，比如间隙锁、排他锁等。 加锁会造成一个比较大的问题， 就是并发效率不高，即使在锁上面进行优化， 也只能治标不治本，所以要寻找一种不加锁的方式， 答案就是数据冗余， mysql基于此实现了mvcc(多版本并发控制)， 下文会有详细描述。 实现方式：锁和mvcc Durability 持久性 数据一旦提交，结果就是永久性的，并不因为宕机、重启等情况丢失。 一般理解就是写入硬盘保存成功。 实现方式：redo log。数据写入磁盘是通过redo log进行的， redo log存储的是对于每个页修改的物理描述。 Consistency 一致性 数据库的记录总是从一个一致性状态转变成另一个一致性状态。 这里的一致性是语义上的一致性, 并不是语法上的一致性， 可以理解为需要达到用户期望的状态。 比如经典的银行转账例子，若A转账200给B，则需要执行如下三步： 检查A账户余额是否大于200 从A账户减去200 将B账户增加200 用户期望的状态就是A减去200，同时B增加200。 在事务的概念中，以上三个步骤必须处于同一个事务中，若不是处于同一事务中，当程序执行到3的时候系统异常了，就会导致用户的钱被扣。在真正的银行事务中，不仅需要强事务来保证一致性，而且会有一个日终对账系统，来计算每天所有的资金流向，保证整个资金流动值为0。 实现方式：通过回滚，恢复以及并发情况下的隔离从而实现的一致性，可以理解为其他三个特性是为了保持一致性。 事务的隔离级别首先介绍一下关于数据不一致的几个概念： 脏读：事务A读到了事务B未提交的数据， 此时事务A读到的数据就是一个脏数据 不可重复读：在同一个事务中， 前后两次相同的查询， 返回的结果不一样， 针对的是update的操作 幻读： 在同一个事务中，前后两次相同的查询， 返回的结果不一样， 针对的是insert和delete的操作 隔离级别总共分为四大类（注意与上面数据不一致类型的区分）： 未提交读 提交读 可重复读 串行读 针对每个隔离级别是否会出现脏读、不可重复读、幻读的情况如下： 隔离级别 脏读 不可重复读 幻读 未提交读 可能 可能 可能 提交读 不可能 可能 可能 可重复读 不可能 不可能 可能 串行读 不可能 不可能 不可能 未提交读 Read Uncommited 一个事务所做的修改在该事务未提交前对其他事务可见。 造成的结果就是会形成脏读， 因此一般不采用。 提交读 Read Commited 只能读取到其他事务已经提交的数据。 即一个事务所做的修改在该事务未提交之前对其他事务不可见。 此级别能够解决脏读的问题，但是有可能会产生不可重复读的问题。 Orcale默认数据隔离级别就是提交读。 可重复读 Repetable Read 保证在同一个事务中，两次读取到的数据是一致的。 该级别能解决数据不一致中的不可重复读的问题，但无法解决幻读（注意此处指的是一般意义上的概念，mysql InnoDB在该级别下是不存在幻读的，具体原因见后面分析)。 mysql InnoDb引擎默认的数据库隔离级别就是可重复读。 串行读顾名思义，所有的读操作都是串行的，这样做肯定不会存在数据一致性问题， 但无疑效率是最低的。 Spring中的@Transactional注意事项该注解是Spring中用来控制事务的注解，在使用时有以下几点需要注意： @Transactional 注解默认回滚RuntimeExcepption异常，注意此处即使异常被处理（即catch捕获了该类型的RuntimeException异常），Spring仍然会回滚事务 @Transactional注解有一个参数rollbackFor可用来指定当自定义Exception发生时，也会进行事务回滚 @Transactional注解只能作用于public方法上，虽然也能写在非public上且不会报错，但实际上是不起作用的 Spring中事务的传播级别以下例子中用到的表结构： 12345678910create table user1 ( id int unsigned not null auto increment, name varchar(32) not null, primary key(id) ) engine=InnoDB;create table user2 ( id int unsigned not null auto increment, name varchar(32) not null, primary key(id) ) engine=InnoDB 在Spring中定义的事务的传播级主要有如下几种，现就其中几个主要的说明如下 PROPAGATION_REQUIRED按需加载。Spring默认的传播级别。 当上下文中已经存在事务，则加入到该事务执行。若上下文不存在事务，则新建一个事务执行。 此处上下文可以理解为@Transactional注解作用的地方，当该注解作用于方法时，上下文从方法最先开始的地方开启，也就是说在刚进入方法时，首先就会开启一个事务。 以下分几种情况进行说明： （1）当外部方法未开启事务时, 若外部方法抛出异常, 如何运行？ User1Service代码 12345678910@Service public class User1Service extends ServiceImpl&lt;User1Mapper, User1Entity&gt; &#123; @Resource private User1Mapper user1Mapper; @Transactional(propagation = Propagation.REQUIRED) public void addUser1(User1Entity user1Entity) &#123; user1Mapper.insert(user1Entity); &#125;&#125; User2Service代码 12345678910@Service public class User2Service extends ServiceImpl&lt;User2Mapper, User2Entity&gt; &#123; @Resource private User2Mapper user2Mapper; @Transactional(propagation = Propagation.REQUIRED) public void addUser2(User2Entity user2Entity) &#123; user2Mapper.insert(user2Entity); &#125; &#125; 测试代码: 123456789101112public void t1() &#123; User1Entity user1Entity = new User1Entity(); user1Entity.setId(100); user1Entity.setName(&quot;sju&quot;); user1Service.addUser1(user1Entity); User2Entity user2Entity = new User2Entity(); user2Entity.setId(200); user2Entity.setName(&quot;fdf&quot;); user2Service.addUser2(user2Entity); throw new RuntimeException(); &#125; 执行结果: user1, user2 均插入成功 分析: 因为外围方法未开启事务，所以程序执行到两个addUser方法时都会开启一个新的事务，这两个事务是相互独立的,分别执行自己的逻辑，插入成功，外部方法异常不影响内部. （2）当外部方法未开启事务时, 若内部方法抛出异常, 如何运行？ User1Service代码: 12345678910@Service public class User1Service extends ServiceImpl&lt;User1Mapper, User1Entity&gt; &#123; @Resource private User1Mapper user1Mapper; @Transactional(propagation = Propagation.REQUIRED) public void addUser1(User1Entity user1Entity) &#123; user1Mapper.insert(user1Entity); &#125; &#125; User2Service代码: 1234567891011@Service public class User2Service extends ServiceImpl&lt;User2Mapper, User2Entity&gt; &#123; @Resource private User2Mapper user2Mapper; @Transactional(propagation = Propagation.REQUIRED) public void addUser2(User2Entity user2Entity) &#123; user2Mapper.insert(user2Entity); throw new RuntimeException(); &#125; &#125; 测试代码: 1234567891011public void t1() &#123; User1Entity user1Entity = new User1Entity(); user1Entity.setId(100); user1Entity.setName(&quot;sju&quot;); user1Service.addUser1(user1Entity); User2Entity user2Entity = new User2Entity(); user2Entity.setId(200); user2Entity.setName(&quot;fdf&quot;); user2Service.addUser2(user2Entity); &#125; 结果: user1插入成功, user2插入失败 分析: 还是因为外部方法未开启事务, 所以user1, user2会开启两个独立的事务, 互不影响。 所以user1插入成功, user2插入失败。 （3）当外部方法开启事务时, 若内部方法或者外部方法抛出异常, 如何运行？ User1Service和User2Service代码同之前, 只是在测试方法上也加上@Transactional注解。 测试方法代码如下: 12345678910111213@Transactional public void t1() &#123; User1Entity user1Entity = new User1Entity(); user1Entity.setId(100); user1Entity.setName(&quot;sju&quot;); user1Service.addUser1(user1Entity); User2Entity user2Entity = new User2Entity(); user2Entity.setId(200); user2Entity.setName(&quot;fdf&quot;); user2Service.addUser2(user2Entity); throw new RuntimeException(); &#125; 结果: user1, user2都未插入 分析: 外部方法开启事务，内部两个方法都会加入到该事务中成为一个事务，外部方法回滚，则所有回滚 PROPAGATION_NESTED事务之间是嵌套的。若上下文存在事务，则嵌套执行，若不存在事务，则新建事务执行。 原理：子事务是父事务的一部分，当进入子事务之前，会先在父事务建立一个回滚点save point，然后执行子事务。待子事务执行结束，再执行父事务。 总结起来就是: 子事务的执行不会影响父事务，但父事务的执行会影响子事务。 举个例子， 若methodA以PROPAGATION_REQUIRED修饰， methodB以PROPAGATION_NESTED修饰， 并且在methodA中调用methodB， 此时A为父事务， B为子事务。 其执行情况如下： 异常情况 执行结果 A抛异常，B正常 A, B 都回滚 A正常， B异常 B先回滚， A再正常提交 A，B都抛异常 A , B 都回滚 问题1： 若子事务回滚，会发生什么？ 若子事务回滚，则父事务会回滚到之前建立的save point,然后执行其他业务逻辑，父事务之前的操作不受影响，更不会自动回滚。所以父事务不受子事务的影响。 问题2：若父事务回滚，子事务会回滚吗？ 答：子事务会回滚 问题3：子事务和父事务谁先提交？ 答：子事务先提交 PROPAGATION_SUPPORTS支持当前事务，若没有当前事务，则以非事务执行 PROPAGATION_MANDATORY使用当前事务，注意这是强制性的（mandatory),因为当发现当前没有事务时，直接抛出异常 PROPAGATION_REQUIRES_NEW不管上下文中是否存在事务，每次都新建一个独立事务。 若上下文中存在事务，则先会将上下文事务挂起，然后执行本方法事务，待本方法事务执行完毕之后，继续执行上下文事务。 若上下文未开启事务，其行为逻辑与requires级别一致,即新建一个自己独立的事务。 当外部方法开启事务时，requires_new修饰的内部方法依然会单独开启独立事务，且与外部方法的事务相互独立，内部方法之间、内部方法和外部方法的事务均相互独立，互不影响。 PROPAGATION_NOT_SUPPORTED以非事务方式执行代码，若当前存在事务，则将当前事务挂起 PROPAGATION_NEVER以非事务执行，该处语气比上一个更强，因为当发现当前存在事务时，则直接抛出异常","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"mysql","slug":"编程/mysql","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://acchw.top/tags/mysql/"},{"name":"事务","slug":"事务","permalink":"https://acchw.top/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"常用正则表达式总结","slug":"编程/other/常用正则表达式总结","date":"2023-05-24T00:00:00.000Z","updated":"2023-05-24T00:00:00.000Z","comments":true,"path":"posts/24604/","link":"","permalink":"https://acchw.top/posts/24604/","excerpt":"","text":"正则表达式语法 字符 说明 ^ 匹配字符输入的开始 $ 匹配字符输入的结束 \\d 数字字符, 等效于[0-9] \\s 匹配任何空白字符，包括空格、制表符、换页符等 \\S 匹配任何非空白字符 {n} 正好匹配n次 {n,} 至少匹配n次 {n, m} n&lt;&#x3D;m, 匹配至少n次,至多m次 () 标记一个子表达式的开始和结束位置。子表达式可以供以后使用 * 零次或多次匹配前面的字符或子表达式, 等效于{0,} + 一次或多次匹配前面的字符或子表达式,等效于{1,} ? 零次或一次匹配前面的字符或子表达式,等效于 {0,1} . 匹配除”\\r\\n”之外的任何单个字符 | 或的关系 \\un 匹配 n，其中 n 是以四位十六进制数表示的 Unicode 字符。例如，\\u00A9 匹配版权符号 (©)。 \\w 匹配任何字类字符，包括下划线。与”[A-Za-z0-9_]”等效 [\\u4e00-\\u9fa5] 匹配中文字符 常见示例以Java写法为例， 其他语言类似： 1234567891011121314151617181920212223//只能输入n到m位的数字String regex = &quot;^\\\\d&#123;n,m&#125;$&quot; //只能输入英文字母和数字String regex = &quot;^[A-Za-z0-9]+$&quot;;//只能输入数字String regex = &quot;^[0-9]+$&quot;;//11位数字String regex = &quot;\\\\d&#123;11&#125;&quot;;//中文字符String regex = &quot;[\\\\u4e00-\\\\u9fa5]&quot;;//匹配任意字符且长度为1到5位String regex = &quot;[\\\\s\\\\S]&#123;1,5&#125;&quot;;//匹配任意ascii码中字符且长度为1到5位String regex = &quot;[\\\\x00-\\\\x7F]&#123;1,5&#125;&quot;;//只要出现一次月份即可，例如 hu01jk, 11kloString regex = &quot;.*([0-1][0-9])+.*&quot;;","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"other","slug":"编程/other","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/other/"}],"tags":[{"name":"正则","slug":"正则","permalink":"https://acchw.top/tags/%E6%AD%A3%E5%88%99/"}]},{"title":"还是阳了","slug":"生活/还是阳了","date":"2023-05-21T00:00:00.000Z","updated":"2023-05-21T00:00:00.000Z","comments":true,"path":"posts/37012/","link":"","permalink":"https://acchw.top/posts/37012/","excerpt":"","text":"还是记录一下为好。时间是2023年5月17号， 我终于还是阳了。 5月17号早上起来的时候， 就感觉头很疼，还以为是昨天晚上吹空调导致的，但是后来越来越疼，于是买了个体温计和检测试剂，不出所所料，确实阳了，当时的体温是38.9度。 前后总共持续4天左右， 除了头疼和发烧， 其他的症状到还好， 但是这个头疼真的很难受，是既不能睡又不能不睡。 之前疫情三年一直都没阳过， 包括最后解封的时候， 我周边的同事都阳了， 就只有我没阳， 还以为自己体质很好（其实我的体质确实感觉还行， 已经有七八年没去过医院，吃过药了，最近的一次生病我记的应该是高中的时候吃东西吃坏肚子）。 但最终还是没躲过去。","categories":[{"name":"生活","slug":"生活","permalink":"https://acchw.top/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://acchw.top/tags/%E7%94%9F%E6%B4%BB/"}]},{"title":"红米AC2100 openwrt下无法进入breed","slug":"折腾/其他/红米AC2100 openwrt下无法进入breed","date":"2023-05-01T11:10:00.000Z","updated":"2025-01-21T05:49:52.459Z","comments":true,"path":"posts/64412/","link":"","permalink":"https://acchw.top/posts/64412/","excerpt":"","text":"最近ac2100刷的openwrt，想换回pandavan，使用如下方法无法进入breed的web页面： 先断电，然后找个针戳住路由器背后 Reset 小孔并插电，等路由器蓝灯一直闪烁后，浏览器输入 192.168.1.1，即可进入 breed 网页。 路由器的system一直闪黄灯，突然想到之前刷openwrt的时候， 刷入了官方的bootloader， 所以自然无法进入。下面介绍一下在openwrt的系统下，如何刷breed的bootloader。 在openwrt的web页面，将breed的固件breed-mt7621-xiaomi-r3g.bin上传到&#x2F;tmp路径下（其他路径也可以），然后ssh进入路由器命令行， 执行 如下命令： 12cd /tmpmtd_write -r write breed-mt7621-xiaomi-r3g.bin Bootloader 之后重启路由器， 登录192.168.1.1就ok了。 有一个注意点，openwrt下ssh的用户名和密码， 网上找了半天都没找到， 所以一直无法登录，后来发现我装的这个openwrt上面已经集成了ssh的设置， 可以使用秘钥的方式登录， 具体操作如下： windows下执行命令ssh-keygen 生成秘钥文件，在你的用户目录下的.ssh文件夹下会有两个文件：id_rsa和id_rsa.pub 在openwrt的页面下（具体哪个页面忘记截图了，是关于ssh设置的地方），将id_rsa.pub文件上传 使用xshell登录， 秘钥文件选择id_rsa， 即可在不知道ssh密码的情况下登录路由器的命令行","categories":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"其他","slug":"折腾/其他","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/tags/%E6%8A%98%E8%85%BE/"},{"name":"路由器","slug":"路由器","permalink":"https://acchw.top/tags/%E8%B7%AF%E7%94%B1%E5%99%A8/"},{"name":"AC2100","slug":"AC2100","permalink":"https://acchw.top/tags/AC2100/"}]},{"title":"从alpine编译nginx的docker镜像","slug":"编程/other/从alpine编译nginx的docker镜像","date":"2023-03-28T00:00:00.000Z","updated":"2023-03-28T00:00:00.000Z","comments":true,"path":"posts/61959/","link":"","permalink":"https://acchw.top/posts/61959/","excerpt":"","text":"因为需要接入nginx监控，用的是vts模块，原生nginx并没有包含该模块，原本想着用别人已经编译好的， 但是一想后期可能还需要加入其他的模块，所以还是自己编译一个。 下面说一下具体的步骤。 编写dockerfile文件此处用的几个主要软件版本： alpine: 3.17 nginx: 1.22.1 nginx-module-vts: 0.2.1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748FROM alpine:3.17ENV NGINX_VERSION nginx-1.22.1RUN echo https://mirrors.aliyun.com/alpine/v3.17/main/ &gt; /etc/apk/repositories &amp;&amp; \\ echo https://mirrors.aliyun.com/alpine/v3.17/community/ &gt;&gt; /etc/apk/repositoriesRUN apk --update add openssl-dev pcre-dev zlib-dev wget build-base libxslt-dev &amp;&amp; \\ mkdir -p /tmp/src &amp;&amp; \\ cd /tmp/src &amp;&amp; \\ wget -O nginx-module-vts.tar.gz https://github.com/vozlt/nginx-module-vts/archive/refs/tags/v0.2.1.tar.gz &amp;&amp; \\ wget http://nginx.org/download/$&#123;NGINX_VERSION&#125;.tar.gz &amp;&amp; \\ tar -zxvf nginx-module-vts.tar.gz &amp;&amp; \\ tar -zxvf $&#123;NGINX_VERSION&#125;.tar.gz &amp;&amp; \\ cd /tmp/src/$&#123;NGINX_VERSION&#125; &amp;&amp; \\ ./configure \\ --prefix=/etc/nginx \\ --sbin-path=/usr/sbin/nginx \\ --conf-path=/etc/nginx/nginx.conf \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --pid-path=/var/run/nginx.pid \\ --lock-path=/var/run/nginx.lock \\ --with-compat \\ --with-pcre-jit \\ --with-http_ssl_module \\ --with-http_stub_status_module \\ --with-http_realip_module \\ --with-http_auth_request_module \\ --with-http_v2_module \\ --with-http_dav_module \\ --with-http_slice_module \\ --with-threads \\ --with-http_addition_module \\ --with-http_gunzip_module \\ --with-http_gzip_static_module \\ --with-http_sub_module \\ --with-http_xslt_module=dynamic \\ --with-stream=dynamic \\ --with-stream_ssl_module \\ --with-mail=dynamic \\ --with-mail_ssl_module \\ --add-module=/tmp/src/nginx-module-vts-0.2.1 &amp;&amp; \\ make &amp;&amp; \\ make install &amp;&amp; \\ apk del build-base &amp;&amp; \\ rm -rf /tmp/src &amp;&amp; \\ rm -rf /var/cache/apk/*WORKDIR /etc/nginxEXPOSE 80 443CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 编译镜像编译镜像可以直接使用docker命令来编译， 我这儿为了方便，就使用jenkins来编译。 新建一个jenkins项目，项目类型选择”流水线”， 然后编写流水线脚本， 具体jenkins使用步骤这里就不描述了，这里贴一下我的脚本， 包含了代码拉取 -&gt; 镜像构建 -&gt; 镜像推送几个步骤。 12345678910111213141516171819202122pipeline &#123; agent any stages &#123; stage (&quot;git pull&quot;) &#123; steps &#123; git credentialsId: &#x27;拉取凭证&#x27;, url: &#x27;你的git仓库地址，dockerfile文件要在仓库根路径&#x27; &#125; &#125; stage(&#x27;docker build&#x27;) &#123; steps &#123; sh &#x27;docker build -t 镜像tag .&#x27; &#125; &#125; stage(&#x27;docker push&#x27;) &#123; steps &#123; sh &#x27;docker login --username=*** --password=*** ***&#x27; sh &#x27;docker push ***&#x27; &#125; &#125; &#125;&#125; 运行服务在运行镜像的时候， 需要将nginx.conf文件挂载出来， 方便后续修改。 下面贴一个支持vts模块的nginx配置文件。 nginx.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127#user nobody;worker_processes 1;load_module /etc/nginx/modules/ngx_stream_module.so;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; # &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; # &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; gzip on; # nginx-vts vhost_traffic_status_zone; vhost_traffic_status_filter_by_host on; #开启此功能，会根据不同的server_name进行流量的统计，否则默认会把流量全部计算到第一个上。 vhost_traffic_status_filter on; vhost_traffic_status_filter_by_set_key $status $server_name; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; location /status &#123; vhost_traffic_status_display; vhost_traffic_status_display_format html; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#x27;s document root # concurs with nginx&#x27;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"other","slug":"编程/other","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/other/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://acchw.top/tags/nginx/"},{"name":"docker - jenkins","slug":"docker-jenkins","permalink":"https://acchw.top/tags/docker-jenkins/"}]},{"title":"hexo主题使用css添加网格背景","slug":"折腾/博客/hexo主题使用css添加网格背景","date":"2023-02-08T00:00:00.000Z","updated":"2023-02-08T00:00:00.000Z","comments":true,"path":"posts/65472/","link":"","permalink":"https://acchw.top/posts/65472/","excerpt":"","text":"给hexo的博客添加一个网格背景， 此处不想使用图片， 而是直接使用css来实现，效果图如下： css文件内容如下（文件名background.css）： 12345body &#123; background:white; background-image:linear-gradient(90deg,rgba(241,243,244,1) 10%,transparent 0),linear-gradient(rgba(241,243,244,1) 10%,transparent 0); background-size:15px 15px;&#125; 为了各个hexo主题都能通用， 此处使用hexo提供的注入功能将css注入到博客中。 在博客根目录下新建一个scripts文件夹， 然后在该文件下新建一个js文件（命名随便都行），复制如下代码： 1hexo.extend.injector.register(&#x27;head_end&#x27;,&#x27;&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;/css/background.css&quot;&gt;&#x27;,&#x27;default&#x27;); 其中，background.css文件就是上文提到的css文件， 位于博客根目录的source&#x2F;css文件夹，注意此处一定要在博客根目录的source文件夹下创建，如果在其他文件夹下，可能识别不到或被主题覆盖。 同理， 其他想脱离特定主题（有些主题提供了自定义css、js的功能， 但是不通用，换了一个主题就无法使用）而实现注入css、js的功能， 都可以使用这种方法来实现。 具体hexo的注入功能查阅hexo的文档即可，地址：https://hexo.io/zh-cn/api/injector.html","categories":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"博客","slug":"折腾/博客","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/tags/%E6%8A%98%E8%85%BE/"},{"name":"博客","slug":"博客","permalink":"https://acchw.top/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"hexo","slug":"hexo","permalink":"https://acchw.top/tags/hexo/"}]},{"title":"live555搭建流视频服务播放视频文件","slug":"折腾/其他/live555搭建流视频服务播放视频文件","date":"2023-01-16T14:00:00.000Z","updated":"2023-01-16T14:00:00.000Z","comments":true,"path":"posts/16866/","link":"","permalink":"https://acchw.top/posts/16866/","excerpt":"","text":"为了方便，使用docker搭建，用的是docker hub上使用人数最多的一个镜像， docker-compose.yml文件内容如下所示： 12345678910version: &quot;3&quot;services: live555: image: vimagick/live555 container_name: live555 restart: always ports: - 554:554 volumes: - $&#123;PWD&#125;/data:/data 视频文件放在当前目录的data文件夹下， 然后使用vlc播放rtsp流地址测试一下， rtsp地址： 1rtsp://ip:554/demo.264","categories":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"其他","slug":"折腾/其他","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"selfhost","slug":"selfhost","permalink":"https://acchw.top/tags/selfhost/"}]},{"title":"JVM内存分配机制介绍","slug":"编程/java/JVM内存分配机制","date":"2023-01-15T21:00:00.000Z","updated":"2024-11-13T10:00:00.000Z","comments":true,"path":"posts/17167/","link":"","permalink":"https://acchw.top/posts/17167/","excerpt":"","text":"本文针对的是hotspot虚拟机， jdk版本1.8的虚拟机进行介绍。 程序计数器线程私有，可以看做是当前线程所执行的字节码的行号，用于下一次线程切换的时候虚拟机定位到上一次执行的位置。 ‍ 虚拟机栈在一个时间点，只会有一个活动的栈帧，通常叫作当前帧，方法所在的类叫作当前类。 如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，成为新的当前帧，一直到它返回结果或者执行结束。JVM直接对Java栈的操作只有两个，就是对栈帧的压栈和出栈。 总结几点如下： 线程私有，生命周期与线程相同。描述的是方法执行的内存模型。 进入方法时对应入栈，方法结束的时候对应出栈。 该区域存储着局部变量，操作数，方法出口等信息。 ‍ 方法区 线程共享。用于存储类信息、常量池、静态变量、JIT编译后的代码等数据。具体放在哪里，不同的实现可以放在不同的地方。 一般情况可以理解成class文件在内存中的存放位置。 在1.7和1.8之后的实现逻辑有所不同。 由于该区域大小一般较小，所以不会对该区域进行垃圾回收。所以在1.7之前的版本，有可能会因为字符串常量池过大导致该区域内存溢出(Permgen space out of memory error)。 永久代（PermGen)和方法区之间是什么关系？ 方法区是虚拟机规范中的一部分，而永久代是hotspot虚拟机用来实现方法区的， 是hotspot虚拟机特有的。 在1.7之前，永久代就是方法区。 从1.8开始，hotspot移除了永久代，将方法区的实现分为两部分： 将原先永久代中的类的​静态变量和常量池放入堆中 将类的元信息放入元空间（metaspace ）中 ‍上文中介绍到的几个概念分别做一一说明： 类型信息：包括类的完整名称，父类名称等，该类型信息是在类加载器加载类的时候从类文件中提取出来的。 元空间：metaspace ，是与堆不相连的一块本地内存。Java将其放在本地内存中， 默认只受本地内存大小的限制，也就是说本地内存剩余多少，理论上Metaspace就可以有多大。可以使用参数 -XX:MaxMetaspaceSize 参数来指定 metaspace 区域的大小 字面量：给基本类型变量赋值的方式就叫做字面量或者字面值 常量池：java中的常量池分为两种， 静态常量池和运行时常量池（此处指的是运行时常量池）： 静态常量池。即class文件中的常量池，主要用于存放两大类常量：字面量(Literal)和符号引用量(Symbolic References)。 其中字面量相当于Java语言层面常量的概念，如文本字符串，声明为final的常量值等，而符号引用则属于编译原理方面的概念，包括了如下三种类型的常量： 类和接口的全限定名 字段名称和描述符 方法名称和描述符 运行时常量池。jvm虚拟机在完成类装载操作后，将class文件中的常量池载入到内存中，并保存在方法区中 ‍ 直接内存（堆外内存）不是虚拟机运行时数据区的一部分。JDK中主要是NIO库中一些直接操作本地内存的类， 例如DirectByteBuffer。 其内存大小虽然不受堆最大内存的制约，但是也会受到操作系统最大内存的制约。 Java中NIO的核心缓冲ByteBuffer，所有的IO操作都是通过这个ByteBuffer进行的。Bytebuffer有两种： HeapByteBuffer和DirectByteBuffer，下面是这两种内存的分配方式： 1234//分配HeapByteBufferByteBuffer buffer = ByteBuffer.allocate(int capacity);//分配DirectByteBufferByteBuffer buffer = ByteBuffer.allocateDirect(int capacity); 两者之间的区别： DirectByteBuffer HeapByteBuffer 涉及到IO时拷贝情况 不需要拷贝，直接使用 需要拷贝到HeapByteBuffer后再使用 创建开销 需要调用原生方法从系统申请内存， 所以创建开销较大。 不过一般应用会提前申请一大块内存， 然后自己实现内存管理机制， 例如netty 从JVM堆上分配，速度很快，所以创建开销小 对于GC的影响 不存在于堆栈中， 但是有冰山现象的问题 频繁申请新的对象会引发GC 为啥要使用堆外内存？ 可以在进程间共享，减少虚拟机间的复制 对垃圾回收停顿的改善：如果应用中包含大量长期存活的对象，发生YGC或者FullGC的频率就会比较高，此时如果将这些内存放到堆外，就会减少堆中发生GC的次数，提高垃圾回收效率 在某些场景下可以提升程序I&#x2F;O操纵的性能。因为少去了将数据从堆内内存拷贝到堆外内存的步骤。 ‍ 堆JVM中空间占比最大的一块区域。被所有线程共享。几乎所有的对象实例和数组都会存储在此地。垃圾收集主要是针对此处进行工作。 主要分为新生代和老年代，见下图分配示意。 先讲述一下新生代的事。以下垃圾回收的算法其实也就是复制算法的实现。 新生代，顾名思义，Java中绝大部分对象都是在该区域被创建，存放新建创建的对象。其特点是对象更新速度快，因为Java中大多数对象都不需要存活很长时间（典型的就是局部变量）。该区域是进行垃圾回收频繁的区域，且进行的垃圾回收类型是Minor GC（GC发生的区域不是整个新生代，而是新生代中的Eden区）。 新生代又被分为Eden区，S0区，S1区（S代表Survivor)。默认参数是Eden区占新生代的绝大部分空间（8:1）。当一个对象被创建的时候，首先会在Eden区分配空间（对于大数组， 也有可能第一次就直接在老年代分配）。当Eden区没有足够的空间时，会触发一次Minor GC，此时会将存活的对象移动到S0，再将Eden清空。若再次发生Minor GC,则将Eden,S0中存活的对象移动到S1，再将Eden，S0清空。 这样对象就会反复在新生代的三个区之间来回移动，随着对象的移动，其GC年龄也会不断增加，当GC年龄达到一个默认值（15）的时候，就会将该对象实例移动到老年代，如此，老年代的数据就出来了。所以，老年代的数据都是新生代中那些存活年龄很大的对象。 经过以上步骤，老年代已经呼之欲出了。当老年代空间不足时，也会触发一次GC，此时的GC又叫Full GC，比新生代发生的Minor GC要慢得多。 ‍比如常见的在方法中new一个对象的写法， 如下所示： Object obj = new Object(); 在等于号右边 new Object()出来的对象是存储在堆上； 在等于号左边obj这个对象引用是存储在该方法的虚拟机栈上； 表示Object这个对象的class属性是存储在方法区上（运行时常量池）； jvm问题排查工具1. 排查是否频繁full gc当整个服务出现响应缓慢的时候， 一个可能的原因是此时jvm正在频繁的进行full gc， 那么如何确定是不是这个原因呢？可以使用jstat命令来判断（如果使用的是openjdk的docker， 一般路径在&#x2F;usr&#x2F;lib&#x2F;jvm下）， 步骤如下： jps -l 获取java进程的进程号 查询GC状态 jstat -gc 6 1000 , 其中 6表示JVM的进程号， 1000表示每隔1000ms打印 一次， 输出结果如下： 其中倒数第三列FGC表示full gc的次数， 如果一直在增长， 则很有可能是发生了OOM， 导致一直在full gc 若出现了full gc, 需要导出堆栈，命令如下：(有时候JVM已经处于假死状态，可能不会响应该命令） 12# 6是进程号jmap -dump:format=b,file=/var/logs/heap.hprof 6 2. JVM参数设置启动参数加上如下： 12345# oom的时候自动生成dump文件-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/var/log/heapdump.hprof# 输出gc日志到文件-XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/var/log/gc.log 注意， 有时候即使设置了此参数，也有可能无法生成对应的dump文件， 可能的原因有如下几个： JVM本身内存已经所剩无几：JVM 可能没有足够的内存来生成堆转储文件，特别是在堆栈溢出或其他严重内存问题发生时。 磁盘不够或目录权限错误：这个一般修改参数或增大磁盘即可 OOM是发生在GC线程中：不过这个一般不太会可能发生 3. 分析工具使用除了一些常用的命令之外， 一些图形化的工具也非常有助于分析问题 分析gc的log日志用 gcviewer, 下载之后直接使用 java -jar 命令启动即可 分析堆栈文件用MAT(Eclipse Memory Analyzer)、visualvm或者jprofile 参考资料： https://zhuanlan.zhihu.com/p/161939673 深入理解Java虚拟机 [https://www.sczyh30.com/posts/Java/jvm-metaspace/](","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"java","slug":"编程/java","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://acchw.top/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"https://acchw.top/tags/jvm/"}]},{"title":"jenkins使用流水线打包springboot和vue镜像","slug":"编程/other/jenkins使用流水线打包springboot和vue镜像","date":"2022-12-19T00:00:00.000Z","updated":"2022-12-19T00:00:00.000Z","comments":true,"path":"posts/22182/","link":"","permalink":"https://acchw.top/posts/22182/","excerpt":"","text":"使用jenkins的流水线功能，可以很方便的知道各个步骤的执行进度和所用时间，还是比较方便的。 在流水线中可以使用docker进行打包， 这样就可以很方便的使用任何docker镜像，而不需要安装对应的环境。 本文要实现的目的如下： 从git仓库拉取代码，并允许指定分支或tag jenkins编译代码 构建镜像 push镜像到远程仓库（此处是阿里云仓库） 使用前准备本文的jenkins本身也是docker安装的， 为了直接使用宿主机的docker，需要在安装jenkins容器的时候将宿主机的docker映射到jenkins容器中，比如使用docker-compose时其部分配置如下： 12- /var/run/docker.sock:/var/run/docker.sock- /usr/bin/docker:/usr/bin/docker Java镜像构建springboot工程需要有一个springboot工程的仓库，并且在项目的根文件下新建一个Dockerfile文件， 内容如下： 123456FROM openjdk:17RUN echo &quot;Asia/Shanghai&quot; &gt; /etc/timezoneVOLUME /tmpADD target/app.jar app.jarEXPOSE 15800ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;-Dspring.profiles.active=prod&quot;, &quot;app.jar&quot;] 同时还需要在项目的根目录下新建一个 settings.xml文件，用于指定中央仓库地址和本地仓库地址， 方便缓存，国内一般可以指定maven的仓库地址为阿里云， 文件内容如下： 123456789101112131415&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.1.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.1.0 http://maven.apache.org/xsd/settings-1.1.0.xsd&quot;&gt; &lt;localRepository&gt;/root/.m2&lt;/localRepository&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;aliyunmaven&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/public&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;pluginGroups&gt; &lt;pluginGroup&gt;org.apache.maven.plugins&lt;/pluginGroup&gt; &lt;pluginGroup&gt;org.codehaus.mojo&lt;/pluginGroup&gt; &lt;/pluginGroups&gt;&lt;/settings&gt; jenkins项目jenkins新建项目， 风格选择“流水线”，然后在流水线处加入groovy脚本， 下面这个是结合git仓库所使用的groovy脚本内容， 可以直接粘贴到jenkins上。 1234567891011121314151617181920212223242526272829303132333435363738def branchTransform(branch) &#123; return branch.replace(&quot;origin/&quot;, &quot;&quot;);&#125;def t = branchTransform(&quot;$&#123;TAG&#125;&quot;);pipeline &#123; agent &#123; docker &#123; image &#x27;maven:3.8.5-openjdk-17&#x27; args &#x27;-v /opt/docker/jenkins/repo/mvn:/root/.m2&#x27; &#125; &#125; stages &#123; stage (&quot;git pull&quot;) &#123; steps &#123; checkout([$class: &#x27;GitSCM&#x27;, branches: [[name: &#x27;$&#123;TAG&#125;&#x27;]], extensions: [], userRemoteConfigs: [[credentialsId: &#x27;.....&#x27;, url: &#x27;....&#x27;]]]) &#125; &#125; stage(&#x27;mvn package&#x27;) &#123; steps &#123; sh &#x27;mvn clean package -DskipTests=true -s settings.xml -B -U&#x27; &#125; &#125; stage(&#x27;docker build&#x27;) &#123; steps &#123; sh &#x27;docker build -t your_registry/service:&#x27; + t + &#x27; .&#x27; &#125; &#125; stage(&#x27;docker push&#x27;) &#123; steps &#123; sh &#x27;docker login --username=username --password=password your_registry&#x27; sh &#x27;docker push your_registry/service:&#x27; + t &#125; &#125; &#125;&#125; 对上面脚本的内容进行一一说明： branchTransform函数， 是在之前指定了一个构建参数， 此处是git的分支或tag， 这样可以在构建的时候手动指定分支或tag, 设置过程如下图所示（需要提前安装git paramter插件才会有这个界面）： 由于此处使用的是java版本是17，所以使用的maven镜像是maven:3.8.5-openjdk-17, 同时为了加快构建，此处选择将maven的本地仓库地址持久化，注意，此处的maven镜像其实是宿主机上的，所以在进行目录映射的时候， 映射的也是宿主机的路径和maven容器中的路径，对于本例： &#x2F;opt&#x2F;docker&#x2F;jenkins&#x2F;repo&#x2F;mvn 宿主机上的路径，maven仓库都会被缓存到此处 &#x2F;root&#x2F;.m2 maven镜像中的路径，是在上一步中settings.xml文件中指定的 git pull 从仓库中拉取代码， 可以直接使用jenkins自带的流水线语法来生成， 注意， 需要提前生成一个凭证，用于从git仓库获取代码 mvn package 编译java代码 docker build 构建docker镜像 docker push 将镜像push到远程仓库 vue镜像构建vue工程此处是使用nginx来运行编译后的vue项目，所以实际上构建的是一个nginx镜像。 需要在vue项目根目录下新建一个Dockerfile文件， 内容如下： 12345FROM nginx:1.22.1RUN echo &quot;Asia/Shanghai&quot; &gt; /etc/timezoneCOPY dist /usr/share/nginx/htmlCOPY nginx.conf /etc/nginx/nginx.confEXPOSE 15802 同时，还需要在项目根目录下新建一个nginx.conf文件，用于nginx的一些配置，比如端口转发等。 jenkins项目基本过程同springboot一样， 此处就不在赘述，直接贴一个groovy脚本， 内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940def branchTransform(branch) &#123; return branch.replace(&quot;origin/&quot;, &quot;&quot;);&#125;def t = branchTransform(&quot;$&#123;TAG&#125;&quot;);pipeline &#123; agent &#123; docker &#123; image &#x27;node:12.5.0&#x27; &#125; &#125; stages &#123; stage (&quot;git pull&quot;) &#123; steps &#123; checkout([$class: &#x27;GitSCM&#x27;, branches: [[name: &#x27;$&#123;TAG&#125;&#x27;]], extensions: [], userRemoteConfigs: [[credentialsId: &#x27;......&#x27;, url: &#x27;......&#x27;]]]) &#125; &#125; stage(&#x27;npm run build&#x27;) &#123; steps &#123; sh &#x27;npm config set registry https://registry.npm.taobao.org&#x27; sh &#x27;npm install&#x27; sh &#x27;npm run build&#x27; &#125; &#125; stage(&#x27;docker build&#x27;) &#123; steps &#123; sh &#x27;docker build -t your_registry/service:&#x27; + t + &#x27; .&#x27; &#125; &#125; stage(&#x27;docker push&#x27;) &#123; when &#123; environment name: &#x27;PUSH&#x27;, value: &#x27;true&#x27; &#125; steps &#123; sh &#x27;docker login --username=username --password=password your_registry&#x27; sh &#x27;docker push your_registry/service:&#x27; + t &#125; &#125; &#125;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"other","slug":"编程/other","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/other/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://acchw.top/tags/docker/"},{"name":"springboot","slug":"springboot","permalink":"https://acchw.top/tags/springboot/"},{"name":"jenkins","slug":"jenkins","permalink":"https://acchw.top/tags/jenkins/"},{"name":"vue","slug":"vue","permalink":"https://acchw.top/tags/vue/"}]},{"title":"使用prometheus监控clickhouse","slug":"编程/clickhouse/使用prometheus监控clickhouse","date":"2022-11-19T17:00:00.000Z","updated":"2025-01-21T05:49:52.460Z","comments":true,"path":"posts/34295/","link":"","permalink":"https://acchw.top/posts/34295/","excerpt":"","text":"较新版本的clickhouse内部已经支持暴露监控数据给prometheus, 所以此处就不用另外部署clickhouse-exporter服务来获取监控数据。 clickhouse配置修改clickhouse的配置文件config.xml, 将prometheus这一项原先的注释放开，使其生效。 官方文档路径：https://clickhouse.com/docs/en/operations/server-configuration-parameters/settings/#server_configuration_parameters-prometheus 12345678&lt;prometheus&gt; &lt;endpoint&gt;/metrics&lt;/endpoint&gt; &lt;port&gt;9363&lt;/port&gt; &lt;metrics&gt;true&lt;/metrics&gt; &lt;events&gt;true&lt;/events&gt; &lt;asynchronous_metrics&gt;true&lt;/asynchronous_metrics&gt; &lt;status_info&gt;true&lt;/status_info&gt;&lt;/prometheus&gt; 然后重启服务，此处配置的端口是9363，可以执行如下命令验证配置是否成功： curl http://localhost:9363/metrics|less 如果有输出如图所示，则表示配置生效。 prometheus配置修改prometheus.yml文件，增加一个clickhouse的job。 1234scrape_configs: - job_name: &#x27;clickhouse-exporter&#x27; static_configs: - targets: [&#x27;10.0.0.239:9363&#x27;] 注意此处的端口就是之前clickhouse配置prometheus的端口。 重启prometheus服务，打开prometheus web页面上的targets页面， 如果看到clickhouse状态是up的话，表示集成成功。 grafana 配置可以自己手动添加dashboard，也可以在grafana官网上找一个图表，直接导入即可。本人用的ID是：14432 导入这个ID之后， 效果如下：","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"clickhouse","slug":"编程/clickhouse","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/clickhouse/"}],"tags":[{"name":"监控","slug":"监控","permalink":"https://acchw.top/tags/%E7%9B%91%E6%8E%A7/"},{"name":"prometheus","slug":"prometheus","permalink":"https://acchw.top/tags/prometheus/"},{"name":"clickhouse","slug":"clickhouse","permalink":"https://acchw.top/tags/clickhouse/"}]},{"title":"克服自己","slug":"感悟/克服自己","date":"2022-11-13T22:40:00.000Z","updated":"2022-11-13T22:40:00.000Z","comments":true,"path":"posts/14802/","link":"","permalink":"https://acchw.top/posts/14802/","excerpt":"","text":"要克服自己的缺陷，打败自己， 这句话说起来容易做起来却是很难。 你会因为惯性去做使自己舒适的事，这样就容易在舒适的道路上越走越远，也就与你自己制定的目标相去甚远。 如此，要怎样克服自己？ 我觉的有如下几点需要注意。 首先不要给自己过于遥远的目标，这样你是一定无法完成的，就会产生懈怠心理。 其次，对于目标一定要检验成果，并且记录下来，不要欺骗自己。 共勉之！","categories":[{"name":"感悟","slug":"感悟","permalink":"https://acchw.top/categories/%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"感悟","slug":"感悟","permalink":"https://acchw.top/tags/%E6%84%9F%E6%82%9F/"}]},{"title":"微服务架构中关于事务的一些思考","slug":"编程/分布式/微服务架构中关于事务的一些思考","date":"2022-11-07T00:00:00.000Z","updated":"2023-02-26T00:00:00.000Z","comments":true,"path":"posts/56453/","link":"","permalink":"https://acchw.top/posts/56453/","excerpt":"","text":"分布式事务 指的是当事务的操作分布在不同的节点上时， 需要保证事务的ACID特性。 其中最重要的一点是要保证在各个节点上的事务要么同时成功，要么同时失败。 分布式事务的解决方案有多种，下面对几种常见的进行一一说明。 2PC2PC， Two-phase Commit 。两阶段提交，通过引入协调者（Coordinator）来协调所有参与者的行为，并最终决定这些参与者是否要真正执行事务。 两个阶段分别如下： 第一阶段：准备阶段。由协调者询问各个参与节点事务是否执行成功，参与节点返回事务执行结果。参与节点收到通知之后，会进行准备操作，例如执行insert（此时并未commit)，准备完成之后会告诉协调节点自己已经准备完成。 第二阶段：提交阶段。协调节点在收到所有参与节点都执行成功之后，就会通知所有节点进行提交操作。若任一节点执行失败，协调节点则会通知所有参与节点回滚数据。 主要缺点如下： 阻塞。 需要等待所有参与者确认OK之后才能commit， 其处理的时间取决于处理事务最慢的那个参与节点。所以不适合并发高的场景。 单点故障。 特别是对协调节点的依赖很大，若协调节点发生故障，则整个事务都将不可用 数据不一致。比如在第二阶段，某些参与节点在接收到commit之后发生故障，将会导致这些参与节点的数据与其他节点数据不一致 TCC 其核心思想是对于每个操作，都需要有一个与其对应的补偿（或者叫撤销）操作 一般分为三个阶段： try: 尝试去执行，完成所有业务的一致性检查，预留必须的业务资源 confirm: 该阶段对业务进行确认提交，不做任何检查，因为 try 阶段已经检查过了，默认 Confirm 阶段是不会出错的 cancel: 若业务执行失败，则进入该阶段，它会释放 try 阶段占用的所有业务资源，并回滚 Confirm 阶段执行的所有操作 TCC有一个大的前提，就是这三个动作必须都是幂等的，对业务有一定的要求。拿资金转账来说，try就是冻结金额；confirm就是完成扣减；cancel就是解冻，只要对应的订单号是一样的，多次执行也不会有任何问题。 由于TCC中事务的发起方是直接在各个业务节点上，所以不需要协调者， 这样也就不会存在2PC中所说的资源阻塞的问题，因为在confirm阶段每个参与节点都已经提交事务了，不需要等待其他节点，所以其并发能力较好。 其最大的缺点是对代码的侵入性太强，相当于业务层去保证事务，需要业务自己去将confirm和cancel抽象出来，对于某些场景会造成大量的编码，甚至难以执行。 本地消息表 通过mq来实现，当发起事务的系统发送mq之后，需要消费的服务接受到该mq之后，就会执行自己的相应处理逻辑，从而达到最终一致性。 本地消息表 业务系统写数据库和发送mq不是一个事务过程， 所以可能会存在写数据库成功，但发送mq失败， 此时就需要引入一个本地消息表，在写数据的同时写入一条消息到本地消息表中，一般状态分为“进行中”、“完成”等状态，由于写业务表和写本地消息表都是操作同一个DB，所以是一个本地事务，能够保证同时完成或同时失败。 引入本地消息表还有两个注意点： 需要有一个定时任务，去定期扫描消息表中不是完成状态的消息，进行重新发送 由于mq存在重复发送的问题，需要其他的业务系统做好幂等处理 缺点： 本地消息表与业务系统耦合比较严重， 对代码的抽象不好处理 由于每条消息都要写本地消息表，对数据库的压力比较大 支持事务的mq其实是对本地消息表的一个封装，如前文所说，普通的mq消息无法和单机数据库一样，具备提交、回滚的能力，所以支持事务的mq，比如rocketmq相当于将本地消息表在mq内部进行了实现。 其他方面的实现和本地消息表类似。 参考资料： https://www.cnblogs.com/lfs2640666960/p/12300585.html https://juejin.cn/post/7012425995634343966#heading-19","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"分布式","slug":"编程/分布式","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://acchw.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"分布式事务","slug":"分布式事务","permalink":"https://acchw.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"架构","slug":"架构","permalink":"https://acchw.top/tags/%E6%9E%B6%E6%9E%84/"},{"name":"mq","slug":"mq","permalink":"https://acchw.top/tags/mq/"}]},{"title":"drone和gitea集成以及hexo博客的自动部署","slug":"折腾/其他/drone和gitea集成以及hexo博客的自动部署","date":"2022-10-10T11:30:00.000Z","updated":"2022-10-10T11:30:00.000Z","comments":true,"path":"posts/46218/","link":"","permalink":"https://acchw.top/posts/46218/","excerpt":"","text":"未完待续！ 目的是为了实现hexo博客的自动部署， 每次push完之后， 触发drone ci自动进行部署。 选用drone的原因还是因为轻量， 且功能够用，如果用其他的CI工具，比如jenkins，我这小小的VPS部署服务一多，就扛不住了。 本文中drone是和gitea进行集成的， 如果要和其他仓库集成， 参考官方文档即可：https://docs.drone.io/ 部署服务还是通过docker来进行。 准备工作登录gitea, 进入设置-&gt;应用， 新建一个给drone用的OAuth2授权 注意， 重定向URI(Redirect URI)是你的drone服务的域名加上login。 生成授权之后， 会得到一个客户端ID和客户端秘钥， 记下来， 后面会用到。 drone搭建本文在部署的时候， 是将drone和gitea进行集成， drone的服务分为两部分： drone-server drone-runner-docker 本人将这两个服务都部署在同一个docker-compose.yml中，同时数据库还是连接的一个单独的mysql容器服务，所以需要先创建数据库， 命令如下： 1create database drone default character set utf8mb4 collate utf8mb4_unicode_ci; 下面是docker-compose.yml文件， 其中db-net就是一个包含mariadb容器的docker网络， 具体创建过程见另外一篇博客：个人博客工具搭建。各个参数见说明。 123456789101112131415161718192021222324252627282930313233343536373839404142434445version: &quot;3&quot;networks: db-net: external: trueservices: drone-server: image: drone/drone:2.12.1 container_name: drone-server restart: always networks: db-net: aliases: - drone ports: - &quot;6340:80&quot; volumes: - $&#123;PWD&#125;/data:/data - /var/run/docker.sock:/var/run/docker.sock environment: - TZ=Asia/Shanghai - DRONE_SERVER_HOST=drone服务的域名 - DRONE_SERVER_PROTO=https - DRONE_RPC_SECRET=自已生成的一个随机字符串即可 - DRONE_GITEA_CLIENT_ID=之前在gitea上生成的客户端ID - DRONE_GITEA_CLIENT_SECRET=之前在gitea上生成的客户端密钥 - DRONE_GITEA_SERVER=gite的地址 - DRONE_DATABASE_DATASOURCE=数据库连接地址，格式 username:password@tcp(host:port)/drone - DRONE_DATABASE_DRIVER=mysql - DRONE_USER_CREATE=username:sobriver,admin:true # 一定要配，否则无法登录gitea drone-runner-docker: image: drone/drone-runner-docker:1.8.2 container_name: drone-runner-docker restart: always depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - TZ=Asia/Shanghai - DRONE_RPC_HOST=drone服务的域名 - DRONE_RPC_PROTO=https - DRONE_RPC_SECRET=自已生成的一个随机字符串即可,和server的要一样 - DRONE_RUNNER_CAPACITY=2 - DRONE_RUNNER_NAME=docker-runner nginx配置123456789101112131415161718server &#123; listen 443 ssl; server_name 你的域名 charset utf-8; ssl_certificate 域名pem文件; ssl_certificate_key 域名key文件; ssl_session_timeout 5m; ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; proxy_pass http://localhost:6340; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; &#125;&#125; 服务启动之后，打开登录页面， 会自动跳转到gitea的登录， 登录成功之后， 对应于相应的仓库， 激活即可。 .drone.yml文件编写此处实现当我们写完一篇文章，push到远程之后，自动触发hexo的构建，并将构建完成之后的文件移动到博客文件目录。 在项目的根目录下创建.drone.yml文件， 内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344kind: pipelinetype: dockername: blog-jobsteps:- name: Hexo Build image: node:12-alpine commands: - npm install hexo-cli -g - npm install hexo-generator-sitemap --save - npm install hexo-generator-baidu-sitemap --save - npm install - hexo clean - hexo g- name: Origin File Clean image: appleboy/drone-ssh settings: host: from_secret: SSH_HOST port: from_secret: SSH_PORT username: from_secret: SSH_USERNAME password: from_secret: SSH_PASSWORD script: - rm -rf /blog/public/*- name: SCP File Transfer image: appleboy/drone-scp settings: target: /blog source: ./public host: from_secret: SSH_HOST port: from_secret: SSH_PORT username: from_secret: SSH_USERNAME password: from_secret: SSH_PASSWORD rm: true trigger: event: - push 说一下几个步骤含义： Hexo Build 使用hexo构建文件 Origin File Clean 清除原先文件， 此处设置的构建文件的存储路径为/blog/public/ SCP File Transfer 将构建完的文件移动到指定目录 其中from_secret的值是利用drone的secret来新建的，如下图所示： 几个值含义如下： SSH_HOST 远程登录主机的IP SSH_PORT 远程登录端口 SSH_USERNAME 远程登录用户名 SSH_PASSWORD 远程登录密码 参考资料： https://docs.drone.io/server/provider/gitea/ https://www.qikqiak.com/post/drone-with-k8s-2/","categories":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"其他","slug":"折腾/其他","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/tags/%E6%8A%98%E8%85%BE/"},{"name":"selfhost","slug":"selfhost","permalink":"https://acchw.top/tags/selfhost/"},{"name":"博客","slug":"博客","permalink":"https://acchw.top/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"drone","slug":"drone","permalink":"https://acchw.top/tags/drone/"}]},{"title":"记录服务异常重启导致clickhouse启动失败","slug":"编程/clickhouse/记录服务异常重启导致clickhouse启动失败","date":"2022-10-08T16:00:00.000Z","updated":"2025-01-21T05:49:52.460Z","comments":true,"path":"posts/41380/","link":"","permalink":"https://acchw.top/posts/41380/","excerpt":"","text":"测试环境中某个clickhouse实例由于意外断电而终止，重新启动报错，报错的关键信息 DB::ParsingException: Cannot parse input: expected ‘columns format version: 1\\n’ at end of stream 其中报错的日志如下： 1&#123;&#125; &lt;Error&gt; auto DB::MergeTreeData::loadDataParts(bool)::(anonymous class)::operator()() const: Code: 27. DB::ParsingException: Cannot parse input: expected &#x27;columns format version: 1\\n&#x27; at end of stream. (CANNOT_PARSE_INPUT_ASSERTION_FAILED), Stack trace (when copying this message, always include the lines below): 可以搜一下github上面的issue，也有几个类似的问题， 例如：https://github.com/ClickHouse/ClickHouse/issues/37397。 这个报错是因为clickhouse在启动服务的时候会检查损坏的数据文件块数量，如果超过一个特定值（默认是10，对应于max_suspicious_broken_parts配置），就会发生这个异常，导致无法启动。 而出现这么多损坏的文件块数据，是因为在系统异常断电的时候，有些数据还存在于内存中，并没有完全写入磁盘，导致出现数据不一致的情况。 解决方案有两个： （1）调整max_suspicious_broken_parts值 让其在启动时能允许更多的损坏，但是这个值不好把控，主要取决于在断电的那一瞬间，不一致的数据量有多大，本人自测当调整到10000的时候，才能正常启动。 修改配置文件中如下配置： 12345&lt;yandex&gt; &lt;merge_tree&gt; &lt;max_suspicious_broken_parts&gt;50&lt;/max_suspicious_broken_parts&gt; &lt;/merge_tree&gt;&lt;/yandex&gt; (2) 强制启动 在clicckhouse数据根目录下的flags文件夹下创建一个force_restore_data文件，然后再重启服务即可。假设现在clickhouse的数据根目录是&#x2F;var&#x2F;lib&#x2F;clickhouse， 则执行如下命令： 1touch /var/lib/clickhouse/flags/force_restore_data 注意，无论上面哪种方式，都有可能会导致数据丢失。 参考文档： https://github.com/ClickHouse/ClickHouse/issues/37397 https://kb.altinity.com/altinity-kb-setup-and-maintenance/suspiciously-many-broken-parts/","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"clickhouse","slug":"编程/clickhouse","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/clickhouse/"}],"tags":[{"name":"clickhouse","slug":"clickhouse","permalink":"https://acchw.top/tags/clickhouse/"}]},{"title":"mysql中undo、redo、binlog日志区别和说明","slug":"编程/mysql/mysql中undo、redo、binlog日志区别和说明","date":"2022-10-04T18:00:00.000Z","updated":"2022-10-04T18:00:00.000Z","comments":true,"path":"posts/50187/","link":"","permalink":"https://acchw.top/posts/50187/","excerpt":"","text":"本文针对的都是MySQL的Innodb引擎。 1. binlog二进制日志。记录数据库的所有写操作。注意此处记录的是逻辑日志。 可用于主从复制、增量备份、监听binglog实现缓存一致性。 1.1 常用命令12345678-- 查看binlog配置信息show variables like &#x27;%log_bin%&#x27;;-- 查看所有的binlog文件show binary logs;-- 查看当前正在使用的binlog文件show master status; 1.2 写入策略通过show binary logs命令可以看到当前数据库使用的哪些binlog文件， 如下图所示： mysql会按照一定的规则，生成对应的日志文件，并按照编号从小到大依次生成。 binlog日志在写入时， 按照其日志记录类型不同， 分为如下三种情况： statement： 记录的是sql原文， 每一条对数据的写操作都会记录在binlog中 优点： 不需要记录每一行的变化， 能够减少binlog日志量，提升性能。 缺点：由于记录的是sql原文，所以还需要记录一些额外的相关信息，用来确保在master和slave上执行都是相同的效果。另外有一些函数是无法被复制的， 例如 UUID() row：记录的是每一行的变化 优点：可以清楚的表示每一行的数据变化，所以不需要记录额外信息，同时也无需担心函数执行在不同的节点上会有不同的效果 缺点：会产生大量的日志，特别是那些涉及到整个表的操作，比如增加一个字段，会对该表的所有记录都会产生一条binlog mixed 混合模式。普通操作使用statement，当无法使用statement时，则使用row 2. redo log 重做日志。redo log 是物理日志格式, 存储的是对于每个页的修改的物理情况。 用来保证事务的原子性和持久性。 2.1 作用mysql为了提高效率，对于数据的修改首先都是在内存中进行的，也就是下图中的Buffer Pool，然后按照一定的策略刷新到磁盘中去。 此时就会存在一个问题， 当数据被写入到内存， 但是还没有刷新到磁盘，此时若数据库宕机，那么该数据页上的数据就会丢失。 为了解决这个问题，mysql引入了redo log， 每次对数据页的修改，都会存储到一个redo log日志文件中去，当出现异常宕机后，数据库实例重新启动时，就会去检查这个redo log文件，并对事务进行重放，从而恢复数据。 2.2 写入策略redo log 也并不是直接写入磁盘的，而是先写入到redo log buffer， 然后按照一定的条件顺序的写入到磁盘中去。 redo log文件路径： 在数据根目录下会有两个文件ib_logfile0和ib_logfile1两个文件， 都是用来存储redo log的， 并且写入的时候是轮流写入的。 redo log 分为两部分: redo log buffer 内存中的重做日志缓存, 易丢失 redo log file 磁盘中的重做日志文件, 持久化 参数innodb_flush_log_at_trx_commi 控制重做日志redo log buffer刷新到磁盘的策略, 默认值为1, 其取值含义如下: 取值1： 事务提交时必须调用一次fsync操作， 默认值。这种情况不会造成redo log本身的丢失， 假设一种极端情况， 当事务未提交时，数据库宕机，当数据库重新启动的时候， 因为这个事务没有写入到redo log, 所以也没有办法进行恢复， 但这种情况本身也是符号预期的。 取值0：事务提交时不进行fsync操作。那么什么时候将其刷新到磁盘呢? 在master thread中, 每隔1秒就会进行一次fsync操作。这种情况可能会造成这一秒内的数据丢失。 取值2： 事务提交时, 仅将重做日志刷新到文件系统系统缓存, 不进行fsync操作，由文件系统来负责进行刷盘操作。 当服务器发生宕机时，当文件系统的缓存还未刷新到磁盘，也会造成数据的丢失。 综上， 要想保证数据一定不会丢失， 需要将 innodb_flush_log_at_trx_commi设置为1， 其他两种情况都有可能会造成数据的丢失。 此处有一个问题， 既然redo log也要写入文件， 那为啥不直接将buffer pool中的数据直接刷新到磁盘呢？ 有两个原因： redo log 写入的时候是顺序写入的， 而buffer pool中的数据页在磁盘中是随机存储的，所以其写入也是随机写的， 而我们直到磁盘顺序写入和随机写入的性能差距很大 通常一次数据修改，涉及到的数据很小，此时redo log就会很小，可能只有几个字节。而buffer pool中的每个数据页大小都是16KB， 写入的时候是以数据页为单位进行的，所以最小也是16KB， 相对而言， 写入的数据量更小，性能也会更高 注意，在8.0之后， mysql将AUTO_INCREMENT计数器的变化也写入到重做日志中， 当 MySQL 服务被重启或者处于崩溃恢复时，它可以从持久化的检查点和重做日志中恢复出最新的 AUTO_INCREMENT 计数器，避免出现不单调的主键。 2.3 redo与bin区别 写入时机不同。 binlog只有在事务提交完成后才会写入，所以一个事务中，只会存在一次写。而redo log在事务进行中会不断的写入到重做日志文件中 记录内容不同。 无论binlog按照哪种方式进行存储，其存储的都是对数据的一个变更， 可以理解为我们平时写的一个sql。而redo log记录的则是对于数据页的物理修改 产生地点不同。 redo是在InnoDb存储引擎层产生的，而bin是在数据库上层产生的， 其bin日志所有的存储引擎都会产生 3. undo log 回滚日志。存储的是逻辑方面的日志。 可以用来实现事务的原子性。 undo log日志存放在数据库内部一个特殊的段中，这个段就是undo段。undo段存储在共享表空间中。 3.1 作用undo log主要有两个作用： 回滚: 如果由于某种异常需要回滚或者用户主动发起回滚， 此时通过undo log就能实现。 注意， 由于undo log 是逻辑日志，所以在回滚的时候也只是逻辑的恢复数据， 但是数据结构和页本身在回滚之后， 可能和之前的不一定相同。 MVVC: 多版本并发控制。在进行快照读的时候，如果记录此时被其他事务占用， 那么此时就直接通过undo log读取之前的行版本信息， 从而非锁定读。 3.2 写入策略undo log 为了保证更好的并发以及多版本控制，所以其存储不应该因为物理存储变化而变化，所以undo log采用了逻辑存储的方式，来保存这些数据的历史版本。所以在数据库中， 是可能存在一行数据的多个历史版本的， 这些数据在InnoDb看来，和其他的数据没有什么区别，所以，同样的，也会写自己的redo log，通过redo log来保证自己的原子性。 对于undo log, 分为两种： Insert Undo: 对于插入操作，由于其并没有历史版本，所以此处并不需要MVCC，记录undo的目的仅仅是为了回滚 Update Undo: 对于更新操作，MVCC需要存储多个历史版本，所以需要存储的信息就比insert类型的多。 3.3 undo与redo区别 在对数据库进行修改时, 不仅会产生redo log, 还会产生一定的undo log redo log是存储在文件里的, 但是undo log是存储在共享表空间一个特殊的段segment内的(undo segment) 参考资料： 《MySQL技术内幕》 http://mysql.taobao.org/monthly/2015/04/01/","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"mysql","slug":"编程/mysql","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://acchw.top/tags/mysql/"},{"name":"日志","slug":"日志","permalink":"https://acchw.top/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"个人博客工具搭建","slug":"折腾/博客/个人博客工具搭建","date":"2022-10-04T17:30:00.000Z","updated":"2023-02-08T17:30:00.000Z","comments":true,"path":"posts/28646/","link":"","permalink":"https://acchw.top/posts/28646/","excerpt":"","text":"背景记录一下本人VPS上搭建的几个专门为个人博客使用的一些工具软件，为了方便， 都是使用docker进行部署，并且为了便于保存，使用docker-compose方式启动，方便后续修改。 因为vps的规格较低，所以在挑选工具时，会尽量偏向于内存占用小的。 下面介绍一下用到的一些工具， 都采用docker自建服务。 公用数据库搭建为了尽量减小资源，专门部署了一个mysql实例（docker方式），各个需要数据库的服务都会建立一个自己的库，然后都连接到这个实例上。 mysql实例的docker-compose.yml文件如下， 在这之前，需要创建一个docker网络，然后将所有需要连接到该数据库的docker服务都连接到该网络上即可，具体连接方法可参考下面的umami或waline中的配置。 此处创建的docker网络名为db-net，创建命令：docker network create db-net mysql的docker-compose.yml文件 123456789101112131415161718192021222324version: &quot;3&quot;networks: db-net: external: trueservices: mariadb: image: mariadb:10.5.9 container_name: mariadb restart: always environment: - MYSQL_ROOT_PASSWORD=****** - MYSQL_USER=root - MYSQL_PASSWORD=****** ports: - 3306:3306 networks: db-net: aliases: - mariadb volumes: - $&#123;PWD&#125;/data:/var/lib/mysql - /etc/timezone:/etc/timezone:ro - /etc/localtime:/etc/localtime:ro 数据统计umami搭建一个个人站点数据统计工具， 界面看上去比较清新简洁。 需要先连接到mysql上先创建一个数据库 umami，登录到数据库， 然后执行如下命令： create database umami default character set utf8mb4 collate utf8mb4_unicode_ci; docker-compose.yml文件内容如下： 12345678910111213141516171819version: &#x27;3&#x27;networks: db-net: external: trueservices: umami: image: ghcr.io/mikecao/umami:mysql-latest container_name: umami ports: - &quot;12000:3000&quot; networks: db-net: aliases: - umami environment: DATABASE_URL: mysql://root:*****@mariadb:3306/umami DATABASE_TYPE: mysql HASH_SALT: ****** restart: always 在hexo博客根目录下的scripts目录，找到一个index.js文件（如果没有就自己创建一个)，在里面加上如下一行： 1hexo.extend.injector.register(&#x27;head_end&#x27;,&#x27;&lt;script async defer data-website-id=&quot;****&quot; src=&quot;*******&quot;&gt;&lt;/script&gt;&#x27;,&#x27;default&#x27;); 其中 script 内容是从umami上获取的跟踪代码 评论系统waline搭建一个博客的评论系统。可以自己部署。 需要先连接到mysql上先创建一个数据库 waline，登录到数据库， 然后执行如下命令： create database waline default character set utf8mb4 collate utf8mb4_unicode_ci; docker-compose.yml文件如下： 12345678910111213141516171819202122232425262728293031version: &#x27;3&#x27;networks: db-net: external: trueservices: waline: container_name: waline image: lizheming/waline:latest restart: always ports: - 8360:8360 volumes: - $&#123;PWD&#125;/data:/app/data networks: db-net: aliases: - waline environment: TZ: &#x27;Asia/Shanghai&#x27; MYSQL_HOST: mariadb MYSQL_PORT: 3306 MYSQL_DB: waline MYSQL_USER: root MYSQL_PASSWORD: ****** JWT_TOKEN: &#x27;******&#x27; SITE_NAME: &#x27;******&#x27; SITE_URL: &#x27;*******&#x27; SECURE_DOMAINS: &#x27;*********&#x27; AUTHOR_EMAIL: &#x27;**********&#x27; IPQPS: 10 #基于 IP 的评论发布频率限制,单位s 这上面的一些配置可以自己查看文档， 传送门 https://waline.js.org/ 上面的关键配置是SECURE_DOMAINS， 需要加上自己博客的域名， 否则你的博客将无法访问。","categories":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"博客","slug":"折腾/博客","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/tags/%E6%8A%98%E8%85%BE/"},{"name":"selfhost","slug":"selfhost","permalink":"https://acchw.top/tags/selfhost/"},{"name":"博客","slug":"博客","permalink":"https://acchw.top/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"umami","slug":"umami","permalink":"https://acchw.top/tags/umami/"},{"name":"waline","slug":"waline","permalink":"https://acchw.top/tags/waline/"}]},{"title":"个人笔记软件的选择","slug":"折腾/其他/个人笔记软件的选择","date":"2022-07-03T00:00:00.000Z","updated":"2023-04-21T00:00:00.000Z","comments":true,"path":"posts/18945/","link":"","permalink":"https://acchw.top/posts/18945/","excerpt":"","text":"写这篇文章的目的， 主要是为了记录一下自己使用的笔记软件的过程以及最终选择（当然也只是目前的选择， 后续会不会变就不清楚了）， 给其他同样有此问题的人一个参考。 先说一下本人选择笔记软件的一些原则： 数据要掌握在自己手上，放在云上的我感觉都不安全， 因为开发该软件的公司哪天收费或倒闭了， 你自己的数据就没了或者不好弄出来 要多端都能使用 方便同步 最好能自己部署 为知笔记推荐星级：★ 这是我个人早起用的时间比较长的一个笔记软件， 是一个传统的笔记软件， 使用过程中陆陆续续出现过一些晓问题， 后来为知强制收费， 加上对其富文本格式的担心，花了一天的时间把数据都迁移出来了。 为知笔记有一个官方的docker镜像， 可以自己部署使用， 但是有些功能还是需要连接到官方使用， 所以不是很友好。 最终弃之。 typora + 坚果云推荐星级：★★★ 在不使用为知笔记之后， 我一直在寻找替代品， 包括印象笔记，有道笔记等， 但都不符合预期， 且不符合数据掌握在自己手中的原则。在这个过程中，了解到了markdown这一文本格式， 就迅速的爱上他了。 再结合数据同步与备份， 便使用了 typora + 坚果云这一组合。这个组合其实还蛮好用的， 但是有三个致命缺点： 不能全文搜索， 特别是笔记一多，有时想找个之前记录的东西又不记得文件名， 很费事 目录树的组织不够清晰明了 坚果云的免费额度较低， 不过只作为笔记同步的话一般够用了 当然，这个组合我目前还在轻微使用， 但是很少用来记录笔记了。 confluence推荐星级：★★★ 这是在公司使用的一个wiki系统， 感觉挺好用的， 然后网上找了一下， 发现有它的docker镜像， 然后就在自己的VPS上部署用了一下， 确实还可以。 这个是完全基于web的应用， 所以只要有浏览器， 都能用， 不用考虑跨平台的问题， 且结合其他插件， 功能还是很强的。 但是也有几个不尽如人意的地方： 资源占用较大。 咱的VPS是一个小水管， 属实有点耗不起 对markdown的支持不是很全面。 有些操作还是需要手动点击相应的按钮才能实现 总体来说， 这个还是比较好用的。本人也有一篇使用docker介绍其安装过程的[博客][https://acchw.top/%E6%8A%98%E8%85%BE/%E5%85%B6%E4%BB%96/docker%E5%AE%89%E8%A3%85confluence.html]。 notion推荐星级：★★★ 说实话， 这个软件我是非常喜欢的， 不管是文字输入还是排版等方面， 都很舒适， 特别是其database功能，真的很强大。 但是其有一个致命缺点， 其服务器在国外， 虽然现在国内在不挂梯子的情况下也能访问， 但是网速还是比较慢， 而且谁也不知道哪天就被ban了。 同时也不支持自建服务， 所以最终还是放弃了。 但是这个软件给我带来的结果就是， 我后面寻找的软件很多都是以它为标准的， 或者说就是寻找它的替代品。 github上有个非常火的项目AppFlowy 就是它的一个替代品， 但是现在还很不完善， 所以暂时放弃。 如果你对上面这些缺点不是很在乎， 那么notion将是一个很好的选择。 outline推荐星级：★ 支持自建服务。但是其登录选项不好弄， 个人弄了半天才成功， 而且使用之后， 感觉也不是很惊艳， 所以试用了一下就放弃了。 trilium推荐星级：★ 支持自建服务。 说实话， 它的颜值确实不敢恭维，这也是我放弃他的最大原因，所以在试用了一下也放弃了。 思源笔记推荐星级：★★★★★ 这是我目前在用的主力软件。和notion比较像，功能还是很强大的。 对mardown的支持也非常好， 基本上我平时用的markdown语法都支持， 也支持将文章导出为markdown格式。 搜索功能也很强大， 总之，比较完美的符合了我现在的一切要求。 支持docker伺服，所以我直接部署在VPS上了， 只需要做好VPS的数据备份即可。 下面这张是我用的集市里面的notion主题， 颜值一下子就上去了。 贴一个docker-compose.yml文件，内容如下， 使用docker-compose up -d命令直接启动即可。 1234567891011version: &quot;3&quot;services: siyuan: image: b3log/siyuan container_name: siyuan restart: always volumes: - $&#123;PWD&#125;/data:/siyuan/workspace/ command: [--workspace=/siyuan/workspace/] ports: - 6806:6806 配置nginx转发的时候， 需要注意一下， &#x2F;ws的也需要配置。 123456789101112131415161718192021server &#123; listen 443 ssl; server_name 你的域名 charset utf-8; ssl_certificate /etc/nginx/cert/域名pem文件; ssl_certificate_key /etc/nginx/cert/域名key文件; ssl_session_timeout 5m; ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; proxy_pass http://localhost:6806; &#125; location /ws &#123; proxy_pass http://localhost:6806; proxy_read_timeout 60s; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &#x27;Upgrade&#x27;; &#125;&#125;","categories":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"其他","slug":"折腾/其他","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/tags/%E6%8A%98%E8%85%BE/"},{"name":"selfhost","slug":"selfhost","permalink":"https://acchw.top/tags/selfhost/"},{"name":"笔记","slug":"笔记","permalink":"https://acchw.top/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"ConcurrentHashMap源码分析","slug":"编程/java/ConcurrentHashMap源码分析","date":"2022-06-20T22:00:00.000Z","updated":"2022-07-02T17:30:00.000Z","comments":true,"path":"posts/42939/","link":"","permalink":"https://acchw.top/posts/42939/","excerpt":"","text":"ConcurrentHashMap的实现机制是一直在变化的， 其中8的变化较大， 下面分别说明一下在Java7和Java8中他们的实现机制。 Java 7 实现原理主要是基于分离锁来实现的。这样做的目的是， 在进行并发操作的时候， 只需要锁住相应的Segment, 而不需要去锁住整个数据， 提高并发性能。 存储数据的是一个个的Segment，Segment是继承自ReentrantLock，所以它本质上就是一个锁。 每个Segment内部都有一个HashEntry的数组， 这个HashEntry数组存储方式和HashMap内部的table数组类似， 哈希相同的元素也是以链表形式存储。 get在并发的时候，get操作只要能保证可见性即可， 所以没有同步操作。 定位元素所属的segment 利用jdk提供的Unsafe方法保证以可见性的方式获取元素，UNSAFE.getObjectVolatile() put 利用UNSAFE.getObject() 方法获取元素所属的segment 利用所属的segment获取可重入锁，从而将该segment锁住， 防止其他的线程进行并发写 会有一个无线循环， 在该循环内部， 会确定该元素的key是否在HashEntry数组中， 从而决定是进行插入还是更新。 size由于需要考虑并发， 计算总容量的时候， 如果锁住整个数据，会导致性能很差。所以ConcurrentHashMap在此处使用了重试机制。 在进行size操作的时候， 通过重试机制（默认2次）获取值，如果重试的时候没有发生变化， 则直接返回旧值， 如果发生了变化，则还是要通过获取锁来进行计算。 Java 8 实现原理和HashMap类似，其内部存储数据的结构是也是一个大的桶数组Node[]， 数组节点是链表或者是红黑树。其数组定义如下： 1transient volatile Node&lt;K,V&gt;[] table; 总结几点： 内部虽仍然有Segment的定义, 但是只是为了保证序列化的兼容性， 并没有任何用处 Node中的value和next都是用volatile来修饰， 保证变量的可见性 大量使用CAS操作， 可以有效减少锁的使用 put 对上面源码几处关键处进行一下说明： 当数组为空的时候进行初始化， 说明初始化的调用时机是第一次put的时候， 和HashMap类似 定位当前数组下标处是否存在节点， 若不存在，则利用CAS尝试写入， 如果失败则自旋保证成功，因为此处是使用CAS进行写入， 所以是不需要加锁的。定位索引的方法（与HashMap一样）： i = (n - 1) &amp; hash 如果检测到当前正在扩容， 则帮助其进行扩容 当以上条件都不满足时， 说明此处已经存在节点， 则对该节点上锁， 此处直接使用synchronized进行加锁， 且加锁的对象只是该节点而不是整个数据 获取该节点的锁之后， 判断该节点类型， 若是链表，则遍历链表插入 若是红黑树，则遍历红黑树插入 判断是否要将链表转换为红黑树，临界值和HashMap一样也是8 其整体流程与HashMap较为相似， 就其中几个关键不同之处进行说明： 当插入一个新节点的时候， HashMap是直接插入，而ConcurrentHashMap使用CAS进行无锁插入 ConcurrentHashMap多了一个状态判断， 当发现Map正在扩容，则调用helpTransfer()帮助其进行扩容， 以加快扩容速度。 当索引处已经存在节点， 此时往该索引处添加元素时， ConcurrentHashMap 首先对该节点加锁， 在获取到该节点的锁之后再进行后续操作， 这样既能保证插入操作的线程安全性，同时因为只对该节点加锁，没有对整个数据加锁， 从而减少锁竞争， 提高效率。 getget方法没有加锁， 而是利用CAS来进行处理， 可以提高查询效率。 下面是源码对应的关键几步进行分析： 利用CAS获取数组列表下标处的节点 如果当前节点（链表头结点）刚好是要找的节点， 则直接返回当前节点值 如果eh&lt;0, 表示当前正在扩容或者该位置是红黑树， 调用find查找 以上条件都不满足， 表明该位置是链表， 遍历链表进行查找 size其调用的是sumCount()方法，采用分而冶之进行计数 1234567891011final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum; &#125; CAS简单介绍上面章节中多次提到cas，下面简单介绍一下。 Compare and Swap， 比较并交换， 包含了两个动作。在现代CPU中，提供了一个CAH指令，保证这两个动作的原子性。 CAS的核心有三个参数： V 内存位置 A 旧的预期值 B 要修改的值，也就是新值 首先要明白， 每个线程都会有一个自己的内存空间，在进行操作时， 首先会将主内存的值copy一份到自己的线程内存空间， 然后再刷新到主内存。 举一个简单例子， 比如a+1 这个操作，此时a的值时0， 当有thread1、thread2两个线程都执行的时候， 其情况是怎么样的？ thread1、thread2将主内存中的a的值copy到自己的线程内存空间，此时对于这两个线程而言，他们的 预期值 A 都是0， 要修改的值 B 都是1 然后就会执行 比较并交换的动作， thread1将a的旧预期值与主内存中a的值进行比较， 此时发现两者相等，就会直接将要修改的值a&#x3D;1刷新到主内存， 此时主内存中a的值就变成了1 此时thread2在提交的时候，发现a的预期值0与主内存中a的值1不相等， 就会放弃本次提交。提交失败之后，会继续重复执行步骤1的操作， 直到成功。 使用UnSafe操作cas是不推荐的， 在Java9之后， 提供了VarHandle来进行CAS操作， 一般流程都是首先获取变量句柄，然后调用其cas方法。 CAS中常见的一个A-B-A问题，由于CAS是在更新时比较新值与旧值，如果刚好新值从A变为B再改为A， 此时这个比较实际上就无效了， Java提供了一个AtomicStampedReference类， 为引用建立版本号， 每次变更值的时候， 版本号都会发生变化， 从而确定该值是否真的改变。","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"java","slug":"编程/java","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://acchw.top/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"https://acchw.top/tags/jvm/"}]},{"title":"HashMap源码分析","slug":"编程/java/HashMap源码分析","date":"2022-06-19T21:00:00.000Z","updated":"2025-01-21T05:49:52.460Z","comments":true,"path":"posts/41417/","link":"","permalink":"https://acchw.top/posts/41417/","excerpt":"","text":"基本原理HashMap是由数组Node&lt;K,V&gt;[] table 和链表（或者树）组成的一个复合结构。 数组被分成一个个的桶（buket），通过下面的这个算法决定元素在桶中的位置： 12// n为数组长度，hash为key的哈希值p = tab[i = (n - 1) &amp; hash] 若p相同，则以链表形式存储。当链表长度超过阈值（TREEIFY_THRESHOLD&#x3D;8）时，则将链表转换为红黑树。 此处为什么需要这么做? 主要是基于查询的效率考虑。链表查询元素的时间复杂度为O(n)，随着链表长度的增大，查询时间也会递增。而红黑树的时间复杂度为O(logn)，此处是一个以空间换时间的典型案例。 HashMap中几个特殊值说明： initialCapacity：HashMap初始容量，默认为16 loadFactor：负载因子，默认0.75 threshold：键值对数量的最大值（不是table数组的长度），超过这个值，则需要扩容，会变为原先值的两倍 TREEIFY_THRESHOLD：链表转换红黑树阈值，默认为8， 当超过该值时， 链表就会转换为红黑树 哈希值计算key本身的哈希值不是通过hashCode得到的， 而是HashMap自己实现的一个算法。 1234static final int hash(Object kye) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt;16);&#125; 上述代码实现了将高位数据移位到低位进行异或运算，是因为有些数据计算出来的哈希值差异主要就在高位，而其哈希寻址是忽略容量以上的高位的，所以通过这样处理， 就能有效避免上述情况的哈希碰撞。现实中，构造哈希冲突并不是很难，恶意代码就有可能会通过该手段造成大量的哈希碰撞，造成服务器CPU大量占用。 插入流程首先计算key的哈希值， 然后调用putVal()函数。 下图是putval()函数的源码， 就其中的关键几步进行说明 当数组为空，则调用resize()函数进行数组的初始化操作。该处代码表明HashMap中数组的初始化并不是在new的时候，而是在第一次put的时候。 使用(n - 1) &amp; hash计算数组下标，若当前项不存在，则调用newNode()函数在数组下标处新建一个节点。 当以上条件都不满足， 说明该处索引已经存在节点，此时就该进行链表或树操作了。3、4、5是对应不同类型的。其中3是直接判断当前节点， 4则是树节点， 5是链表。 此处需要判断该节点处的key和待存入数据的key是否相等。判断相等的条件如下（之间是且的关系）： 将要存入数据key的哈希值和数组下标处节点的哈希值相等 将要存入数据的key和数组下标处节点的key相等（此处相等是内存地址相等或者equals比较相等都可以） 该代码表明该处数组下标处的节点是树节点， 所以此时调用putTreeVal()函数插入树节点。 当3和4都不满足时，则表明该处是一个链表，则进行链表的遍历。 若一直能遍历到链表尾部，则在链表尾部新建一个节点储存当前待存入数据。然后判断是否要将链表（TREEIFY_THRESHOLD）转化为红黑树， 若是则调用treeifyBin()函数进行链表的树化。 若链表中某个节点的key与待存入数据的key相等（与第3步的判断条件一样），则退出遍历。 判断之前是否已经存在key值相同的节点，若是此时根据onlyIfAbsent参数来决定是否将之前节点的值更新为本次要插入的值（实际上map默认的put操作该值为true,表明是覆盖插入） 判断是否要进行扩容操作， 若是则调用resize()函数进行扩容。注意此处的++resize操作可能导致线程不安全。 扩容resize()函数。该函数有两个用途： 创建初始的存储数组 容量不足的时候， 进行扩容 下面是resize函数关键几步分析： 基本流程： 当扩容之前的数组长度大于最大值时，直接返回未扩容之前数组（也就是不进行扩容），此处表明当HashMap容量达到最大值时（Integer.MAX_VALUE)，继续插入新值虽然不会报错， 但实际上并没有生效， 返回的仍是原数组。 当元素个数大于阈值（默认初始容量16 * 负载因子0.75 &#x3D; 12）时进行扩容，将新数组长度和阈值都扩大为原先2倍 能进入该分支表明是第一次初始化，设置数组容量大小（指定值或者默认值）和阈值大小 重新初始化一个新的数组，数组长度是原先的2倍 开始进行重哈希，将原数组项的数据重新放入新的数组项里面，这是扩容时消耗时间最长的地方。此处需要遍历原数组， 具体步骤如下： 6处表明当前下标处没有值，则直接将元素插入到新数组项中 7处表明当前数组项是一个红黑树，进行红黑树的重新赋值 8处，当以上两种情况都不符合，肯定是链表节点，则进行链表的重哈希，需要遍历链表 链表节点的重哈希 有必要说明一下，此处设计的比较巧妙,具体描述可见文章：https://yikun.github.io/2015/04/01/Java-HashMap%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/ JDK中解释resize函数的说明大意如下： 当进行扩容时，因为我们每次扩容容量都是之前的2倍，任意元素在新数组中要么是原先的位置，要么是原位置移动2次幂的位置。 其具体原理是利用0与0或者1进行&amp;运算结果都是0，这样在进行重hash的时候，不需要重新计算Hash值，只需要判断原先的Hash值新增的那一位是0还是1，若为0，则原先位置，若为1，则索引变为“oldCap+原索引”。 这地方有几点需要注意： 判断索引是否改变用的是 hash &amp; oldCap，此处与计算索引值**(n - 1) &amp; hash**需要区分开来 链表转化红黑树treeifyBin()函数。在链表长度超过8的时候，使用该函数将链表转化为红黑树。 其主要思路如下： 当整个数组桶的长度小于64时，此时并不会进行树化操作，只是进行扩容。注意，在进行扩容的时候，链表的长度有可能会变短 将链表中的节点转化为树节点TreeNode，形成一个新的链表 将新链表节点赋值给给定的数组项 调用TreeNode的treefify()方法将该处的链表转化为红黑树，该函数大致步骤如下： 插入树节点元素，具体可以参考二叉搜索树的插入操作。在进行插入的时候，比较key的hash值来决定插入的方向。 插入完成之后开始调整红黑树，使其符合红黑树的特性 查找getNode()函数。提供常数时间复杂度的查找效率。 根据(n - 1) &amp; hash计算得到该key所在的桶bucket，若桶不存在或者数组table为空，则直接返回null，根据这一点我们可以知道HashMap取元素的方法get和判断元素是否存在的contanins方法的时间复杂度都是O(1) 当桶存在时，首先判断该桶上第一个节点是否就是要找的节点，若是直接返回该节点值 若不是，判断节点类型，若是红黑树，则遍历红黑树查找，若是链表，则遍历链表查找","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"java","slug":"编程/java","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://acchw.top/tags/java/"},{"name":"jdk","slug":"jdk","permalink":"https://acchw.top/tags/jdk/"}]},{"title":"java大图片压缩与裁剪时防止oom","slug":"编程/java/java大图片压缩与裁剪时防止oom","date":"2022-05-01T18:40:00.000Z","updated":"2022-05-01T18:40:00.000Z","comments":true,"path":"posts/59491/","link":"","permalink":"https://acchw.top/posts/59491/","excerpt":"","text":"常规使用java进行图片裁剪或压缩的时候， 比如使用ImageIO.read()读取图片信息的时候， 或者使用Thumb nails框架进行压缩时， 都会调用DataBufferByte类的下面这个方法： 12345678910public DataBufferByte(int size, int numBanks) &#123; super(STABLE, TYPE_BYTE, size, numBanks); bankdata = new byte[numBanks][]; for (int i= 0; i &lt; numBanks; i++) &#123; // 构造数组 bankdata[i] = new byte[size]; &#125; data = bankdata[0];&#125; 当图片像素很大时， size的值会很大， 此时构造这个数据就有可能会出现oom，比如当一张6.4M的图片， 宽高是5472*7296， size的值是114M。 基于此， 可以基于采样的方式进行， 不需要引用任何第三方库， 具体代码如下： 1234567891011121314151617181920212223242526272829303132333435363738public static byte[] resize(byte[] srcFileData, int width, int height) &#123; ImageInputStream input = null; ImageReader reader = null; try &#123; input = ImageIO.createImageInputStream(new ByteArrayInputStream(srcFileData)); Iterator&lt;ImageReader&gt; readers = ImageIO.getImageReaders(input); reader = readers.next(); reader.setInput(input); //原始图像的长和宽 int srcWidth = reader.getWidth(0); int srcHeight = reader.getHeight(0); ImageReadParam param = reader.getDefaultReadParam(); int sampling = Math.min(srcWidth/width, srcHeight/height); //采样压缩, 其中sampling的值表示每隔多少个像素点取一个像素 param.setSourceSubsampling(sampling, sampling, 0, 0); // 裁剪 param.setSourceRegion(new Rectangle(0, 0, srcWidth, srcHeight)); BufferedImage bufferedImage = reader.read(0, param); ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); ImageIO.write(bufferedImage, &quot;jpg&quot;, outputStream); return outputStream.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; input.close(); if (reader != null)&#123; reader.dispose(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return new byte[]&#123;&#125;;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"java","slug":"编程/java","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://acchw.top/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"https://acchw.top/tags/jvm/"}]},{"title":"arthas中如何获取Bean","slug":"编程/java/arthas中如何获取Spring中的Bean","date":"2022-02-08T10:00:00.000Z","updated":"2022-02-08T10:00:00.000Z","comments":true,"path":"posts/28416/","link":"","permalink":"https://acchw.top/posts/28416/","excerpt":"","text":"现在大部分应用都是通过Spring来管理对象， 在使用arthas分析线上问题时， 如何获取Spring中已经注入到容器中的Bean， 主要是使用tt命令。 首先执行如下命令，等待输出 1tt -t org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter invokeHandlerMethod -n 3 假设要搜索的类名为com.example.DemoService， 注意此处需要使用类的全限定名。 1tt -i 1000 -w &#x27;target.getApplicationContext().getBean(&quot;com.example.DemoService&quot;).getTargetSource().target&#x27;","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"java","slug":"编程/java","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://acchw.top/tags/java/"},{"name":"arthas","slug":"arthas","permalink":"https://acchw.top/tags/arthas/"},{"name":"spring","slug":"spring","permalink":"https://acchw.top/tags/spring/"}]},{"title":"arthas的一些使用技巧","slug":"编程/java/arthas的一些使用技巧","date":"2022-02-08T10:00:00.000Z","updated":"2024-01-09T18:20:00.000Z","comments":true,"path":"posts/28416/","link":"","permalink":"https://acchw.top/posts/28416/","excerpt":"","text":"arthas获取spring中的bean现在大部分应用都是通过Spring来管理对象， 在使用arthas分析线上问题时， 如何获取Spring中已经注入到容器中的Bean， 主要是使用tt命令。 首先执行如下命令，等待输出 1tt -t org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter invokeHandlerMethod -n 3 假设要搜索的类名为com.example.DemoService， 注意此处需要使用类的全限定名。 1tt -i 1000 -w &#x27;target.getApplicationContext().getBean(&quot;com.example.DemoService&quot;).getTargetSource().target&#x27; arthas获取http请求的入参和出参有时我们需要线上跟踪某个请求的入参和出参， 此时可以使用arthas的watch命令。 基于spring的工程，所有请求都会走RequestMappingHandlerAdapter的invokeHandlerMethod方法， 所以跟踪此方法。 有两点说明一下： 此处只打印了request，所以是params[0] 使用uri来过滤请求地址 当然能看到的信息还有很多， 具体可以参考watch命令。 1watch org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter invokeHandlerMethod &#x27;params[0]&#x27; &#x27;params[0].getRequestURI().contains(&quot;/ai/img&quot;)&#x27; -x 2","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"java","slug":"编程/java","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://acchw.top/tags/java/"},{"name":"arthas","slug":"arthas","permalink":"https://acchw.top/tags/arthas/"},{"name":"spring","slug":"spring","permalink":"https://acchw.top/tags/spring/"}]},{"title":"Linux中文件权限说明","slug":"编程/linux/Linux中文件权限说明","date":"2021-12-19T16:30:00.000Z","updated":"2021-12-19T17:30:15.000Z","comments":true,"path":"posts/47908/","link":"","permalink":"https://acchw.top/posts/47908/","excerpt":"","text":"概述 Linux下的文件权限包括读， 写， 执行， 英文简写分别是 r, w, x 文件权限包含三个方面： 拥有者， 用户组， 其他组。每个文件可分别对这三个方面设置不同的rwx权限。通常情况下，一个文件只能归属于一个用户和组， 如果其它的用户想有这个文件的权限，则可以将该用户加入具备权限的群组，一个用户可以同时归属于多个组。 查看文件权限ls -l 输出格式如下： -rw-r--r-- 1 root root 25934 Jun 26 10:35 X120 其中第一列除了第一个表示文件类型外， 剩下9个则表示该文件在上面三个粒度下的权限，具体信息 2,3,4列表示文件所有者权限 5,6,7列表示该文件所属用户组的权限 7,8,9列表示其他组的权限 更改文件权限chmod命令， 其参数如下： -R 以递归的方式对目前目录下的所有档案与子目录进行相同的权限变更 下面只介绍一下使用数字来表示的权限使用方法。 基本规定如下： 4 读r 2 写w 1 执行x 其他的权限组合用这几个进行相加就行， 示例如下： 7 可读+可写+可执行 rwx （4+2+1&#x3D;7） 6 可读+可写 rw-（4+2&#x3D;6） 5 可读+可执行 r-x（4+1&#x3D;5) 在使用数字进行设置权限的时候， 其语法格式： 1chmod [可选项] &lt;abc&gt; file 其三位数字分别表示拥有者，群组， 其他组的权限详情，也就是a代表拥有者权限，b代表群组权限， c代表其他权限。 例如： chmod 777 file则表示所有用户都有读写和执行的权限（当然这是比较危险的） 下面列举一下常见的权限表现形式： 1234567-rw------- (600) 只有拥有者有读写权限。-rw-r--r-- (644) 只有拥有者有读写权限；而属组用户和其他用户只有读权限。-rwx------ (700) 只有拥有者有读、写、执行权限。-rwxr-xr-x (755) 拥有者有读、写、执行权限；而属组用户和其他用户只有读、执行权限。-rwx--x--x (711) 拥有者有读、写、执行权限；而属组用户和其他用户只有执行权限。-rw-rw-rw- (666) 所有用户都有文件读、写权限。-rwxrwxrwx (777) 所有用户都有读、写、执行权限。 更改文件所有者语法 1chown [-hvR] user[:group] file... user : 新的文件拥有者的使用者 ID group : 新的文件拥有者的使用者组(group) -h :修复符号链接 -R : 处理指定目录以及其子目录下的所有文件 示例如下： 123456# 将文件的所有者设置为rootchown root file# 将文件拥有者设为rob, 组设置为robGroupchown rob:robGroup file# 仅改变文件的组设置为512（组ID）， 不改变所有者chown :512 file 顺便说一下查看用户组ID的命令： id cat /etc/password","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"linux","slug":"编程/linux","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://acchw.top/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://acchw.top/tags/shell/"}]},{"title":"Shell语法参考","slug":"编程/linux/shell与命令参考/Shell语法参考","date":"2021-12-19T16:30:00.000Z","updated":"2021-12-19T17:30:15.000Z","comments":true,"path":"posts/41179/","link":"","permalink":"https://acchw.top/posts/41179/","excerpt":"","text":"几点注意事项 一次执行多条命令,可以有如下三种方法, 其区别如下: 分号： 顺序地独立执行各条命令， 彼此之间不关心是否失败， 所有命令都会执行 &amp;&amp; ： 顺序执行各条命令， 只有当前一个执行成功时候， 才执行后面的 || ： 顺序执行各条命令， 只有当前面一个执行失败的时候， 才执行后面的 设置shell脚本遇到错误时自动退出, 不执行后续命令 1#!/bin/bash -e 或者 set -e 特殊符号使用12345678910&gt; 覆写原先的内容&gt;&gt; 在原先的内容后追加$? 前一个命令或者函数的返回码, 0表示执行成功$1 表示第一个参数,$2 表示第二个$# 命令行参数的个数$0 当前程序的名称$* 以&quot;参数1 参数2 ...&quot;的形式保存所有参数$ 本程序进程PID$! 上一个命令的PID脚本内取得输入命令时的参数: $n n代表第几个参数 特殊文件 &#x2F;dev&#x2F;null 重定向到此文件的数据都会被系统丢掉 &#x2F;dev&#x2F;tty 自动重定向到一个终端 函数使用 注意： 函数的定义要放在使用之前， 否则的话会报错 12345678# 函数定义function funname() &#123; echo &quot;第n个参数为$&#123;n&#125;&quot; action retun&#125;# 函数使用funname param1 param2 比较运算 一般用于在if条件中，用[]包裹，注意前后空格。 同时注意为了防止空情况下导致的语法错误， 变量都加上双引号 数值比较 -ne 不等于则为真 -eq 等于则为真(用来判断数字） -gt 大于则为真 -ge 大于等于为真 -lt 小于为真 -le 小于等于为真 字符串比较 var1 &#x3D; var2 判断两个字符串是否相等 var1 !&#x3D; var2 判断两个字符串是否不相等 -n “$var” 当字符串的长度大于零时为真(要用双引号包括—） -z “$var” 当字符串的长度等于零时为真(要用双引号包括—） 文件比较 -d file 检查file是否存在并且是一个目录 -f file 检查file是否存在并且是一个文件 -e file 检查file是否存在 逻辑操作运算 [ condition1 ] &amp;&amp; [ condition2 ] 与 [ condition1 ] || [ condition2 ] 或 控制语句语法 控制条件condition用[]包起来,或者使用test语句.注意空格 12345678910111213141516# if语句:if [ condition ];then commandfi# if-else:if [ condition ];then commandelif [ condition2 ];then commandelse commandfi# while语句:while [ condition ];do commanddone 数学运算推荐使用 $[] 这种格式 12345678910111213141516171819202122# 1.使用 $[]，推荐使用(注意在引用变量的时候需要加$)n1=4n2=3n3=$[$n1 * $n2] #输出12# 2.let用法,提供常用运算符,注意: 变量前不需要加$运算符且let之后的表达式不要有空格no1=4;no2=5;let result=no1+no2# 3.expr用法，只识别部分比较简单的运算符result=`expr 3 + 4`result=`$no1 + 4`# 3.注意,已上只能用于整数计算,下面这个也可用于浮点计算(使用bc命令)# 输出2.24echo &quot;4 * 0.56&quot; |bc# 输出81.0no=54result=`echo &quot;Sno * 1.5&quot; |bc`echo $result 文件读取 以每一行为单位依次读取文件 123while read line; do echo $linedone &lt; /home/db2inst1/temp1.txt 数组操作123456789101112131415161718192021222324252627282930# 定义数组(数组下标从0开始)my_array=(A B &quot;C&quot; D)# 定义一个空数组my_array=()# 读取数组$&#123;my_array[index]&#125;# 给数组某一项赋值(注意此处不需要使用$)my_array[0]=1# 获取数组的长度$&#123;#my_array[@]&#125;# 遍历数组(每一项为具体值)for item in $&#123;arr[@]&#125;do echo $itemdone# 遍历数组(每一项为数组下标)for i $&#123;!arr[@]&#125;do echo $idone# 将某条命令执行的结果全赋值给数组my_arr=(`awk &#x27;&#123;print $2&#125;&#x27; file.txt`) for循环写法12345# 循环10次for i in $(seq 1 10)do echo $idone 正则表达式正则表达式可用于sed, awk,grep等命令. 注意, sed只能使用基本正则表达式,不能使用扩展的正则表达式,sed在使用时需要使用&#x2F;&#x2F;来包裹 基本正则表达式1234567891011121314151617181920212223242526272829303132333435# 1. 基础用法, 匹配含有word的行grep &#x27;word&#x27; file_name# 2. ^word 匹配word在行首的行grep &#x27;^word&#x27; file_name# 3. word$ 匹配word在行尾的行grep &#x27;word$&#x27; file_name# 4. . 匹配除换行符之外的任意一个字符(空格也是一个字符),该处必须有字符存在# 匹配行中含有at的字符,且at前面有一个字符,如下面第一行,第三行可以匹配,第二行不能匹配,因为at在行首,前面无任何字符#This is at dog #at a dog#th hs cat fdsed -n &#x27;/.at/p&#x27; file_name # 5. * 匹配0个或任意多个前一个正则表达式字符# 以下全部匹配#i ha kg#kkkkggrep &#x27;k*g&#x27; file_name# 6. [] 搜索集合字符, []括号内的^表示除[]内的字符之外的所有字符grep &#x27;[0-9]&#x27; file_name # 匹配出现数字的行grep &#x27;[abc]&#x27; file_name # 匹配出现a或者b或者c的行grep &#x27;[a-z]&#x27; file_name # 匹配出现小写字母的行grep &#x27;[A-Z]&#x27; file_name # 匹配出现大写字母的行grep &#x27;[a-zA-Z0-9]&#x27; file_name # 匹配出现字母或数字的行# 7. x\\&#123;\\&#125; 匹配字符连续出现的次数,注意若是单词需要分别写grep &#x27;m\\&#123;2\\&#125;&#x27; file_name #匹配字母m连续出现2次的行, 如 hsjmmjsgrep &#x27;m\\&#123;2,4\\&#125;&#x27; file_name #匹配字母m出现次数在2到4次的文本# 其他示例# 匹配一个IP地址grep &#x27;[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;&#x27; file_name# 匹配形如 &quot;13445676789&quot; 的字符串,开始和结束是双引号,中间是个11位数字grep &#x27;&quot;[0-9]\\&#123;11\\&#125;&quot;&#x27; file_name 扩展正则表达式grep使用时要加-E参数(好像不加也行?) 1234567891011# 1. ? 与星号类似,但前面的字符只能出现0次或1次#bet 匹配#bt 匹配#beet 不匹配grep -E &#x27;be?t&#x27; file_name# 2. + 与星号类似,但前面的字符至少出现1次(注意点号是指当前位置必须有一个字符)# bt 不匹配# bet 匹配# beeet 匹配grep -E &#x27;be+t&#x27; file_name# 3.管道符 |, 逻辑或的意思 EOF用法将EOF与&lt;&lt;结合使用时，表示后续的输入作为子命令或子Shell的输入，直到遇到EOF为止，再返回到主程序中。 注意， 在编写代码的时候，最后一个EOF前面不要有任何符号，包括空格， 否则会报语法错误，所以一般为了书写美观， 我都是将涉及到EOF操作的封装为一个函数， 然后调用这个函数。 比如使用lftp命令登录sftp服务器， 然后上传文件，可以使用EOF来实现。 123456function upload() &#123;lftp -u $&#123;ftp_user&#125;,$&#123;ftp_pwd&#125; sftp://$&#123;ftp_host&#125;:$&#123;ftp_port&#125; &lt;&lt;EOFcd $&#123;ftp_remote_path&#125;put file_name.txtEOF&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"linux","slug":"编程/linux","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://acchw.top/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://acchw.top/tags/shell/"}]},{"title":"Linux常用命令参考","slug":"编程/linux/shell与命令参考/Linux常用命令参考","date":"2021-12-19T00:00:00.000Z","updated":"2023-10-25T00:00:00.000Z","comments":true,"path":"posts/55955/","link":"","permalink":"https://acchw.top/posts/55955/","excerpt":"","text":"当做个人字典使用， 会进行不定期更新！ tar打包与压缩命令。 常用参数： -c (–create) 建立新的备份文件 -x (–extract) 从备份文件中还原文件 -z (–gzip或–ungzip) 通过gzip指令处理备份文件 -v (–verbose) 输出执行过程中的详细信息 -f (–file) 指定备份文件 12345# 将/home文件夹下所有内容打包压缩成home.tar.gz文件tar -czvf home.tar.gz /home# 将home.tar.gz文件解压到当前目录tar -xzvf home.tar.gz getops该命令可以用来解析命令行参数。 以下表示获取命令行参数 -d -t的值 1234567891011while getopts &#x27;d:t:&#x27; OPT; do case $OPT in d) echo &quot;d $OPTARG&quot; exit 0;; t) echo &quot;t $OPTARG&quot;;; ?) echo &quot;no match&quot; esacdone 其中getopt和getopt的区别以及getopt的详细用法示例见：https://blog.sigoden.com/how-to-use-getopt-to-build-cli/ awk工作流程: 读入有\\n换行符分割的一条记录,然后将该记录按指定的域分隔符划分域(默认的域分隔符是空格符) 语法 awk 参数 ‘BEGIN{ commands } pattern { commands} END{commands}’ 参数: -F 指定字段定界符,默认是空格,可以是正则表达式， 注意分隔符直接跟在后面， 不需要任何符号 pattern: 模式,可以是正则表达式,用来匹配每一行,使用&#x2F;&#x2F;包裹, 如 &#x2F;^tcp&#x2F;表示匹配每一行开头以tcp开始 BEGIN内指定参数: FS 同-F; FS&#x3D;”” 表示以空行切分记录 特殊参数: $0 所有域, $1 第一个域, $2 第二个域,以此类推 $NF 表示一行中的最后一个字段 流程控制语法: if(condition)&#123;&#125; else if(condition)&#123;&#125; else&#123;&#125; 循环语法: for (i=0; i&lt;3;i++)&#123;&#125; 指定分隔符有三种方法，下面分别是指定分隔符为逗号时的写法： 使用 -F 指定，注意其后不需要任何符号， 语法：awk -F, file 使用FS指定，加上-v参数， 语法： awk -v FS=&quot;,&quot; file 在BEGIN内部指定， 语法： awk &#39;BEGIN &#123;FS=&quot;,&quot;&#125;&#39; file 字符串函数 length(string) 获取字符串长度(字符数) 拼接字符串时不需要使用任何修饰符,直接即可 printf() 格式化输出,默认不输出换行符.%s 字符; %d 整数,小数取整直接去除尾数; %.2f 小数,2表示小数点保留两位,最后一位四舍五入printf(“%.2f\\n”, 1.3374) 输出1.34 split(string,array [,r]) 字符串拆分,返回拆分后数组大小string:待拆分的字符串,array:拆分后结果保存的数组,r:分隔符,可选,默认FS值;拆分后的数组下标从1开始,for(k in arr)&#123;print arr[k]&#125; substr(s,i [,n]) 字符串截取s:待截取字符串;i:索引位置,从1开始;n:要截取的长度.默认截取到字符尾。 字符串查找:index(s,t), match(s,r [,a])返回第一次匹配成功的索引位置,从1开始,失败返回0s: 待查找的字符串;t:目标子串r: 查询的正则表达式, a 结果二维数组 字符串替换 sub(r,s[,t]) 替换首次匹配到的子串,返回成功替换子串的数目,r 用于匹配的正则表达式,s 要替换的字符串值,t 目标字符串n,默认$0 gsub(r,s[,t]) 用法同sub,替换所有匹配到的子串 gensub(r,s,h[,t]) h: “g”表示全局替换,或是用数字指定子串出现的位置 时间函数 systime() 返回精确到秒的当前时间戳 mktime(date) 获取指定时间的时间戳,date格式: “YYYY MM DD HH MM SS” strftime() 转化时间字符串 注意 中间命令的编写一定要用单引号包裹，不能用双引号 当字符串中含有单引号，转义写法如下： 12# 此为打印单引号，比较字符串的单引号同理awk &#x27;&#123;print &quot;&#x27;\\&#x27;&#x27;&quot;&#125;&#x27; awk中比较在一个范围之内不能用连写方式，如 2&lt;x&lt;7是错误的,应写成 x&gt;2 &amp;&amp; x&lt;7 awk 使用外部变量，需要在Action之后定义变量，如下所示使用外部test变量： 12test=hhhhfudfhdhfawk &#x27;&#123;print test&#125;&#x27; test=&quot;$test&quot; filename 示例12# 假设一个目录下的文件按照时间进行命名， 如202204011628.tar.gz,现在要取出每个文件名的前8位（也就是年月日）， 操作如下ls|awk &#x27;BEGIN &#123;FS=&quot;.&quot;&#125; &#123;a=substr($1,1,8);print a&#125;&#x27; grep在命令之前加上LANG&#x3D;C之后可大幅提高检索速度, 如 LANG&#x3D;C grep -ia -B 1 Exception filename 参数说明: -i 忽略大小写 -a 显示文本(当使用通配符搜索文件内容时，有时只显示匹配的文件名而不显示匹配的内容，用此参数即可） -e 指定多个匹配样式 -c 计算找到的符合行的次数 -n 输出匹配行的行号 -v 反转查找 -w 只显示全字符合的列 -A n 打印匹配行和匹配行之后的n行 -B n 打印匹配行和匹配行之前的n行 -C n 打印匹配行和匹配行之前,之后的n行,共2n+1 -h 在显示匹配行的那一列之前,不显示该列的文件名称 -o 只输出文件中匹配到的部分 示例： 123# 过滤时间段内的数据, 例如[15:10:00,15:20:00)# 需要注意，正则表达式中的数字范围只能是一位整数grep &quot;15:1[0-9]&quot; file zgrep可以搜索gz压缩文件内的内容。用法同grep sed语法 sed options script file 默认不对原文件进行修改,处理的是原文件的拷贝 options参数: -n 取消默认的输出,仅显示处理后的结果 -e 以选项中指定的script处理 -i 直接修改原文件,慎用 script 参数: d 删除 p 打印 s 替换 注意 若在sed命令中使用外部的变量，此时匹配规则必须使用双引号 示例1234567891011121314151617181920# 打印第三行sed -n &#x27;3p&#x27; file # 打印第200行到300行sed -n &#x27;200,300p&#x27; file # 删除文件中的所有空白行sed -n &#x27;/^$/d&#x27; file # 在每个有Statement行的下一行添加一个空行sed &#x27;/Statemt/G&#x27; # 将文件中含有test字符串的行打印出来sed -n &#x27;/test/p&#x27; test.txt # 将文件中my字符替换为Bobsed &#x27;s/my/Bob/g&#x27; test.txt# 将文件中第三行替换为huangsed -i &#x27;3s/.*/huang/&#x27; file echo-n 省略结尾的换行符,直接在文本后面输入 readread value 读取用户输入 df显示磁盘信息 -a 所有 -h 可读性较好显示 tail &amp; head从文件开头或文件结尾查看文件 1234567891011# 显示文件最后n行tail -n file # 实时查看文件内容, 一般查看实时查看日志文件用此命令tail -f file# 显示文件的前n行head -n file #显示文件的m到n行head -n file | tail -m zip压缩文件 -q 不显示指令执行过程 -r 递归处理 示例 12#将 /home/db2/ddl目录下所有文件和文件夹压缩至当前目录的test.zip文件zip -q -r test.zip /home/db2/ddl typeset设置变量 ps 显示系统进程信息(linux中线程是伪线程，用轻量级进程来实现的，所以查看线程信息也是用此命令） 参数 -ef 显示系统运行的所有进程信息 返回信息 PID ：该进程的进程ID号 %CPU：该进程使用掉的 CPU 资源百分比 %MEM：该进程所占用的物理内存百分比 VSZ ：该进程使用掉的虚拟内存量 (单位KB) RSS ：该进程占用的固定的内存量 (单位KB) TTY ：该进程表示在哪个终端机上面运作，其取值可能有如下几种 ? 与终端机无关 tty1-tty6 本机上面的登入者程序 pts&#x2F;0 由网络连接进主机的程序 STAT：该程序目前的状态，主要的状态有 R ：该程序目前正在运作，或者是可被运作 S ：该程序目前正在睡眠当中 (可说是 idle 状态啦！)，但可被某些讯号(signal) 唤醒 T ：该程序目前正在侦测或者是停止了 Z ：该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态 START：该进程被触发启动的时间 TIME ：该进程实际使用 CPU 运作的时间 crontab 定时任务 参数 -l 查看现有cron表中的内容 -e 编辑 cron文件的语法如下: 1f1 f2 f3 f4 f5 program 其中 f1 是表示分钟，f2 表示小时，f3 表示一个月份中的第几日，f4 表示月份，f5 表示一个星期中的第几天。program 表示要执行的程序。 当 f1 为 * 时表示每分钟都要执行 program，f2 为 * 时表示每小时都要执行程序，其馀类推 当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行，f2 为 a-b 时表示从第 a 到第 b 小时都要执行，其馀类推 当 f1 为 *&#x2F;n 时表示每 n 分钟个时间间隔执行一次，f2 为 *&#x2F;n 表示每 n 小时个时间间隔执行一次，其馀类推 当 f1 为 a, b, c,… 时表示第 a, b, c,… 分钟要执行，f2 为 a, b, c,… 时表示第 a, b, c…个小时要执行，其馀类推 示例12345# 每一分钟执行一次* * * * * program# 每天7:50执行一次50 7 * * * program 创建定时任务步骤crontab -e 其他常用命令： 123456789101112# 当有service命令#启动service crond start# 停止service crond stop# 重启service crond restart# 当没有service命令/etc/init.d/cron stop/etc/init.d/cron start/etc/init.d/cron restart tee将命令运行结果同时输出到终端和文件 ls |tee log.log du 显示文件或目录大小 -c 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和 -h 按友好模式显示 -s 只显示目录总大小 -l 重复计算硬件连接的文件 –max-depth 超过指定层数的目录后，予以忽略 123456# 查看当前目录总大小du -sh# 查看当前目录下一级子文件和子目录占用的磁盘容量du -lh --max-depth=1# 统计当前文件夹(目录)大小，并按文件大小排序du -sh * | sort -n scpLinux服务器之间传输文件 12345# 传输aa.txt文件到206服务器的home目录下scp aa.txt usroot@22.5.229.206:/home/# 206服务器下载aa.txt文件到本服务器当前路径： scp usroot@22.5.229.206:/home/aa.txt . sort排序. 排序时以行为单位 -r 下降排序,默认升序 -n 按照数值大小排序 -k 指定排序所依据的列数,从1开始 -t 指定排序时的列分隔符 -u 输出行中去除重复行 示例： 12# 按照文件大小从大到小进行排序ls -l|sort -nr -k 5 uniq 忽略文件中的重复行，常与sort一起使用 -c 在每列旁边显示该行重复出现的次数 -d 仅显示重复出现的行 -u 仅显示唯一出现的行 注意： uniq的去重是将当前行与上一行进行对比， 所以为了得到整体去重， 需要先进行排序，在执行去重 top实时显示系统进程情况. 以下命令为进入该命令之后执行： M 根据内存大小进行排序 P 根据CPU使用百分比进行排序 T 根据时间&#x2F;累计时间排序 输出参数说明: 第一行相当于uptime命令输出 第一列时间表示当前系统时间 第二列 up 6 days 58min, 表示系统已经运行时间 第三列 2 users, 表示表示当前有2个用户在登陆 第四列 load average三个值分别表示系统1分钟,5分钟,15分钟平均负载 第二行 tasks信息表示系统运行的整体进程数量和状态信息 zombie 僵尸进程数. 第三行 %Cpu(s)表示的是总体CPU使用情况 us user 表示用户态的CPU时间比例. 当us很高时，证明CPU时间主要消耗在用户代码，需要优化用户代码 sy system 表示内核态的CPU时间比例. 说明CPU时间都消耗在内核，要么是频繁的系统调用，要么是频繁的CPU切换（进程切换&#x2F;线程切换） wa iowait 表示处于IO等待的CPU时间比例. 很高时，说明有进程在进程频繁的IO操作，有可能是磁盘IO，也有可能是网络IO ni nice 表示运行低优先级进程的CPU时间比例 id idle 表示空闲CPU时间比例 hi hard interrupt 表示处理硬中断的CPU时间比例 si soft interrupt 表示处理软中断的CPU时间比例 st steal 表示当前系统运行在虚拟机中的时候，被其他虚拟机占用的CPU时间比例 第4行. 内存使用情况, 单位KiB totol 表示总内存 free 表示没使用过的内容 used是已经使用的内存 buff表示用于读写磁盘缓存的内存 cache表示用于读写文件缓存的内存 avail表示可用的应用内存 第5行, swap使用情况, 单位KiB, Swap原理是把一块磁盘空间或者一个本地文件当成内存来使用. 这三个值都为0表示系统关闭了swap功能，虚拟机一般都关闭swap功能 Swap total表示能用的swap总量 swap free表示剩余 used表示已经使用的 之后为各个进程具体的信息.各字段说明如下 PID 进程ID USER 进程所有者的用户名，例如root VIRT 虚拟内存, virtual memory usage。单位KB. 表示当前进程能够访问到的最大内存大小 RES 物理内存（不包括共享内存), resident memory usage，单位KB。表示当前有多少物理内存被这个进程消费。如果申请 100m 的内存，实际使用 10m，那么RES &#x3D; 10m，VIRT&#x3D;100M。 一般情况下看此值大小即可 SHR 进程使用的共享内存. 单位KB CPU 进程使用的CPU占比 MEM 进程使用的内存占比 TIME 进程启动后到现在所用的全部CPU时间 COMMAND 进程的启动命令（默认只显示二进制，top -c能够显示命令行和启动参数） lsls -l 的输出内容格式如下: -rw-r--r-- 1 root root 25934 Jun 26 10:35 X120 参数: -h 友好方式显示大小 -a 所有 -l 详细格式列表 -t 用文件和目录的更改时间排序 -r 反向排序 添加-l参数时详细输出参数说明: 第一列 第一个， 文件类型 d 目录 -文件， c 字符型文件 b 块设备 l 链接文件 接下来三个为一组，用来表示权限信息，其中 r 读， w 写， x 执行. 具体如下: 2,3,4：文件所有者权限 5,6,7：同用户组的权限 8,9,10：非本用户组的权限 第二列：有多少文件名连接到此节点 第三列：所有者账号 第四列：文件所属的用户组 第五列：文件大小，默认B 第六列：最近修改日期 示例: 12# 仅显示目录名ls -d */ stat 查看文件属性，包括文件创建时间 Access 访问时间，每读一次这个文件内容，就会更新。比如对这个文件使用more命令。ls、stat命令都不会修改文件的访问时间 Modify 修改时间，对文件内容进行写操作，就会更新。比如：vi后保存文件。ls -l列出的时间就是这个时间。 Change 状态改变时间，通过chmod命令更改一次文件属性，这个时间就会更新。 split分割大文件为多个小文件 参数: -b value 按value大小分割文件,即分割后每个文件大小为value(单位为byte) -l value 按行数分割文件,即分割后每个文件行数为value -d 使用数字作为文件名后缀 curl不带任何参数, 默认发送get请求 参数: -d 发送post请求的数据体 1curl -d &#x27;login=emma＆password=123&#x27; -X POST https://google.com/login -H 设置请求头 1curl -H &#x27;Content-Type: application/json&#x27; https://google.com/login -o 将服务器回应保存成文件, 等同于wget -s 不输出错误和进度信息 -X 指定请求的方法 1curl -X POST https://www.example.com xargs 语法: xargs [-options] [command] 作用是将标准输入转为命令行参数 管道符|将左侧的标准输出转化为标准输入, 供右边命令使用, 但是这需要右边命令支持标准输入作为参数, 如grep是支持的, 下面命令是可以的. 1ps -ef|grep java 但是很多命令不支持标准输入作为参数, 如echo, 下面这条命令没有任何输出 1echo &quot;sdsd&quot;|echo 下面这条命令输出 sdsd 1echo &quot;sdsd&quot;|xargs echo 参数: -d 指定分隔符,默认将换行符和空格作为分隔符,如制表符为”\\t” 示例： 12# 保留当前目录下所有txt格式的文件， 删除所有其他类型的文件ls|grep -v &quot;.txt&quot;|xargs rm lsof查看某个端口占用情况.一般查看端口冲突时可使用该软件. lsof -i:port nohup后台执行命令，即使退出此终端， 仍然会执行。 示例： 1234567# nohup输出的信息不输出到文件nohup ./program &gt;/dev/null 2&gt;&amp;1 &amp;# 将nohup命令执行的log日志输出到指定文件# 2&gt;&amp;1表示不仅命令行正常的输出保存到backupdb.log中，产生错误信息的输出也保存到backupdb.log中# &amp;表示该进程在后台运行nohup ./backupdb.sh &gt;backupdb.log 2&gt;&amp;1 &amp; htop 相比于top显示的信息更加详细 注意几点： htop默认会把一个进程里的线程当做一个进程来显示出来，若要关闭线程，只显示进程，按F2，再选择 Display options，再选择 Hide userland threads nload 查看各个网络设备的当前网络速率，也会展示流经设备的总流量 。 也可指定网卡， 如查看网卡eth0的流量 nload etho 注意：页面上显示的速率单位MBit&#x2F;s， 是M比特每秒， 换算成正常的MB&#x2F;s（M字节每秒）需要除以8 date123456789# 格式化成 2020-01-12 23:23:34date &quot;+%Y-%m-%d %H:%M:%S&quot;date -d &quot;+1 day&quot; +%Y%m%d #显示后一天的日期 date -d &quot;-1 day&quot; +%Y%m%d #显示前一天的日期 date -d &quot;-1 month&quot; +%Y%m%d #显示上一月的日期 date -d &quot;+1 month&quot; +%Y%m%d #显示下一月的日期 date -d &quot;-1 year&quot; +%Y%m%d #显示前一年的日期 date -d &quot;+1 year&quot; +%Y%m%d #显示下一年的日期 查看系统发型版本1cat /etc/*release* iostat 用于查看系统设备的IO负载情况， 同时也会显示出CPU处理器的使用情况。 数据来源是 &#x2F;proc&#x2F;diskstats https://cloud.tencent.com/developer/article/1698369 语法：iostat [参数] 设备名 常用参数： -d 显示设备利用率 -c 显示CPU使用情况 -h 使用NFS网络文件系统来输出报告 -N 显示LVM逻辑卷管理器设备信息 -p 显示块设备和分区的状态 -t 显示报告产生时的时间 -x 显示更为详细的信息， 一般情况下都需要带上这个参数，方便分析 -k 以 KB 为单位显示 -m 以 M 为单位显示 输出关键参数说明： avg-cpu行表示总体cpu的使用情况， 对于多核，这里指的是平均值： %user CPU在用户态执行进程的时间百分比 %nice CPU在用户态模式下，用于nice操作，所占用CPU总时间的百分比 %system CPU处在内核态执行进程的时间百分比 %iowait CPU用于等待I&#x2F;O操作占用CPU总时间的百分比， 若该值过高，表示硬盘可能存在I&#x2F;O瓶颈 %idle CPU空闲时间百分比， 若该值高但系统响应慢，可能是cpu等待分配内存，此时应该加大内存；若该值持续低于1，则系统的cpu处理能力相对较低，应该加大cpu Device行表示磁盘设备的情况： tps 每秒IO数， 表示 每秒向磁盘设备请求数据的次数，包括读、写请求，为rtps与wtps的和 kB_read&#x2F;s 每秒从磁盘读取数据大小，单位KB&#x2F;s kB_wrtn&#x2F;s 每秒写入磁盘的数据的大小，单位KB&#x2F;s kB_read 从磁盘读出的数据总数，单位KB kB_wrtn 写入磁盘的的数据总数，单位KB r&#x2F;s 每秒读操作的次数 rkB&#x2F;s 同kB_read&#x2F;s %util 代表磁盘繁忙程度。越大越繁忙。一般地，如果该参数是100%表示设备已经接近满负荷运行（如果是多磁盘，即使%util是100%，因为磁盘的并发能力，所以磁盘使用未必就到了瓶颈） await 平均每次IO请求的等待时间（包括等待时间和处理时间，单位为毫秒）， 这里可以理解为响应时间，一般的系统应该低于5ms，若超过10ms则比较大。一般情况下await与svctm差值（真正的等待时间）越大，队列的时间越长，系统可能存在问题 svctm 平均每次IO请求的处理时间(单位为毫秒) 示例： 1234567891011# 每隔2秒报告一次所有硬盘的使用情况iostat -d 2# 每隔2秒报告一次所有硬盘的详细使用情况,总共报告6次iostat -d 2 6# 每隔2秒报告一次所有硬盘的详细使用情况iostat -x -d 2# 每隔2秒报告一次sda硬盘的详细使用情况iostat -x sda -d 2 netstat 查看网络情况。 显示项Recv-Q, Send-Q表示网络接受队列,发送队列.一般情况下为0, 可接受短暂的非0状态。 示例 12345# 统计各个Tcp状态的连接有多少个netstat -n | awk &#x27;/^tcp/ &#123;++state[$NF]&#125; END &#123;for(key in state) print key,&quot;\\t&quot;,state[key]&#125;&#x27;# 统计与nginx建立连接的IP，并包含各个IP的连接数netstat -ntp | grep nginx | grep -v &quot;127.0.0.1&quot; | awk &#x27;&#123;print $5&#125;&#x27; | awk -F &#x27;:&#x27; &#x27;&#123;print $1&#125;&#x27; | sort | uniq -c tcpdump抓包工具。 常用参数： -i 指定网卡， 如果设置为any则表示抓取所有网卡 -w 将结果保存为wireshark可识别的文件， 可直接用wireshark进行分析 当有多个过滤条件时， 进行连接的操作符有： and 且 or 或 not 非 过滤条件： host 主机IP， 包含出和入 port 端口号 src ip包的源地址 dst ip包的目标地址 示例： 12# 抓取所有网卡流量，并且过滤主机为192.168.1.23，端口为8123，将结果保存为dd.cap文件tcpdump -i any host 192.168.1.23 and port 8123 -w dd.cap","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"linux","slug":"编程/linux","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://acchw.top/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://acchw.top/tags/shell/"}]},{"title":"docker安装confluence","slug":"折腾/其他/docker安装confluence","date":"2021-12-15T22:30:00.000Z","updated":"2021-12-15T22:30:00.000Z","comments":true,"path":"posts/55856/","link":"","permalink":"https://acchw.top/posts/55856/","excerpt":"","text":"自己搭建一个confluence wiki，现记录一下搭建过程和其中需要注意的点。 编写docker-compose12345678910111213141516171819202122232425version: &#x27;3&#x27;services: db: image: postgres:latest container_name: confluence-db ports: - &quot;15202:5432&quot; restart: always environment: - POSTGRES_PASSWORD=123456 volumes: - /opt/docker/confluence/pgsql-data:/var/lib/postgresql/data confluence: image: cptactionhank/atlassian-confluence:latest container_name: confluence ports: - &quot;15200:8090&quot; - &quot;15201:8091&quot; restart: always depends_on: - db volumes: - /opt/docker/confluence/logs:/opt/atlassian/confluence/logs - /opt/docker/confluence/confluence-data:/var/atlassian/confluence 启动 docker-compose up -d 注意此处/opt/docker/confluence/confluence-data是没有权限的， 按照网上的修改文件夹权限 chown -R daemon.daemon confluence-data 也不管用， 不得已先直接777赋权， 以后再研究下。 1chmod 777 confluence-data 破解 从此处下载破解文件： https://www.jianguoyun.com/p/DalHveAQqo6RCBjo1KIE 解压， 在命令行执行java -jar confluence_keygen.jar 在弹出窗中输入Server ID, 点击 .gen!, 将产生的授权码复制下来备用 将已经启动好的confluence容器中的atlassian-extras-decoder-v2-3.4.1.jar文件复制出来并重命名, 并下载到本地 1docker cp confluence:/opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3.4.1.jar ./atlassian-extras-2.4.jar 在之前弹出窗口中点击.patch!按钮， 并选择刚刚下载的atlassian-extras-2.4.jar文件， 当显示jar successfully patched则表示patch成功 重新将atlassian-extras-2.4.jar文件命名为atlassian-extras-decoder-v2-3.4.1.jar， 并复制到容器内部 重启confluence容器 初始化数据库docker进入Postgres容器 1docker exec -it confluence-db bash 依次执行以下命令： 12psql -U postgresCREATE DATABASE confluence WITH OWNER postgres; 然后重启容器即可","categories":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"其他","slug":"折腾/其他","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"confluence","slug":"confluence","permalink":"https://acchw.top/tags/confluence/"},{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/tags/%E6%8A%98%E8%85%BE/"},{"name":"selfhost","slug":"selfhost","permalink":"https://acchw.top/tags/selfhost/"}]},{"title":"红米AC2100刷pandavan及设置无线中继","slug":"折腾/其他/红米AC2100刷pandavan及设置无线中继","date":"2021-10-23T11:10:00.000Z","updated":"2023-07-28T00:00:00.000Z","comments":true,"path":"posts/43359/","link":"","permalink":"https://acchw.top/posts/43359/","excerpt":"","text":"获取SSH权限 打开本地浏览器输入192.168.31.1并登陆。 右上角选择固件升级， 升级到有漏洞版本2.0.7（ 文件名：miwifi_rm2100_firmware_d6234_2.0.7.bin） 刷完重启后重新输入192.168.31.1登陆管理页，此时的浏览器地址栏如下（注意stock&#x3D;后面的值每个人是不一样的）： http://192.168.31.1/cgi-bin/luci/;stok=ODJ893023kd2344224kdF/web/home#router 将stok=ODJ893023kd2344224kdF显示的值 复制替换到如下链接对应位置并浏览器打开：http://192.168.31.1/cgi-bin/luci/;stok=你浏览器显示的值/api/misystem/set_config_iotdev?bssid=Xiaomi&amp;user_id=longdike&amp;ssid=-h%3B%20nvram%20set%20ssh_en%3D1%3B%20nvram%20commit%3B%20sed%20-i%20&#39;s%2Fchannel%3D.*%2Fchannel%3D%5C%22debug%5C%22%2Fg&#39;%20%2Fetc%2Finit.d%2Fdropbear%3B%20%2Fetc%2Finit.d%2Fdropbear%20start%3B 此时就已打开了SSH，继续按照上面方法替换stok&#x3D;你浏览器显示的值如下链接并打开，自动修改ssh密码为admin。http://192.168.31.1/cgi-bin/luci/;stok=你浏览器显示的值/api/misystem/set_config_iotdev?bssid=Xiaomi&amp;user_id=longdike&amp;ssid=-h%3B%20echo%20-e%20&#39;admin%5Cnadmin&#39;%20%7C%20passwd%20root%3B 刷Breed 使用ssh登录路由器： IP： 192.168.31.1 用户名： root 密码：admin 下载breed固件并上传到路由器（文件名：breed-mt7621-xiaomi-r3g.bin） 执行如下命令， 并等待20s 1mtd -r write breed-mt7621-xiaomi-r3g.bin Bootloader 进入breed先断电，然后先找个针戳住路由器背后Reset小孔， 同时插电，等路由器蓝灯一直闪烁后，浏览器输入192.168.1.1即可进入breed网页。 更改环境变量找到环境变量增加：xiaomi.r3g.bootfw 值：2 然后保存。 刷pandavan固件进入breed网页， 清除数据（恢复出厂设置 -&gt;选择pandavan)。 点击 固件更新 -&gt; 固件 -&gt; 选择文件， 上传trx格式的固件包 ,然后安装即可。 以下是我用过的几个版本： 文件名 路由器初始IP 用户名密码 备注 RM2100_3.4.3.9-099-1200MHz.trx 192.168.2.1 admin&#x2F;admin 1200MHz,当前在用 R2100_3.4.3.9-099.trx 192.168.31.1 admin&#x2F;admin redmi2100.trx 192.168.123.1 admin&#x2F;admin 设置无线中继（好像使用5G来设置中继的话效果更好， 没有做进一步测试） 其他设置设置内网与上级网络分别属于不同网络 上述文件下载地址： 链接：https://pan.baidu.com/s/1Hd6Q8lbYHRcWArt2YfPYaQ提取码：8u65 参考资料： http://openwrt.ink:88/archives/s-breed","categories":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"其他","slug":"折腾/其他","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"路由器","slug":"路由器","permalink":"https://acchw.top/tags/%E8%B7%AF%E7%94%B1%E5%99%A8/"},{"name":"折腾 - AC2100","slug":"折腾-AC2100","permalink":"https://acchw.top/tags/%E6%8A%98%E8%85%BE-AC2100/"}]},{"title":"spring中的设计模式","slug":"编程/java/spring中的设计模式","date":"2021-10-05T21:50:00.000Z","updated":"2025-01-21T05:49:52.461Z","comments":true,"path":"posts/63016/","link":"","permalink":"https://acchw.top/posts/63016/","excerpt":"","text":"本文结合spingboot的源码描述一下spring中运用到的几种点典型的设计模式。 工厂模式本身也能产生bean, 例如其中一个实现类：```AbstractFactoryBean```,123456789101112131415getObject()方法源码如下：```java @Override public final T getObject() throws Exception &#123; //单例从缓存中获取或者暴露引用（用来解决循环引用） if (isSingleton()) &#123; return (this.initialized ? this.singletonInstance : getEarlySingletonInstance()); &#125; else &#123; //创建实例 return createInstance(); &#125; &#125; 其最终创建实例的方法是createInstance, 该方法由其子类工厂去实现， 具体的子类有如下几种： 例如mybatis的SqlSessionFactoryBean就是实现了该接口。 这里有必要说明一下BeanFactory和FactoryBean的区别： BeanFactory是Spring工厂中的顶层规范，Spring中的容器都是它的具体实现， 例如常见的ApplicationContext FactoryBean是一个能生产或修饰对象生成的工厂Bean， 它本身也是一个bean, 由BeanFactory管理 单例模式从Spring容器中获取的bean, 默认情况下是单实例的， 其具体实现在org.springframework.beans.factory.support.DefaultSingletonBeanRegistry#getSingleton(java.lang.String, boolean), 方法源码如下： 123456789101112131415161718192021private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; //使用锁保证多线程同步竞争 //如果此bean正在加载，则不处理 singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); //记录在缓存中，earlysingletonObjects和singletonFactories互斥（用来解决循环依赖） this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject; &#125; 策略模式 策略模式用于封装系列的算法，这些算法通常被封装在一个 Context 类中，客户端程序可以自由选择其中一种算法，或让 Context 为客户端选择一个最佳的算法 —— 使用策略模式的优势是为了支持算法的自由切换。 Spring中的Resource接口是具体资源访问策略的抽象，也是所有资源访问类所实现的接口。 Resouce接口本身并没有提供任何访问底层资源的逻辑， 针对不同的资源， spring提供了不同的实现类来负责对应的资源访问逻辑。具体如下： UrlResource： 访问网络资源 ClassPathResource： 访问类加载路径里资源 FileSystemResource： 访问文件系统里资源 ServletContextResource： 访问相对于 ServletContext 路径里的资源 InputStreamResource： 访问输入流资源 ByteArrayResource： 访问字节数组资源 具体spring该使用哪个实现类， 其中就用到了策略模式的思想。 Spring提供了如下两个接口： ResourceLoader: 获取一个Resouce实例 ResourceLoaderAware： 获取一个ResourceLoader的引用 当 Spring 应用需要进行资源访问时，实际上并不需要直接使用 Resource 实现类，而是调用 ApplicationContext 实例的 getResource () 方法来获得资源，ApplicationContext 将会负责选择 Resource 的实现类，也就是确定具体的资源访问策略，从而将应用程序和具体的资源访问策略分离开来，这就体现了策略模式的优势。 下图是ApplicationContext接口， 可以看到它继承了ResourceLoader接口， 同时也就拥有了该接口的所有方法。 此处 Spring 框架的 ApplicationContext 不仅是 Spring 容器，而且它还是资源访问策略的 “决策者”，也就是策略模式中 Context 对象，它将为客户端代码 “智能” 地选择策略实现。 当 ApplicationContext 实例获取 Resource 实例时，系统将默认采用与 ApplicationContext 相同的资源访问策略。","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"java","slug":"编程/java","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://acchw.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://acchw.top/tags/spring/"},{"name":"springboot","slug":"springboot","permalink":"https://acchw.top/tags/springboot/"}]},{"title":"springboot启动流程及原理剖析","slug":"编程/java/springboot启动流程及原理剖析","date":"2021-09-10T16:40:00.000Z","updated":"2025-01-21T05:49:52.461Z","comments":true,"path":"posts/41153/","link":"","permalink":"https://acchw.top/posts/41153/","excerpt":"","text":"SpringBoot应用打出的jar包， 是可以直接使用 java -jar XXX.jar 命令直接启动的， 那么背后的原理是怎样的？ JarLauncherjar包结构首先先看一下springboot的jar包结构是什么样的。 新建一个springboot工程（可以直接使用idea自带的Spring Initializer创建）， 然后使用mvn clean package打包， 使用压缩软件打开jar包， 观察其内部结构如下： 12345678910111213141516.├── BOOT-INF│ ├── classes│ │ ├── application.properties│ │ ├── cn│ │ ├── static│ │ └── templates│ └── lib│ ├── spring-core-5.2.2.RELEASE.jar│ ├── spring-webmvc-5.2.2.RELEASE.jar│ ├── ...// 这里略了大量jar包├── META-INF│ └── MANIFEST.MF└── org └── springframework └── boot 现在分别说明如下： MANIFEST.MF 该文件描述了jar包的一些关键信息， 其中Main-Class指定了启动类， 在springboot应用中该项是org.springframework.boot.loader.JarLauncher, 该类后续还要深入分析 BOOT-INF&#x2F;classes 工程的源代码编译完成后的class文件 BOOT-INF&#x2F;lib 工程依赖的第三方jar包文件 org 目录： Spring Boot loader 相关的源代码，其中的JarLauncher就放在此处 LauncherLauncher各种 Launcher 的基础抽象类，用于启动应用程序，跟 Archive 配合使用。 目前有三种实现： JarLauncher WarLauncher PropertiesLauncher Archive归档文件的基础抽象类。 JarFileArchive 就是 jar 包文件的抽象。它提供了一些方法比如 getUrl 会返回这个 Archive 对应的 URL。getManifest 方法会获得 Manifest 数据等。 ExplodedArchive 是文件目录的抽象。 JarFile对 jar 包的封装，每个 JarFileArchive 都会对应一个 JarFile。JarFile 被构造的时候会解析内部结构，去获取 jar 包里的各个文件或文件夹，这些文件或文件夹会被封装到 Entry 中，也存储在 JarFileArchive 中。如果 Entry 是个 jar，会解析成 JarFileArchive。 在执行java jar XXX.jar的时候， 首先触发的是 org.springframework.boot.loader.jar.Handler的main方法， 而不是我们自定义的XXXApplication。 这里需要注意一点， 直接在idea中搜索JarLauncher这个类是搜不到的， 是因为该类是在编译的时候直接导入到Jar包中的， 如果需要看源码， 需要在pom文件中引入如下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-loader&lt;/artifactId&gt;&lt;/dependency&gt; 从JarLauncher的main方法开始进行分析，其主要流程如下： 123456789protected void launch(String[] args) throws Exception &#123; if (!isExploded()) &#123; JarFile.registerUrlProtocolHandler(); &#125; ClassLoader classLoader = createClassLoader(getClassPathArchivesIterator()); String jarMode = System.getProperty(&quot;jarmode&quot;); String launchClass = (jarMode != null &amp;&amp; !jarMode.isEmpty()) ? JAR_MODE_LAUNCHER : getMainClass(); launch(args, launchClass, classLoader); &#125; 创建一个自定义类加载器 LaunchedURLClassLoader，遵循双亲委派机制，对于父类无法加载的类，则由 LaunchedURLClassLoader 进行加载，其加载的路径包括 BOOT-INF&#x2F;lib 和 BOOT-INF&#x2F;classes 调用Thread.currentThread().setContextClassLoader(classLoader)将其设置为线程上下文加载器 反射执行我们自定义的springboot启动类的main方法，也就是使用@SpringBootApplication注解的类 一个普通的springboot项目一般都是使用如下方式来启动的： 1234567891011@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; try &#123; SpringApplication.run(Application.class, args); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 这里我们可以看到主要是一个@SpringBootApplication注解和SpringApplication的run()方法。下面对这两个进行详细解释。 SpringBootApplication注解12345678@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;) 该注解主要由三个注解组合而成，其他的都是常规注解， 分别是： @ComponentScan @EnableAutoConfiguration @SpringBootConfiguration @ComponentScan该注解的主要作用是用来进行包扫描， 从而创建bean。 其中有一个AutoConfigurationExcludeFilter， 其作用是用来进行包扫描的时候排除自动配置的类， 简而言之不扫描自动配置类。 @EnableAutoConfiguration该注解是SpringBoot中用来实现自动装配的关键。 123456@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class) 这里重点关注的是@Import(AutoConfigurationImportSelector.class)这一行， 该注解的作用分为如下三点： 导入被@Configuration修饰的配置类 导入实现了ImportSelector接口的配置类 导入实现了ImportBeanDefinitionRegistar接口的配置类 该注解最终调用的是SpringFactoriesLoader类中的loadSpringFactories()方法， 此方法会加载在META-INF&#x2F;spring.factories中已经定义好的配置类。 从而通过此注解， 实现将所有的配置类自动装载到spring容器中去。 下面是springboot 2.1.3版本中autoconfigure模块该文件部分内容： 12345678910111213141516171819202122232425262728293031323334353637383940# Initializersorg.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer,\\org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener# Application Listenersorg.springframework.context.ApplicationListener=\\org.springframework.boot.autoconfigure.BackgroundPreinitializer# Auto Configuration Import Listenersorg.springframework.boot.autoconfigure.AutoConfigurationImportListener=\\org.springframework.boot.autoconfigure.condition.ConditionEvaluationReportAutoConfigurationImportListener# Auto Configuration Import Filtersorg.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\\org.springframework.boot.autoconfigure.condition.OnBeanCondition,\\org.springframework.boot.autoconfigure.condition.OnClassCondition,\\org.springframework.boot.autoconfigure.condition.OnWebApplicationCondition# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\----此处省略-----# Failure analyzersorg.springframework.boot.diagnostics.FailureAnalyzer=\\org.springframework.boot.autoconfigure.diagnostics.analyzer.NoSuchBeanDefinitionFailureAnalyzer,\\org.springframework.boot.autoconfigure.jdbc.DataSourceBeanCreationFailureAnalyzer,\\org.springframework.boot.autoconfigure.jdbc.HikariDriverConfigurationFailureAnalyzer,\\org.springframework.boot.autoconfigure.session.NonUniqueSessionRepositoryFailureAnalyzer# Template availability providersorg.springframework.boot.autoconfigure.template.TemplateAvailabilityProvider=\\org.springframework.boot.autoconfigure.freemarker.FreeMarkerTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.mustache.MustacheTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.web.servlet.JspTemplateAvailabilityProvider 综上， @SpringBootApplication注解的主要作用总结如下： 实现自动配置 定义需要加载到spring容器中的bean SpringApplication类SpringApplication.run()方法主要分为两步： 构造SpringApplication对象 执行该对象的run方法 下面分别就这两步进行说明。 构造SpringApplication对象跟踪SpringApplication类实例初始化最终代码如下： 123456789101112131415public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); // 设置应用类型 this.webApplicationType = WebApplicationType.deduceFromClasspath(); // 设置初始化 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); // 设置事件监听器 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); // 找出main方法所属的类 this.mainApplicationClass = deduceMainApplicationClass(); &#125; 就其中关键的几个步骤进行说明 设置应用类型1this.webApplicationType = WebApplicationType.deduceFromClasspath(); 应用类型共分为三种， 分别如下： NONE：正常流程走，不额外的启动web容器, 比如Tomcat。 SERVLET：基于servlet的web程序，需要启动内嵌的servletweb容器，比如Tomcat。 REACTIVE：基于reactive的web程序，需要启动内嵌reactiveweb容器 通过判断是否加载了对应的类，比如加载了DispatcherServlet等则会判断是Servlet的web程序, 比如引用了spring-boot-starter-web模块， 则 是web程序。 设置初始化器 初始化器ApplicationContextInitializer， 用于Spring的IOC容器在刷新之前， 进行一些组件的初始化， 比如ServletContextApplicationContextInitializer。 其最终调用是SpringFactoriesLoader.loadSpringFactories()方法， 该方法同@EnableAutoConfiguration注解作用类似， 会从META-INF/spring.factories中加载定义好的类，此处对应的key是 org.springframework.context.ApplicationContextInitializer。 例如在spring-boot-autoconfigure模块该值对应如下： 1234# Initializersorg.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer,\\org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener 在spring-boot模块该值对应如下： 1234# PropertySource Loadersorg.springframework.boot.env.PropertySourceLoader=\\org.springframework.boot.env.PropertiesPropertySourceLoader,\\org.springframework.boot.env.YamlPropertySourceLoader 所以， 实际上的初始化器ApplicationContextInitializer在整个容器中会有多个， 只要实现了ApplicationContextInitializer接口并且在spring.factories文件中定义好就行。 设置事件监听器 监听器ApplicationListener主要是用来监听特定的事件ApplicationEvent, 比如IOC容器的刷新，关闭等。 其实现原理和上面的初始化器类似， 只不过这一次从spring.factories文件中加载的类的key是org.springframework.boot.SpringApplicationRunListener 执行run()方法SpringApplication类构造完成之后， 就会调用该类的run()方法， 该方法的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public ConfigurableApplicationContext run(String... args) &#123; //任务执行观察器, 用来记录任务的开始时间和结束时间 StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); //获取运行时监听器（1） SpringApplicationRunListeners listeners = getRunListeners(args); //发送应用程序启动事件（2） listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); // 创建并配置Environment(此时会加载application.yml文件) ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); //打印banner Banner printedBanner = printBanner(environment); //创建context context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances( SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); //刷新context之前的一些准备工作 prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新context refreshContext(context); //context刷新完成之后执行额外一些操作 afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; //发送ApplicationStartingEvent事件 listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; //发送ApplicationReadyEvent事件，标志SpringApplication已经正在运行，即已经成功启动，可以接收服务请求。（3） listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; //返回context return context; &#125; 运行时监听器 此处获取的是SpringApplicationRunListeners, 该监听器的作用主要是用来监听应用程序启动过程的, 并将相应的事件广播出去。 首先需要获取， 对应的代码是（1）处的代码： 1SpringApplicationRunListeners listeners = getRunListeners(args); 类似的， 该类的定义还是在spring.factories文件中， 对应的key为org.springframework.boot.SpringApplicationRunListener, 在spring-boot模块中该值定义如下： 12org.springframework.boot.SpringApplicationRunListener=\\org.springframework.boot.context.event.EventPublishingRunListener 总共定义了如下几个事件类型： ApplicationStartedEvent: run方法执行的时候立马执行 ApplicationEnvironmentPreparedEvent: ApplicationContext创建之前并且环境信息准备好的时候调用 ApplicationPreparedEvent: ApplicationContext创建完成之后， refresh之前 ApplicationReadyEvent： ApplicationContext成功启动 ApplicationFailedEvent： ApplicationContext启动失败 这里需要需要说明一下此处的SpringApplicationRunListener和在构造SpringApplication对象时创建的ApplicationListener的联系： context的创建首先是创建ApplicationContext， 这个过程很简单，就是根据webApplicationType创建相应的ApplicationContxet, 决定是servlet、reactive或者非web应用。 例如对于一个普通web的springboot工程，其最终的ApplicationContext实现类是：AnnotationConfigServletWebServerApplicationContext, 类结构如下所示： prepareContext该方法主要做的事如下： 基本的初始化，如设置Environment 注册已经有的对象为单例bean, 比如banner 加载main方法所在的类 其中加载main方法所在类的关键代码如下： 1234567891011121314protected void load(ApplicationContext context, Object[] sources) &#123; // 获取BeanDefinition加载器 BeanDefinitionLoader loader = createBeanDefinitionLoader(getBeanDefinitionRegistry(context), sources); if (this.beanNameGenerator != null) &#123; loader.setBeanNameGenerator(this.beanNameGenerator); &#125; if (this.resourceLoader != null) &#123; loader.setResourceLoader(this.resourceLoader); &#125; if (this.environment != null) &#123; loader.setEnvironment(this.environment); &#125; loader.load();&#125; 首先会创建BeanDefinitionLoader， 然后利用该loader将主类的BeanDefinition加载到context中去。 其中需要说明一下BeanDefinition, Spring的bean的来源有各种方式， 比如xml文件或者注解的方式， 对于这些bean的定义， 每一个都会生成一个相应的BeanDefinition。 refresh容器刷新的核心方法。该方法的主要作用是加载其他的BeanDefinition。 以web程勋为例， 其对应的context是AnnotationConfigEmbeddedWebApplicationContext， 跟踪其方法， 最终是调用其父类AbstractApplicationContext的refresh方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public void refresh() throws BeansException, IllegalStateException &#123; //使用synchronized修饰，标识在同一时刻 synchronized (this.startupShutdownMonitor) &#123; // 刷新前准备，设置flag、时间，初始化properties等 prepareRefresh(); // 获取ApplicationContext中组合的BeanFactory ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 设置类加载器，添加后置处理器等准备 prepareBeanFactory(beanFactory); try &#123; // 供子类实现， 例如web程序中的webApplicationContext会在此处构造ServletContext postProcessBeanFactory(beanFactory); // todo 需要再说明 调用Bean工厂的后置处理器 invokeBeanFactoryPostProcessors(beanFactory); // 对于实现了BeanFactoryPostProcessor接口的bean进行注册 registerBeanPostProcessors(beanFactory); // 初始化与国际化有关的属性 initMessageSource(); // 初始化事件广播器， 对于springboot而言， 之前已经注册过， 所以此处不需要重新注册， 只是从容器中拿出来用即可 initApplicationEventMulticaster(); // 子类实现 onRefresh(); // 将容器内部的监听器添加到事件广播中 registerListeners(); // 实例化所有的(懒加载的除外)单例Bean，在进行实例化的时候， BeanPostProcessor开始生效 finishBeanFactoryInitialization(beanFactory); // 发布刷新完毕事件 finishRefresh(); &#125; catch (BeansException ex) &#123; &#125; finally &#123; &#125; &#125;&#125; 对上面其中几个关键的步骤进行说明： invokeBeanFactoryPostProcessors 从容器中找出BeanDefinitionRegistryPostProcessor和BeanFactoryPostProcessor接口的实现类， 然后按照特定的顺序执行。 注意其中有一个ConfigurationClassPostProcessor的接口， 是BeanDefinitionRegistryPostProcessor的实现类， 该类的作用就是解析所有被以下注解修饰的类 @Configuration @Component @ComponentScan @Import @ImportResource registerBeanPostProcessors 从容器中找出BeanPostProcessor接口的实现类， 在后面的方法finishBeanFactoryInitialization进行bean的实例化的时候， 会执行BeanPostProcessor。 onRefresh 子类实现。 例如对于web程序，AnnotationConfigEmbeddedWebApplicationContext会在此处创建内置的servlet容器， 比如常见的Tomcat, Jetty。 callRunners该方法会调用所有实现了CommandLineRunner和ApplicationRunner接口的类。 12345678910111213141516private void callRunners(ApplicationContext context, ApplicationArguments args) &#123; List&lt;Object&gt; runners = new ArrayList&lt;&gt;(); runners.addAll(context.getBeansOfType(ApplicationRunner.class).values()); runners.addAll(context.getBeansOfType(CommandLineRunner.class).values()); //按照定义好的order进行排序 AnnotationAwareOrderComparator.sort(runners); //使用LinkedHashSet来保证runner是有序的， 这样就能按照order顺序执行 for (Object runner : new LinkedHashSet&lt;&gt;(runners)) &#123; if (runner instanceof ApplicationRunner) &#123; callRunner((ApplicationRunner) runner, args); &#125; if (runner instanceof CommandLineRunner) &#123; callRunner((CommandLineRunner) runner, args); &#125; &#125; &#125; 综上， 整个启动流程的图例：","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"java","slug":"编程/java","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://acchw.top/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"https://acchw.top/tags/springboot/"}]},{"title":"树莓派使用另一主机的硬盘","slug":"折腾/树莓派/树莓派使用另一主机的硬盘","date":"2021-08-07T10:10:15.000Z","updated":"2025-01-21T05:49:52.460Z","comments":true,"path":"posts/56849/","link":"","permalink":"https://acchw.top/posts/56849/","excerpt":"","text":"实现效果：不实际接入真实硬盘， 而是使用局域网内（公网主机也行， 只是速度取决于带宽）另一主机上的硬盘（或者是目录） 实现方案： 使用NFS来实现 准备： 一个树莓派 一台Linux主机， 系统Ubuntu 20.04, ip是10.0.0.239 操作步骤： 服务端（Linux主机） IP为10.0.0.239的主机安装nfs server 1sudo apt install nfs-kernel-server 创建nfs共享目录（如果已经存在， 可以不创建）， 也就是要挂载到树莓上的目录 1mkdir -p /mnt/media/download 配置nfs服务， 编辑配置文件：vim &#x2F;etc&#x2F;exports, 添加一行 1/mnt/media/download *(rw,sync,no_root_squash,no_subtree_check) 各个字段说明如下： &#x2F;mnt&#x2F;media&#x2F;download: 要共享的目录 *：指定可以访问共享目录的用户 ip, * 代表所有用户。192.168.3. 指定网段。192.168.3.29 指定 ip。 rw：可读可写。如果想要只读的话，可以指定 ro。 sync：文件同步写入到内存与硬盘中。 async：文件会先暂存于内存中，而非直接写入硬盘。 no_root_squash：登入 nfs 主机使用分享目录的使用者，如果是 root 的话，那么对于这个分享的目录来说，他就具有 root 的权限！这个项目『极不安全』，不建议使用！但如果你需要在客户端对 nfs 目录进行写入操作。你就得配置 no_root_squash。方便与安全不可兼得。 root_squash：在登入 nfs 主机使用分享之目录的使用者如果是 root 时，那么这个使用者的权限将被压缩成为匿名使用者，通常他的 UID 与 GID 都会变成 nobody 那个系统账号的身份。 subtree_check：强制 nfs 检查父目录的权限（默认） no_subtree_check：不检查父目录权限 配置完成后， 执行如下命令： 12sudo exportfs -asudo service nfs-kernel-server restart 此时服务端配置完成 客户端（树莓派） 安装nfs客户端 1apt install nfs-common 将树莓派的目录挂载到之前在另外一台主机上共享出来的文件夹， 例如将树莓派的&#x2F;mnt&#x2F;download目录挂载到刚刚在另外一台Linux主机上创建的&#x2F;mnt&#x2F;media&#x2F;download目录， 命令如下： 1mount 10.0.0.239:/mnt/media/download /mnt/download/ 在10.0.0.239的&#x2F;mnt&#x2F;media&#x2F;download下创建一个文件， 此时可以看到树莓派的&#x2F;mnt&#x2F;download&#x2F;目录下也存在刚刚新建的文件","categories":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"树莓派","slug":"折腾/树莓派","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E6%A0%91%E8%8E%93%E6%B4%BE/"}],"tags":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/tags/%E6%8A%98%E8%85%BE/"},{"name":"树莓派","slug":"树莓派","permalink":"https://acchw.top/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/"}]},{"title":"红米AC2100 openWrt设置无线中继","slug":"折腾/其他/红米AC2100 openwrt设置无线中继","date":"2021-08-02T21:10:15.000Z","updated":"2025-01-21T05:49:52.459Z","comments":true,"path":"posts/50827/","link":"","permalink":"https://acchw.top/posts/50827/","excerpt":"","text":"红米AC2100刷openWrt的教程：http://openwrt.ink:88/archives/s-breed 刷完之后， 设置无线中继的步骤记录一下。这里使用2.4G的频率来作为客户端接收上一级信号， 然后使用5G频率作为服务端发射无线信号。图片是已经设置好之后截的， 所以有些地方可能有些不一样。 选择 网络 - 无线， 选择2.4G旁边的扫描按钮，加入网络， 选择需要中继的上一级网络， 然后填写密码， 其他默认即可。然后点击保存。 进入网络-接口页面， 点击 LAN条目的编辑， 注意此时已经有一个刚刚加入的wwan网络。 除了刚才新添加的wwan网络， 其余的全部勾选上 以上已经完成。 若不想开启2.4G的发射信号， 去无线页面禁用或删除2.4G的即可。","categories":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"其他","slug":"折腾/其他","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"路由器","slug":"路由器","permalink":"https://acchw.top/tags/%E8%B7%AF%E7%94%B1%E5%99%A8/"},{"name":"折腾 - AC2100","slug":"折腾-AC2100","permalink":"https://acchw.top/tags/%E6%8A%98%E8%85%BE-AC2100/"}]},{"title":"基于docker-compose+prometheus+grafana搭建Linux监控","slug":"折腾/监控/基于docker-compose+prometheus+grafana搭建Linux监控","date":"2021-07-29T23:10:00.000Z","updated":"2021-12-15T17:10:15.000Z","comments":true,"path":"posts/50788/","link":"","permalink":"https://acchw.top/posts/50788/","excerpt":"","text":"基于docker-compose、prometheus、grafana来搭建Linux服务器的监控。 用到的几个expoter说明： node-exporter: 监控整个主机所有资源 cadvisor： 监控容器资源 创建目录在主机上创建一些目录， 用来持久化监控数据和配置 123mkdir -p /opt/docker/monitor/configmkdir -p /opt/docker/monitor/datachmod 777 /opt/docker/monitor/data 创建docker-compose.yml切换到&#x2F;opt&#x2F;docker&#x2F;monitor目录， 新建docker-compose.yml， 内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859version: &#x27;2&#x27;networks: monitor: driver: bridgeservices: grafana: image: grafana/grafana container_name: monitor-grafana hostname: grafana restart: always volumes: - /opt/docker/monitor/data:/var/lib/grafana ports: - &#x27;11000:3000&#x27; networks: - monitor prometheus: image: prom/prometheus container_name: monitor-prometheus hostname: prometheus restart: always volumes: - /opt/docker/monitor/config/prometheus.yml:/etc/prometheus/prometheus.yml ports: - &#x27;11001:9090&#x27; networks: - monitor node-exporter: image: quay.io/prometheus/node-exporter container_name: monitor-node-exporter hostname: node-exporter restart: always ports: - &#x27;11002:9100&#x27; networks: - monitor cadvisor: image: google/cadvisor container_name: monitor-cadvisor hostname: cadvisor restart: always volumes: - /:/rootfs:ro - /var/run:/var/run:ro - /sys:/sys:ro - /var/lib/docker/:/var/lib/docker:ro - /dev/disk/:/dev/disk:ro devices: - /dev/kmsg:/dev/kmsg ports: - &#x27;11003:8080&#x27; networks: - monitor 10619 创建prometheus.yml切换到&#x2F;opt&#x2F;docker&#x2F;monitor&#x2F;config目录， 新建prometheus.yml，内容如下： 12345678910111213141516171819global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s).scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: &#x27;prometheus&#x27; static_configs: - targets: [&#x27;10.0.0.239:11001&#x27;] - job_name: &#x27;node-exporter&#x27; static_configs: - targets: [&#x27;10.0.0.239:11002&#x27;] - job_name: &#x27;cadvisor&#x27; static_configs: - targets: [&#x27;10.0.0.239:11003&#x27;] 页面配置 启动容器 docker-compose up -d 待容器成功启动之后，进入dashboard页面, 页面地址：http://10.0.0.239:11000， 第一次进入时的默认用户名和密码是：admin&#x2F;admin， 然后需要设置新密码 配置datasource, 选择prometheus, URL填写： http://10.0.0.239:11001 从模板网站找到自己喜欢的模板， 比如模板ID为1860， 直接输入ID， 然后点击load导入即可。 说明一下几个exporter用到的比较好用的模板ID node-exporter: 1860 process-exporter： 249 cadvisor： 11600","categories":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"监控","slug":"折腾/监控","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/tags/%E6%8A%98%E8%85%BE/"},{"name":"linux","slug":"linux","permalink":"https://acchw.top/tags/linux/"},{"name":"监控","slug":"监控","permalink":"https://acchw.top/tags/%E7%9B%91%E6%8E%A7/"},{"name":"docker","slug":"docker","permalink":"https://acchw.top/tags/docker/"}]},{"title":"mybatis相关","slug":"编程/java/mybatis相关","date":"2021-07-09T16:40:00.000Z","updated":"2025-01-21T05:49:52.461Z","comments":true,"path":"posts/45791/","link":"","permalink":"https://acchw.top/posts/45791/","excerpt":"","text":"在springboot中打印sql语句， 在配置文件中添加： 1mybatis.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"java","slug":"编程/java","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://acchw.top/tags/java/"},{"name":"mybatis","slug":"mybatis","permalink":"https://acchw.top/tags/mybatis/"}]},{"title":"clickhouse索引原理介绍","slug":"编程/clickhouse/clickhouse索引原理介绍","date":"2021-07-07T09:00:00.000Z","updated":"2025-01-21T05:49:52.460Z","comments":true,"path":"posts/20353/","link":"","permalink":"https://acchw.top/posts/20353/","excerpt":"","text":"clickhouse本身支持很多表引擎，这里只介绍其中最常用的MergeTree引擎。 建表语句12345678910111213CREATE TABLE [IF NOT EXISTS] [db.]table_name ( name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1] [TTL expr1], name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2] [TTL expr2], ... INDEX index_name1 expr1 TYPE type1(...) GRANULARITY value1, # 创建普通索引（跳数索引） INDEX index_name2 expr2 TYPE type2(...) GRANULARITY value2) ENGINE = MergeTree()ORDER BY expr[PARTITION BY expr] # 创建分区键索引[PRIMARY KEY expr] # 创建主键索引[SAMPLE BY expr][TTL expr [DELETE|TO DISK &#x27;xxx&#x27;|TO VOLUME &#x27;xxx&#x27;], ...][SETTINGS name=value, ...] 介绍其中几个关键选项的含义： PARTITION BY ：分区键。 指定表数据以何种标准进行分区。分区键既可以是单个列字段，也可以通过元组的形式使用多个列字段，同时它也支持使用列表达式。 ORDER BY ：排序键，用于指定在一个数据片段内，数据以何种标准排序。默认情况下主键（PRIMARY KEY）与排序键相同。 PRIMARY KEY： 主键。声明后会依照主键字段生成一级索引。默认情况下，主键与排序键(ORDER BY)相同，所以通常直接使用ORDER BY代为指定主键。 SETTINGS:：index_granularity选项表示索引的粒度，默认值为8192。MergeTree索引在默认情况下，每间隔8192行数据才生成一条索引。 数据存储文件下面是clickhouse在存储数据时所产生的文件， 现分别对其用途做简要说明： checksums.txt 校验文件，用于记录其他的各类文件（如idx, mrk等）的size和其哈希值， 用于快速校验文件的完整性和正确性。 columnx.txt 列信息文件， 明文存储，记录该表的所有列信息。 count.txt 计数文件，明文存储，记录当前分区下数据的总行数。 primary.idx 主键索引文件 列名.bin 列数据文件，使用压缩格式存储。每一列都对应一个该文件，如列age为age.bin 列名.mrk 列标记文件，使用二进制存储。 partition.dat 保存当前分区下分区表达式最终生成的值 minmax_.idx 记录当前分区下分区字段对应原始数据的最小和最大值。 skp_idx_列名.idx 跳数索引数据文件 。 skp_idx_列名.mrk 跳数索引标记文件。 索引类型首先说明两个重要概念 granule 索引粒度， 由index_granularity指定，默认8192 block 列存储文件的压缩单元。每个列存文件的Block包含若干个Granule，具体多少个Granule是由参数min_compress_block_size控制，每次列的Block中写完一个Granule的数据时，它会检查当前Block Size有没有达到设定值，如果达到则会把当前Block进行压缩然后写磁盘。 主键索引对应文件：primary.idx 与传统数据库不同， 主键索引是可以相同的。主键索引存储的是主键值和block， 且数据是按照主键进行排序的。 若查询条件中含有主键值， 则会先根据主键索引得到可能的granule范围，再根据mk标记文件中的偏移量确定数据。 分区键索引数据文件：minmax_分区键名.idx 记录当前分区下分区字段对应原始数据的最小和最大值。用于查询时迅速排除不需要的分区。 跳数索引数据文件： skp_idx_列名.idx 语法：INDEX index_name1 expr1 TYPE type1(...) GRANULARITY value1 索引的可用类型包括minmax, set, bloom_filter。 和主键索引类似， 也是一种稀疏索引。因为数据是按主键排序的，主键索引统计的其实就是每个Granule粒度的主键序列最大和最小值，而Skipping索引提供的聚合函数种类更加丰富，是主键索引的一种补充能力。 数据插入MergeTree在写入一批数据时，数据总会以数据片段的形式写入磁盘，且数据片段不可修改。为了避免片段过多，ClickHouse会通过后台线程，定期合并这些数据片段，属于相同分区的数据片段会被合成一个新的片段。 MergeTree表的写入链路是一个极端的batch load过程，Data Part不支持单条的append insert。每次batch insert都会生成一个新的MergeTree Data Part。如果用户单次insert一条记录，那就会为那一条记录生成一个独立的Data Part，这必然是无法接受的。一般我们使用MergeTree表引擎的时候，需要在客户端做聚合进行batch写入或者在MergeTree表的基础上创建Distributed表来代理MergeTree表的写入和查询，Distributed表默认会缓存用户的写入数据，超过一定时间或者数据量再异步转发给MergeTree表。MergeTree存储引擎对数据实时可见要求非常高的场景是不太友好的。 数据查询例如有如下数据，主键为x和y。 x y z A a 1 A a 2 A c 1 B c 1 B c 2 C a 3 C a 1 假设index_granularity为2，先将数据分为多个block x y block-id A a 1 A a 1 A c 2 B c 2 B b 3 C a 3 C a 4 primary.idx内容展示的是主键和block的关系 主键 block (A,a) 1 (A,c) 2 (B,b) 3 (C,a) 4 x.bin 和 y.bin存储对应的各个列的数据，x.mrk存储如下 block-id offset 1 1-3 2 4-9 3 10-30 查询过程如下： 1、查询条件2、通过查询条件的主键，可以根据primary.idx得出数据落在哪些block3、根据block id 到各自的 mrk上寻找对应的offset4、根据offset去bin中获取对应的数据，加载到内存中向量化操作，过滤 从以上可以看出： 查询条件含有主键会减少很多不必要的磁盘IO 查询返回的值中列越少， 读取的列标记文件和列数据文件就越少，磁盘IO也会降低很多 参考文章 https://segmentfault.com/a/1190000023089140 https://developer.aliyun.com/article/761931 https://clickhouse.tech/docs/zh/engines/table-engines/mergetree-family/mergetree/ https://www.dazhuanlan.com/2019/11/21/5dd5815e95f7e/","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"clickhouse","slug":"编程/clickhouse","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/clickhouse/"}],"tags":[{"name":"clickhouse","slug":"clickhouse","permalink":"https://acchw.top/tags/clickhouse/"},{"name":"原理","slug":"原理","permalink":"https://acchw.top/tags/%E5%8E%9F%E7%90%86/"}]},{"title":"Linux压测和硬件测试命令","slug":"编程/linux/Linux常用压测和硬件测试命令","date":"2021-07-05T21:23:15.000Z","updated":"2025-01-21T05:49:52.461Z","comments":true,"path":"posts/11469/","link":"","permalink":"https://acchw.top/posts/11469/","excerpt":"","text":"硬盘使用fio命令来进行硬盘测试。 安装：sudo apt install fio 基本参数如下： 123456789101112131415161718192021filename=/dev/emcpowerb 支持文件系统或者裸设备，-filename=/dev/sda2或-filename=/dev/sdbdirect=1 测试过程绕过机器自带的buffer，使测试结果更真实rw=randwread 测试随机读的I/Orw=randwrite 测试随机写的I/Orw=randrw 测试随机混合写和读的I/Orw=read 测试顺序读的I/Orw=write 测试顺序写的I/Orw=rw 测试顺序混合写和读的I/Obs=4k 单次io的块文件大小为4kbsrange=512-2048 同上，提定数据块的大小范围size=5g 本次的测试文件大小为5g，以每次4k的io进行测试numjobs=30 本次的测试线程为30runtime=1000 测试时间为1000秒，如果不写则一直将5g文件分4k每次写完为止time_based: 如果在runtime指定的时间还没到时文件就被读写完成，将继续重复直到runtime时间结束。ioengine=psync io引擎使用pync方式，如果要使用libaio引擎，需要yum install libaio-devel包rwmixwrite=30 在混合读写的模式下，写占30%group_reporting 关于显示结果的，汇总每个进程的信息此外lockmem=1g 只使用1g内存进行测试zero_buffers 用0初始化系统buffernrfiles=8 每个进程生成文件的数量 随机读向磁盘写一个2G文件，10线程，随机读1分钟 1fio -filename=/tmp/test_randread -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=16k -size=2G -numjobs=10 -runtime=60 -group_reporting -name=mytest 随机写1fio -filename=/dev/sdb1 -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=psync -bs=16k -size=2G -numjobs=10 -runtime=60 -group_reporting -name=mytest 顺序读1fio -filename=/dev/sdb1 -direct=1 -iodepth 1 -thread -rw=read -ioengine=psync -bs=16k -size=2G -numjobs=10 -runtime=60 -group_reporting -name=mytest 顺序写1fio -filename=/dev/sdb1 -direct=1 -iodepth 1 -thread -rw=write -ioengine=psync -bs=16k -size=2G -numjobs=10 -runtime=60 -group_reporting -name=mytest 网络测试局域网内设备之间的网速， 使用iperf3 进行测试。 安装： ubuntu: apt install iperf3 windows: 去官网下载文件直接解压， 然后使用cmd运行即可 在局域网内某台服务器上（假设该台机器IP为10.0.0.239）启动iperf3 1iperf3 -s 在局域网内的另一台机器上运行命令： 1iperf3 -c 10.0.0.239 即可得到网速输出结果 CPU使用stress来进行。 安装： apt install stress 主要参数： -c, –cpu N 产生 N 个进程，每个进程都反复不停的计算随机数的平方根 -i, –io N 产生 N 个进程，每个进程反复调用 sync() 将内存上的内容写到硬盘上 -m, –vm N 产生 N 个进程，每个进程不断分配和释放内存 –vm-bytes B 指定分配内存的大小 –vm-stride B 不断的给部分内存赋值，让 COW(Copy On Write)发生 –vm-hang N 指示每个消耗内存的进程在分配到内存后转入睡眠状态 N 秒，然后释放内存，一直重复执行这个过程 –vm-keep 一直占用内存，区别于不断的释放和重新分配(默认是不断释放并重新分配内存) -d, –hadd N 产生 N 个不断执行 write 和 unlink 函数的进程(创建文件，写入内容，删除文件) –hadd-bytes B 指定文件大小 -t, –timeout N 在 N 秒后结束程序 –backoff N 等待N微妙后开始运行 -q, –quiet 程序在运行的过程中不输出信息 -n, –dry-run 输出程序会做什么而并不实际执行相关的操作 –version 显示版本号 -v, –verbose 显示详细的信息 压满CPU命令，其中4是CPU核心数。通过调用 sqrt 函数计算由 rand 函数产生的随机数的平方根实现。 1stress -c 4 在压测过程中每隔1s实时显示主频： 1watch -n1 &quot;cat /proc/cpuinfo | grep \\&quot;^[c]pu MHz\\&quot;&quot;","categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"linux","slug":"编程/linux","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://acchw.top/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://acchw.top/tags/shell/"}]}],"categories":[{"name":"编程","slug":"编程","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/"},{"name":"other","slug":"编程/other","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/other/"},{"name":"java","slug":"编程/java","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/java/"},{"name":"生活","slug":"生活","permalink":"https://acchw.top/categories/%E7%94%9F%E6%B4%BB/"},{"name":"go","slug":"编程/go","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/go/"},{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/"},{"name":"监控","slug":"折腾/监控","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E7%9B%91%E6%8E%A7/"},{"name":"其他","slug":"折腾/其他","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E5%85%B6%E4%BB%96/"},{"name":"mysql","slug":"编程/mysql","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/mysql/"},{"name":"分布式","slug":"编程/分布式","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"博客","slug":"折腾/博客","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E5%8D%9A%E5%AE%A2/"},{"name":"clickhouse","slug":"编程/clickhouse","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/clickhouse/"},{"name":"感悟","slug":"感悟","permalink":"https://acchw.top/categories/%E6%84%9F%E6%82%9F/"},{"name":"linux","slug":"编程/linux","permalink":"https://acchw.top/categories/%E7%BC%96%E7%A8%8B/linux/"},{"name":"树莓派","slug":"折腾/树莓派","permalink":"https://acchw.top/categories/%E6%8A%98%E8%85%BE/%E6%A0%91%E8%8E%93%E6%B4%BE/"}],"tags":[{"name":"海外","slug":"海外","permalink":"https://acchw.top/tags/%E6%B5%B7%E5%A4%96/"},{"name":"Google Play","slug":"Google-Play","permalink":"https://acchw.top/tags/Google-Play/"},{"name":"Android","slug":"Android","permalink":"https://acchw.top/tags/Android/"},{"name":"封闭式测试","slug":"封闭式测试","permalink":"https://acchw.top/tags/%E5%B0%81%E9%97%AD%E5%BC%8F%E6%B5%8B%E8%AF%95/"},{"name":"java","slug":"java","permalink":"https://acchw.top/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"https://acchw.top/tags/jvm/"},{"name":"acme.sh","slug":"acme-sh","permalink":"https://acchw.top/tags/acme-sh/"},{"name":"证书","slug":"证书","permalink":"https://acchw.top/tags/%E8%AF%81%E4%B9%A6/"},{"name":"namesilo","slug":"namesilo","permalink":"https://acchw.top/tags/namesilo/"},{"name":"生活","slug":"生活","permalink":"https://acchw.top/tags/%E7%94%9F%E6%B4%BB/"},{"name":"go","slug":"go","permalink":"https://acchw.top/tags/go/"},{"name":"折腾","slug":"折腾","permalink":"https://acchw.top/tags/%E6%8A%98%E8%85%BE/"},{"name":"linux","slug":"linux","permalink":"https://acchw.top/tags/linux/"},{"name":"监控","slug":"监控","permalink":"https://acchw.top/tags/%E7%9B%91%E6%8E%A7/"},{"name":"prometheus","slug":"prometheus","permalink":"https://acchw.top/tags/prometheus/"},{"name":"tailscale","slug":"tailscale","permalink":"https://acchw.top/tags/tailscale/"},{"name":"pve","slug":"pve","permalink":"https://acchw.top/tags/pve/"},{"name":"mysql","slug":"mysql","permalink":"https://acchw.top/tags/mysql/"},{"name":"微服务","slug":"微服务","permalink":"https://acchw.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"分布式","slug":"分布式","permalink":"https://acchw.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"事务","slug":"事务","permalink":"https://acchw.top/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"正则","slug":"正则","permalink":"https://acchw.top/tags/%E6%AD%A3%E5%88%99/"},{"name":"路由器","slug":"路由器","permalink":"https://acchw.top/tags/%E8%B7%AF%E7%94%B1%E5%99%A8/"},{"name":"AC2100","slug":"AC2100","permalink":"https://acchw.top/tags/AC2100/"},{"name":"nginx","slug":"nginx","permalink":"https://acchw.top/tags/nginx/"},{"name":"docker - jenkins","slug":"docker-jenkins","permalink":"https://acchw.top/tags/docker-jenkins/"},{"name":"博客","slug":"博客","permalink":"https://acchw.top/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"hexo","slug":"hexo","permalink":"https://acchw.top/tags/hexo/"},{"name":"selfhost","slug":"selfhost","permalink":"https://acchw.top/tags/selfhost/"},{"name":"docker","slug":"docker","permalink":"https://acchw.top/tags/docker/"},{"name":"springboot","slug":"springboot","permalink":"https://acchw.top/tags/springboot/"},{"name":"jenkins","slug":"jenkins","permalink":"https://acchw.top/tags/jenkins/"},{"name":"vue","slug":"vue","permalink":"https://acchw.top/tags/vue/"},{"name":"clickhouse","slug":"clickhouse","permalink":"https://acchw.top/tags/clickhouse/"},{"name":"感悟","slug":"感悟","permalink":"https://acchw.top/tags/%E6%84%9F%E6%82%9F/"},{"name":"分布式事务","slug":"分布式事务","permalink":"https://acchw.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"架构","slug":"架构","permalink":"https://acchw.top/tags/%E6%9E%B6%E6%9E%84/"},{"name":"mq","slug":"mq","permalink":"https://acchw.top/tags/mq/"},{"name":"drone","slug":"drone","permalink":"https://acchw.top/tags/drone/"},{"name":"日志","slug":"日志","permalink":"https://acchw.top/tags/%E6%97%A5%E5%BF%97/"},{"name":"umami","slug":"umami","permalink":"https://acchw.top/tags/umami/"},{"name":"waline","slug":"waline","permalink":"https://acchw.top/tags/waline/"},{"name":"笔记","slug":"笔记","permalink":"https://acchw.top/tags/%E7%AC%94%E8%AE%B0/"},{"name":"jdk","slug":"jdk","permalink":"https://acchw.top/tags/jdk/"},{"name":"arthas","slug":"arthas","permalink":"https://acchw.top/tags/arthas/"},{"name":"spring","slug":"spring","permalink":"https://acchw.top/tags/spring/"},{"name":"shell","slug":"shell","permalink":"https://acchw.top/tags/shell/"},{"name":"confluence","slug":"confluence","permalink":"https://acchw.top/tags/confluence/"},{"name":"折腾 - AC2100","slug":"折腾-AC2100","permalink":"https://acchw.top/tags/%E6%8A%98%E8%85%BE-AC2100/"},{"name":"树莓派","slug":"树莓派","permalink":"https://acchw.top/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/"},{"name":"mybatis","slug":"mybatis","permalink":"https://acchw.top/tags/mybatis/"},{"name":"原理","slug":"原理","permalink":"https://acchw.top/tags/%E5%8E%9F%E7%90%86/"}]}